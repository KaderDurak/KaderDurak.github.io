{"pages":[],"posts":[{"title":"Model Representation","text":"Makine öğrenimi algoritmasının çoğunun temel amacı bir model oluşturmaktır. Bu modelden hipotez olarak söz edebiliriz. Hipotez temel olarak girdiyi çıktıya eşler. Girdi değişkeni özelliği ve çıktı değişkeni hedefi belirtir. Öğrenmek için kullanacağımız veri kümesine eğitim seti(trainning set) denir. Amacımız, bir eğitim seti verildiğinde, h: X → Y fonksiyonunu öğrenmek, böylece h (x), y’nin karşılık gelen değeri için “iyi” bir tahmin edici model diyebiliriz. Gelin bunu bir örnekle açıklayalım. Diyelim ki ev fiyatları tahmini yapmak istiyoruz. Elimizde evlerin m2 ölçüleri ve fiyatları var. Burada dikkat etmemiz gereken girdilerimiz yani “x” , fiyatını tahmin edeceğimiz çıktı “y” olacak. Eğer biz verilerimizden fiyat tahmini yapmak istiyorsak bunun için regresyon (regression) kullancağız. Eğer yaşam alanının ( villa, arsa , apartman vs.) ne olduğunu bulmak istiyorsak bunun için sınıflandırma (classification) kullanacağız. Hedefimiz fiyat tahmini bu yüzden regresyon kullancağız. Hipotez formülü : hQ(x) =θ0+θ1X Tetalar (θ) bizim parametrelerimizdir. Katsayılarımızı düzgün seçmeliyiz çünkü verilerimiz görselleştirdiğimizde eğimi 0 olduğunda tahminimiz yani y değeri hep 0 gelecektir.NOT: Model oluşturmanın amacı parametreleri veya teta değerlerini doğru seçmektir, böylece h (x) training verilerimiz olan x’ler için ulaşmak istedğimiz y değerine yakın olur. Eğer θ1 değerimizi yani eğimi veren değer 0 olursa aşağıdaki gibi grafik elde ederiz ve istediğimiz y değerine ulaşamayız. 1234import matplotlib.pyplot as pltplt.plot([1, 2, 3, 4], [1,1,1,1])plt.ylabel('some numbers')plt.show() Şimdi örnek verimizi görselleştirerek anlatalım.Elimizde evlerin ölçüleri ve fiyatları olsun burada eğim 0 olmadığından girdiğimiz her x değerimize karşılık y değeri geliyor bu da bize regression kullanarak fiyat tahmini yapmamızı sağlıyor.Aşağıdaki örnekteki gibi küçük bir verimiz olsun. 123import pandas as pddf = pd.DataFrame({'x': [0, 0.5, 1,1.5,2,2.5,3], 'hθ(x)': [1.0,1.5,2.0,2.5,3.0,3.5,4.0]})df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x hθ(x) 0 0.0 1.0 1 0.5 1.5 2 1.0 2.0 3 1.5 2.5 4 2.0 3.0 5 2.5 3.5 6 3.0 4.0 1234plt.plot([852, 1416,1534,2104], [178,232,315,460], color='blue')plt.ylabel('Price($) in 1000s')plt.xlabel('Size in house feet^2 (x)')plt.show() Üstteki grafikte olduğu gibi kırmızı noktalarla işaretlediğimiz 1750 feet^2 olan evimizin tahmini değeri 375000 $ civarı oluyor.İşte modelimizin bize tahminde bulunmasını istediğimiz değerleri böyle örneklendirebiliriz.","link":"/ModelRepresentation/"},{"title":"Cost Function","text":"Öncelikle lineer regresyonda tahmin edilen y değeri ile gerçek y değeri arasındaki hatayı minimuma indirebilmek için teta(θ) değerleri bulmalıyız. Maliyet fonksiyonunu (cost function) minimize etmeliyiz. Maliyet fonksiyonu diye gerçek y değerleri ile tahmin edilen y değerleri arasındaki farka deriz.Maliyet fonksiyonumuz test setindeki çıktıları ne kadar iyi tahmin ettiğini ölçer.Tahmin edilen değer ile gerçek değer arasındaki fark ne kadar az ise modelimiz o kadar iyi tahminde bulunur. Amaç, maliyeti en aza indiren bir dizi ağırlık(weight) ve önyargı(bias) bulmaktır. Bunun için y’nin gerçek değeri ile y’nin tahmini değeri (tahmin) arasındaki farkı ölçen ortalama kare hatası(the mean squared error)kullanılır. Aşağıdaki regresyon çizgisinin denklemi, sadece iki parametreye sahip olan hθ (x) = θ0 + θ1x’tir: weight(θ1) ve bias(θ0) Minimising Cost functionHerhangi bir makine öğrenmesi modelinin amacı cost fuction’ı (maliyet fonksiyonu) en aza indirgemektir. Gelin, yukarıdaki görselimizi anlayalım. Kırmızı olan tepecikler random olarak seçtiğimiz teta parametrelerimizin bulunduğu yeri temsil ediyor.Hedefimiz koyu mavi ile gösterilen “global minimum” dediğimiz yere doğru adım adım ilerlemek. Şekilde görüldüğü gibi ikinci bir mavi noktamız var buraya da “local minimum” diyoruz ama bu noktaya ilerlemiyoruz.Çünkü istediğimiz şey costu minimize etmek(hatalı değerlerimizi minimuma indirgemek) local minimumda değerimiz global minimuma göre daha yüksek çıkacağından hedefimiz her zaman global minimuma gitmek olmalıdır.Peki nasıl global minimuma varacağız. Bunun için etkili bir optimizasyon algoritması olan Gradient Descent Algoritmasını kullanacağız. Gradient Descent AlgorithmGradient Descent (Degrade İniş), hesaplamayı kullanarak belirli maliyet işlevinin minimum değerine karşılık gelen parametrelerin optimal değerlerini bulmak için yinelemeli olarak çalışır. Matematiksel olarak, ‘türev’ tekniği maliyet işlevini en aza indirmek için son derece önemlidir, çünkü minimum noktayı elde etmeye yardımcı olur. Türev, matematikten gelen bir kavramdır ve belirli bir noktada fonksiyonun eğimini ifade eder. Eğimi bilmemiz gerekir, böylece bir sonraki yinelemede daha düşük bir maliyet elde etmek için katsayı değerlerini hareket ettirme yönünü (işaretini) biliriz. Her parametredeki bir fonksiyonun türevi (bizim durumumuzda, J (θ)) bize bu değişkene göre fonksiyonun hassasiyetini veya değişkeni değiştirmenin fonksiyon değerini nasıl etkilediğini söyler. Gradient descent, bu nedenle, öğrenme sürecinin modeli optimal bir parametre kombinasyonuna doğru hareket ettiren öğrenilmiş tahminlerde düzeltici güncellemeler yapmasını sağlar (θ). Cost , bir gradient descent algoritmasının her tekrarı için tüm training set kümesinde bir makine öğrenme algoritması için hesaplanır. Gradient Descent, algoritmanın bir yinelemesine bir “Batch Gradient Descent” deniyor. Bu her bir yinelemenin gradyanını hesaplamak için kullanılan bir training set kümesindeki toplam örnek sayısını belirtir. Bu yeni gradyan, maliyet fonksiyonumuzun mevcut konumumuzdaki eğimini (geçerli parametre değerleri) ve parametrelerimizi güncellemek için hareket etmemiz gereken yönü gösterir. Güncellememizin boyutu learning rate (α)(öğrenme oranı) tarafından kontrol edilmektedir. Learning rate (α) Gradient descent algoritmasında adımların boyutuna, ne kadar büyük adımlar attığımız konusunda bize ek kontrol sağlayan değere learning rate (α) denir. Büyük bir learning rate(α) sağ alt köşedeki görselde olduğu gibi, her adımda daha fazla yer atlayabiliriz, ancak tepenin eğimi sürekli değiştiği için en düşük noktayı aşma riskiyle karşı karşıyayız. Çok düşük bir learning rate(α) sağ üst köşedeki görselde olduğu gibi, negatif gradyan yönünde güvenle hareket edebiliriz, çünkü bunu çok sık yeniden hesaplıyoruz. Düşük bir learning rate(α) daha kesindir, ancak gradyanı hesaplamak zaman alıcıdır, bu nedenle en alt noktaya gelmek çok uzun zaman alacaktır. En sık kullanılan learning rate(α) değerleri: 0.001, 0.003, 0.01, 0.03, 0.1, 0.3 Şimdi Gradient descent algoritmasının üç varyantını tartışalım. Aralarındaki temel fark, her bir learning step(öğrenme adımı) için degradeleri hesaplarken kullandığımız veri miktarıdır. Aralarındaki değişim, her bir parametrenin güncellemesini gerçekleştirmek için zaman karmaşıklığına karşı degradenin doğruluğudur (learning step). Stochastic Gradient Descent (SGD)Batch Gradient Descent ile ilgili temel sorun, her adımda degradeleri hesaplamak için tüm eğitim setini kullanmasıdır, bu da eğitim seti büyük olduğunda çok yavaş olmasını sağlar. Stochastic Gradient Descent her adımda belirlenen eğitimde rastgele bir örnek seçer ve degradeleri yalnızca bu tek örneğe göre hesaplar. Algoritmayı çok daha hızlı hale getirir. Öte yandan, stokastik doğası nedeniyle, bu algoritma Batch Gradient Descent’ten çok daha az düzenlidir: minimum seviyeye ulaşıncaya kadar hafifçe azaltmak yerine, maliyet fonksiyonu yukarı ve aşağı sıçrar ve sadece ortalama olarak azalır. Zamanla minimum seviyeye çok yakın olacak, ancak oraya vardığında geri dönmeyecek, asla yerleşmeyecek. Dolayısıyla algoritma durduğunda, son parametre değerleri iyidir, ancak optimal değildir. Cost function çok düzensiz olduğunda, bu aslında algoritmanın local minimum dışına atlamasına yardımcı olabilir, bu nedenle Stochastic Gradient Descent, Batch Gradient Descent’ten daha fazla global minimum bulma şansına sahiptir. Bu nedenle, rasgelelik local optima’dan kaçmak için iyidir, diğer yandan kötüdür, çünkü algoritmanın asla minimumda yerleşemeyeceği anlamına gelir. Bu ikilemin bir çözümü learning rate(α) kademeli olarak azaltmaktır. Adımlar büyük başlar (hızlı ilerleme kaydetmeye ve yerel minimadan kaçmaya yardımcı olur), daha sonra gittikçe küçülür ve algoritmanın küresel minimumda yerleşmesine izin verir. Her yinelemede öğrenme hızını belirleyen işlev öğrenme çizelgesi olarak adlandırılır. Öğrenme oranı çok yavaş bir şekilde azalırsa, minimuma çok uzun bir süre sonra varabilir ve eğitimi çok erken durdurursanız, en uygun olmayan bir çözüm elde edebilirsiniz. Öğrenme oranı çok hızlı bir şekilde azalırsa, yerel bir minimumda takılabilir veya hatta en sonunda yarıya kadar donmuş olabilirsiniz. Öğrenme oranı çok yavaş bir şekilde azalırsa, minimum süre boyunca uzun süre atlayabilir ve eğitimi çok erken durdurursanız, en uygun olmayan bir çözüm elde edebilirsiniz. Stochastic Gradient Descent kullanıldığında, parametrelerin ortalama olarak global minimum değere doğru çekilmesini sağlamak için training set bağımsız ve aynı şekilde dağıtılmalıdır. Bunu sağlamanın basit bir yolu, eğitim sırasında örnekleri karıştırmaktır. Bunu yapmazsanız, örneğin örnekler etikete göre sıralanırsa, SGD bir etiket için, ardından bir sonraki öğe için optimizasyon yaparak başlayacaktır ve global minimum değere yakın yerleşmeyecektir. Mini-Batch Gradient DescentHer adımda, gradientleri tüm training sete (Batch GD’de olduğu gibi) veya yalnızca bir örneğe (Stochastic GD’de olduğu gibi) dayalı olarak hesaplamak yerine, Mini-Batch GD, gradientleri mini-batches adı verilen küçük rasgele örnek kümelerinde hesaplar. Mini-Batch GD’nin Stochastic GD’ye göre ana avantajı, özellikle GPU’ları kullanırken matris işlemlerinin donanım optimizasyonundan bir performans artışı elde edebilmenizdir. Algoritmanın parametre alanındaki ilerlemesi, özellikle oldukça büyük Mini-Batch’lerde SGD’den daha az düzensizdir. Sonuç olarak, Mini-Batch GD, SGD’den minimum seviyeye biraz daha yakın yürüyecektir. Ancak, diğer taraftan, yerel minimadan kaçmak daha zor olabilir. Hepsi minimum seviyeye yakın, ancak Batch GD’nin yolu aslında minimumda dururken, hem Stochastic GD hem de Mini-Batch GD dolaşmaya devam ediyor. Ancak, Batch GD’nin her adımı atması çok zaman aldığını ve iyi bir öğrenme programı kullandıysanız Stochastic GD ve Mini-Batch GD’nin de minimum seviyeye ulaşacağını unutmayın.","link":"/CostFunction-GradientDescent/"},{"title":"Linear and Polynomial Regression","text":"İki tür gözetimli(supervised) makine öğrenme algoritması vardır: Regresyon ve sınıflandırma.Örneğin, bir evin fiyatını dolar olarak tahmin etmek bir regression problemidir, bir tümörün kötü veya iyi huylu olup olmadığını tahmin etmek bir sınıflandırma problemidir. Bu yazıda , Python için en popüler makine öğrenimi kütüphanelerinden biri olan Scikit-Learn kullanarak doğrusal regresyonun ne olduğunu ve hem iki değişken hem de çoklu değişken için nasıl uygulanabileceğini kısaca inceleyeceğiz. Cebirde “doğrusallık” terimi, iki veya daha fazla değişken arasındaki doğrusal bir ilişkiyi ifade eder. Bu ilişkiyi iki boyutlu bir alanda (iki değişken arasında) çizersek, düz bir çizgi elde ederiz. Doğrusal regresyon, verilen bağımsız değişkeni (x) temel alarak bağımlı bir değişken değerini (y) tahmin etme görevini yerine getirir. Dolayısıyla, bu regresyon tekniği x (girdi) ve y (çıktı) arasında doğrusal bir ilişki bulur. Bu nedenle, adı Linear Regression(Doğrusal Regresyon) dur. Bağımsız değişkeni (x) x eksenine ve bağımlı değişkeni (y) y eksenine çizersek, doğrusal regresyon bize aşağıdaki şekilde gösterildiği gibi veri noktalarına en iyi uyan düz bir çizgi verir. Yukarıdaki çizginin denklemi: Y = mx + b Burada b kesişme noktası ve m doğrunun eğimidir. Temel olarak, lineer regresyon algoritması bize kesişme ve eğim için en uygun değeri verir (iki boyutta). Veri özellikleri oldukları ve değiştirilemedikleri için y ve x değişkenleri aynı kalır. Kontrol edebileceğimiz değerler kesişme noktası (b) ve eğimdir (m). Kesişim ve eğim değerlerine bağlı olarak birden fazla düz çizgi olabilir. Tek değişkeni olan bir regresyon modeli şu şekilde temsil edilebilir: y = b0 + m1b1 hQ(x) =θ0 + θ1X Multiple Linear RegressionTemel olarak doğrusal regresyon algoritmasının yaptığı şey, veri noktalarına birden çok satır sığdırması ve en az hatayla sonuçlanan çizgiyi döndürmesidir. Aynı kavram ikiden fazla değişkenin bulunduğu vakalara da genişletilebilir. Buna multiple linear regression(çoklu doğrusal regresyon) denir. Örneğin, evin fiyatını alanı, yatak odası sayısı, bölgedeki insanların ortalama geliri, evin yaşı vb. Temelinde tahmin etmeniz gereken bir senaryo düşünün. Bu durumda, bağımlı değişken (hedef değişken) birkaç bağımsız değişkene bağlıdır. Birden çok değişkeni içeren bir regresyon modeli şu şekilde temsil edilebilir: y = b0 + m1b1 + m2b2 + m3b3 + … mnbn hQ(x) =θ0 +θ1X1 + θ2X2 + θ3X3 + …θnXn Bu, bir hiper düzlemin denklemidir. Unutmayın, iki boyutta doğrusal bir regresyon modeli düz bir çizgidir; üç boyutta olan bir düzlemdir ve üçten fazla boyutta olan bir hyperplane(hiperdüzlem)dir. Polynomal Linear RegressionKullanacağınız veri setine göre veriler lineer olarak dağılım göstermeyebilir ve doğrusal olmayan(non-linear) diye adlandırılan dağılımı gösterebilir. Lineer regresyon burada istediğimiz sonucu vermeyecektir.Non-linear olan dağılımda polinomal regresyon istediğimiz sonuca bizi yaklaştıracaktır.Polinomal regresyonda bağımsız değişken x ve bağımlı değişken y arasındaki ilişkinin n’inci derece polinom olarak modellendiği bir doğrusal regresyon biçimidir. Unutmayın burada x’ler lineer ilerlemiyor.Zaten lineer dememizin sebebi θ0,θ1,θ2,θ3… değerleridir. n’inci derece polinom denklemi y = a + b1x + b2x^2 +….+ bnx^n hQ(x) =θ0 +θ1X1 + θ2X2^2 + θ3X3^3 + …θnXn^n Gelin küçük bir örnekle lineer ve polinomal regresyon için kodlayalım. Amaç: Sıcaklık ve basınç değerleri verilen bir veri setinde istenilen sıcaklık değerinde basıncın ne olacağını tahmin edebilmektir. 12345678# Importing the libraries import numpy as np import matplotlib.pyplot as plt import pandas as pd # Importing the dataset datas = pd.read_csv('data.csv') datas .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sno Temperature Pressure 0 1 0 0.0002 1 2 20 0.0012 2 3 40 0.0060 3 4 60 0.0300 4 5 80 0.0900 5 6 100 0.2700 123# for x axis we select temperature, for y axis we select pressureX = datas.iloc[:, 1:2].values y = datas.iloc[:, 2].values 12345# Fitting Linear Regression to the dataset from sklearn.linear_model import LinearRegression lin = LinearRegression() lin.fit(X, y) 12LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) 123456789# Visualising the Linear Regression results plt.scatter(X, y, color = 'blue') plt.plot(X, lin.predict(X), color = 'red') plt.title('Linear Regression') plt.xlabel('Temperature') plt.ylabel('Pressure') plt.show() 123456789# Fitting Polynomial Regression to the dataset from sklearn.preprocessing import PolynomialFeatures poly = PolynomialFeatures(degree = 4) X_poly = poly.fit_transform(X) poly.fit(X_poly, y) lin2 = LinearRegression() lin2.fit(X_poly, y) 12LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) 123456789# Visualising the Polynomial Regression results plt.scatter(X, y, color = 'blue') plt.plot(X, lin2.predict(poly.fit_transform(X)), color = 'red') plt.title('Polynomial Regression') plt.xlabel('Temperature') plt.ylabel('Pressure') plt.show() Görselimizde görüldüğü üzere regresyon çizgimiz değerlerimize yakın bile değil peki yakın(fit) olmaması sorun teşkil eder mi? Tabi ki eder modelimize uyguladığımızda modelimiz doğru tahminde bulunmayacaktır. 12# Predicting a new result with Linear Regression print(lin.predict([[197]])) 1[0.41050733] 12# Predicting a new result with Polynomial Regression lin2.predict(poly.fit_transform([[197]])) 1array([7.18740604]) Yukarıda aynı x sıcaklık değeri için basınç tahminleri arasındaki farkı görebiliriz.Polinomal regresyon modelimiz lineer regresyon modelimize göre daha iyi tahminde bulundu diyebiliriz. Polinomal regresyonda avantajlar: Polinom, bağımlı ve bağımsız değişken arasındaki ilişkiye en iyi yaklaşımı sağlar. Polinomal regresyonda dezavantajlar: Bunlar aykırı değerlere karşı çok hassastır. Verilerdeki bir veya iki aykırı değerin varlığı, doğrusal olmayan bir analizin sonuçlarını ciddi şekilde etkileyebilir. Ek olarak, maalesef doğrusal olmayan regresyonda aykırı değerlerin tespiti için doğrusal regresyon için olanlardan daha az model doğrulama aracı vardır.","link":"/Regression/"},{"title":"GPT-3","text":"Generative Pre-trained Transformer 3 (Türkçe: Üretken Ön İşlemeli Dönüştürücü 3) kısaca GPT-3, insanların yazdığı metinlere benzer içerik üretmek için derin öğrenmeyi kullanan özbağlanımlı dil modelidir. GPT-n serisindeki üçüncü nesil dil tahmin modeli olan GPT-3, San Francisco merkezli yapay zeka araştırma laboratuvarı OpenAI tarafından geliştirilmiştir. GPT-3’ün tam sürümü, veri işleyecek 175 milyar parametreye sahiptir. Bu rakam GPT-2’nin öğrenme kapasitesinin 2 katıdır. 14 Mayıs 2020’de tanıtılan ve Temmuz 2020 itibarıyla beta aşamasında olan GPT-3, önceden öğretilmiş dil örnekleriyle doğal dil işleme (NLP) sistemini kullanmaktadır. GPT-3’ün piyasaya sürülmesinden önce, en büyük dil modeli Microsoft’un Şubat 2020’de tanıttığı ve GPT-3’ün %10’undan daha az kapasiteye sahip olan (17 milyar parametre) Turing NLG idi.Wikipedia sitesinde bu şekilde açıklanıyor. Youtube panelinde GPT-3 hakkında sorulan sorulara Google Brain’de Araştırmacı olan Lukasz Kaiser şu açıklamaları yaptı: Transformerlardan öncesini yani derin öğrenme kısmında NLP’de RNN’ler her şeyi doğru yapıyordu. Derin öğrenmenin ve NLP’nin ilk büyük dalgasıydılar. İşleri adım adım yineleyerek yapmanız gerektiğine dair süper temel fikirlere sahiptiler, bu da çok sezgisel ancak modern donanımda gerçekten yavaştır çünkü hızlandırıcılar paralel işlem için inşa edilmiştir. Dikkat fikri NLP’de çok eski bir bir yöntem olan hizalamadan (alignment) geliyor. Diyelim ki bir cümleyi çevirmeye çalışıyorsunuz elinizde ingilizce ve fransızca cümleler var hangi kelimelerin hangi kelimelere karşılık geldiğini hizalamaya çalışıyorsunuz. Dolayısıyla, bu hizalama fikrini bir sinir ağına koyarsanız, elde ettiğiniz şey dikkat mekanizmasıdır. Kelimeleri daha önce gelen kelimelerle hizalamanın farklılaştırılabilir yumuşak bir versiyonudur ve öz-ilgi, aynı metni, daha önce görünen kelimelerle aynı hizaya getirecek şekilde hizalamaktır. Bu fikir, aldığınız sonuçlar açısından iyi işliyor, ancak aynı zamanda modern derin öğrenme hızlandırıcılarında iyi bir şekilde uygularsanız şaşırtıcı derecede hızlı da çalışıyor. Sonuçları bir gün veya bir ay beklemeniz gerekmiyor bu da büyük bir fark yaratıyor. Ama diğer bir şey de hizalama(alignment), nlp’de uzun zamandır bilinen gerçekten iyi bir fikir.Paragrafın tamamını çevirmek istiyorsanız, bu bölümü çevirmeye odaklandığınızda ve her seferinde sadece bu bölüme baktığınızda çok daha kolay. Her insanın yaptığı da budur. Bunu bir sinir ağına öncelikli olarak veriyorsunuz ve bu gerçekten işe yarıyor, bu yüzden dikkatin geldiği yer burasıdır ancak şunu söylemek isterim, her şey dalgalar halinde ilerlerken, RNN’leri kullanmak çok iyi bir fikirdir. Çünkü seyrek transformatörlerle ilgili, bu ilginin insanların düşündüğünden daha çok RNN’ e benzediğini gösteren modern makaleler var ve aslında buna tekrar eden bir ağ(recurrent network) eklemek onu daha da iyi hale getiriyor. İnsanlar tekrar eden ağa geri dönerse, tekrar bir şekilde tekrarlayan ağlara bile dönüşmesi bu yüzden şaşırtıcı olmaz. En yeni teknikten daha fazlasını öğrenmek, daha önce gelen şeyleri bilmek ve bununla ilgili her şeyi öğrenmek iyidir.Herkesin internette NLP’de derin öğrenme yaptığını düşünebilirsiniz ama ben bunun tam tersini düşünüyorum. Elbette bugünlerde her şey çevrimiçi olarak gerçekleşiyor, çok fazla hareket varmış gibi geliyor çünkü nlp dünyası onlarca yıl öncesine göre çok daha büyük ama bu derin modellerin aslında dil yapabildiği şeylerin yüzeyini zar zor çizdiğimizi hissediyorum. Bu dil son derece derin bir alandır. Evet, size bir hikaye oluşturabiliriz ve okuruz, tamam mıdır? Gerçekten anlamı var mı? Bu doğru şeyler yaratır mı? Bunu bize bildiğini söyleyebilir mi? Doğrulayabilir miyiz? Önyargılar(bias) hakkında konuştuğumuzu bildiğini bize söyleyebilir mi? Aslında dil modelinin bu kadar saldırgan olup olmadığını sorabilirsiniz ve çoğu durumda size bunun olup olmadığını söyleyecektir. Ancak insan benzeri olmayan bazı hatalar yapacaktır. Nedenini anlayabilir miyiz?Sadece birkaç hafta önce piyasaya sürülen GPT-3, gradyan inişi olmadan öğrenebileceğini gösteren ilk model, bir şeyleri girdi olarak modele koyabilirsiniz ve sanki onları eğitiyormuş gibi çalışır, bu yüzden bu çok yeni ve test etmesi çok zor çünkü büyük modele ihtiyacınız var .Yarım yıl veya yıl içinde, bunu uygulamalı olarak yapmaya başlayabileceğiniz modeller olacak. Öğrenmeye başlamak için harika bir zaman. Çünkü dile giren bu şeylerin çoğunun başlangıcı. Teknolojiyi aldık ama aslında dilin derinliklerine inerken hala önümüzde çok düşündüğümüz bu uygulamaları getirecek.GPT-3 transformer modeli tüm web üzerinden eğitildi. Gelecekteki öğrenmeyi biraz beklenmedik olan yeni görevlere genelleştirir, ancak gerçekten tüm web üzerinde eğitilmiştir. Yani bir anlamda o kadar da beklenmedik değil ve arabalarda eğiteceğimiz daha küçük modelleri bile göreceksiniz, onlar da genelleştiriyorlar. Bu yüzden şimdi GPT-3 size harika cevaplar veriyor ama bu cevaplar ne işe yarıyor ve belki görevleriniz soruya uyuyor. Ancak görevinizi çözmeniz gerekir, genellikle görevinizi çözmek için modeli kullanmak ister ve onunla oynarsınız.Tamam işe yaramaz bir görevi çözmelisin deneyim kazanıp, öğrenmen gerekiyor ama daha sonra gerçek dünya görevinde bir araç kullanmalısın ve harika çeviri modellerimiz var. Google Translate sadece bu model değil tam da bunun gibi derin öğrenme modeli başlatamazsın. Biraz regex eklemelisiniz. Korkunç bir çıktı üretip üretmediğini görmek için basit bir regexin için bile, tüm eski tekniklere ön işleme(pre-processing) koymanız gerekir. Kullanıcılarınıza, müşterilerinize sonuç olarak neyi çıkardığınıza bakmanız ve bunu doğrulamanız gerekir. Bu modelin neden belirli durumlarda kötü çıktılar verdiğini ve modeli nasıl tamir edeceğinizi bilmiyorsanız düşünmeye başlamanız gerekir.Hala bilmediğimiz çok şey var, o zaman buna karşı biraz savunma yapmanız gerekiyor, belki sadece modelin gerçekten kötü olduğu ve GPT-3’ün kötü olduğu durumları tespit edin. GPT-3 diğer pek çok durumda iyidir, bu yüzden onu nasıl kullanacağınızı gerçekten öğrenmeniz gereken bir araç olduğunu öğrenmeniz gerekir. Verimli bir şekilde kullanabileceğiniz her yerde deneyim kazanın, sadece alıp uygulamak işe yarıyor mu? Hayır. Ne zaman çalıştığını, nasıl çalıştığını anlamak için çok iş var. Yıllar geçtikçe, bu şeylerin gerçekte nasıl çalıştığını daha iyi anlayacağımızı umuyoruz. Bunlar dilde biraz daha derine inmemize, ancak yine de uzun bir yol kat etmemize olanak tanıyan araçlar. Onu nerede nasıl kullanabileceğimizi öğrenmemiz gereken uzun bir yolumuz var ama bizim de ihtiyacımız olan başka şeyler olabilir ve kesinlikle bir GPT-4 olacaktır, bu yolun sonu değil, ama bu yolda büyük bir adım. Bir diğer panelist olan makine öğrenmesi ve yapay zeka alanında verdiği eğitimlerle birçok insanın hayatına dokunan Prof. Andrew NG GPT-3 ün çıkışı hakkında şunları söyledi: “İnanılmaz görünen her şey, çok çalıştığımızda ve bunları iyileştirdiğimizde, niş görünse bile doğru uygulamaları bulduğumuzda, bir gün okuduğumuz ve hayran kaldığımız bu modelin nerede olduğunu hayal edin. Kol saatinizde koşacak mıyım bilmiyorum ama teknoloji bu şekilde daha kullanılabilir hale geliyor. Şu anda NLP alanında çok sayıda zayıf sinyal görüyorum. Bunun patlayacağını ve daha yetenekli ve daha yaygın hale geleceğini düşündüğüm şeylerle yapabilirsiniz. Umarım bu araçları öğrenerek bu devrime katılabilirsiniz.” GPT-3 parlak bir obje mi? Doğru zamanda mı piyasa sürüldü? İşlerimizi elimizden alacak mı? Bu tür sorulardan ziyade kendimizi güncel tutmalı öğrenebileceğimiz herşeyi öğrenmeli, tüm yetkinlikleri kazanmalıyız. Bu yetkinlikleri bir sonraki ürünü geliştirmek için kullanmalıyız. Bu GPT4, GPT-5 yada adı her ne ise kendimizi geliştirip bu henüz yüzeyinde olduğumuz dünyanın derinlerine inmeliyiz. O dünyanın nasıl olacağını belirleyenler arasında olmalıyız.","link":"/GPT-3/"},{"title":"Feature Scaling","text":"Makine öğreniminde feature scaling (özellik ölçeklendirme), bir makine öğrenimi modeli oluşturmadan önce verilerin ön işlenmesi sırasında en kritik adımlardan biridir. Ölçeklendirme, zayıf bir makine öğrenimi modeli ile daha iyisi arasında bir fark yaratabilir. Makine öğrenimi, karışık meyve suyu yapmak gibidir. En iyi karıştırılmış suyu elde etmek istiyorsak, tüm meyveleri boyutlarına göre değil, doğru oranlarına göre karıştırmamız gerekir. Benzer şekilde, birçok makine öğrenimi algoritmasında, tüm özellikleri aynı duruma getirmek için, ölçeklendirme yapmamız gerekir, böylece tek bir önemli sayı oluşturduğumuz modeli büyüklükleri nedeniyle etkileyemez. Feature scaling işleminde en çok kullanılanlar Normalizasyon ve Standardizasyon teknikleridir.Normalizasyonda değerlerimizi iki sayı arasında, tipik olarak [0,1] veya [-1,1] arasında sınırlamak istediğimizde normalleştirme kullanılır.Standardizasyon, verileri sıfır ortalamaya ve 1 varyansına dönüştürürken, verilerimizi birimsiz hale getirir. Peki neden gereklidir? Makine öğrenimi algoritması sadece sayıyı görür. Eğer aralıkta çok büyük bir fark varsa, bir tarafta farkın binler olduğunu ve diğer tarafta farkın onlar arasında değiştiğini farzedelim. Daha yüksek aralıklı sayıların bir tür üstünlüğe sahip olduğu varsayımını yapar. Dolayısıyla bu daha önemli sayı, modeli eğitirken daha belirleyici bir rol oynamaya başlar. Makine öğrenimi algoritması sayılar üzerinde çalışır ve bu sayının neyi temsil ettiğini bilmez. 10 gramlık bir ağırlık ve 10 dolarlık bir fiyat tamamen iki farklı şeyi temsil ediyor ama makine öğrenmesi algoritması bunun farklı olduğunu anlamıyor ve model için her ikisine aynı muamelesi yapıyor. Dolayısıyla bu daha önemli sayı, modeli eğitirken daha belirleyici bir rol oynamaya başlar. Bu nedenle, herhangi bir ön önem olmaksızın her özelliği aynı temelde getirmek için Feature Scaling “özellik ölçeklendirmesi” gereklidir. İlginç bir şekilde, ağırlığı “Kg” ye çevirirsek, “Fiyat” baskın hale gelir.Özellik ölçeklemenin uygulanmasının bir başka nedeni de, sinir ağı gradyan descent gibi birkaç algoritmanın, özellik ölçeklendirmesi olunca global minimuma çok daha hızlı yakınlaşmasıdır. Verilerin arasındaki mesafeyi ölçen makine öğrenmesi algoritmaları için feature scaling çok önemlidir. Eğer ölçeklendirme yapılmazsa, yüksek değere sahip özellik mesafe ölçümünü domine edecektir.Birçok algoritmada, daha hızlı yakınsama istediğimizde ölçeklendirme, sinir ağında olduğu gibi bir zorunluluktur.Ham verilerin değer aralığı büyük ölçüde değiştiğinden, bazı makine öğrenimi algoritmalarında, nesnel işlevler normalleştirme olmadan doğru şekilde çalışmaz. Örneğin, sınıflandırıcıların çoğu iki nokta arasındaki mesafeyi mesafeye göre hesaplar. Özelliklerden biri geniş bir değer aralığına sahipse, mesafe bu belirli özelliği yönetir. Bu nedenle, tüm özelliklerin aralığı normalize edilmelidir, böylece her özellik son mesafeye yaklaşık orantılı olarak katkıda bulunur.Yukarıda belirtildiği gibi koşullar karşılanmadığında bile, ML algoritması bir ölçek beklerse veya bir saturation fenomeni meydana gelirse, tekrar özelliklerinizi yeniden ölçeklendirmeniz gerekebilir. Yine, doyurucu aktivasyon işlevlerine (örneğin sigmoid) sahip bir sinir ağı iyi bir örnektir.Özellik ölçeklendirmesinin önemli olduğu bazı algoritmalara bakalım. • K-nearest neighbors (KNN) Öklid mesafe ölçüsü ile büyük değerlere duyarlıdır ve bu nedenle tüm özelliklerin eşit olarak tartılması için ölçeklendirilmelidir. • K-Means burada Öklid mesafe ölçüsünü kullanır özellik ölçekleme önemlidir. • Principal Component Analysis(PCA) gerçekleştirilirken ölçeklendirme çok önemlidir. PCA, feature(özellikleri) maksimum varyansla elde etmeye çalışır ve varyans, yüksek büyüklükteki özellikler için yüksektir ve PCA’yı yüksek büyüklük özelliklerine doğru çarpıtır. • Gradient Descent’i ölçeklendirerek hızlandırabiliriz çünkü küçük aralıklarda hızlı ve büyük aralıklarda yavaşça iner ve değişkenler çok düzensiz olduğunda verimsiz bir şekilde optimum seviyeye iner. Normalleştirme / ölçeklendirme gerektirmeyen algoritmalar, kurallara bağlı olanlardır. Değişkenlerin herhangi bir monoton dönüşümünden etkilenmezler. Ölçeklendirme, tekdüze bir dönüşümdür. Bu kategorideki algoritmaların örnekleri, tüm tree-tabanlı algoritmalardır. Bunlar CART, Random Forests, Gradient Boosted Decision Trees. Bu algoritmalar kuralları kullanır(eşitsizlikler dizisi) ve normalleştirme gerektirmez.Linear Discriminant Analysis(LDA), Naive Bayes gibi algoritmalar bu durumu işlemek ve özelliklere göre ağırlık vermek için donatılmış tasarımlara sahiptirler.Bu algoritmalarda özellik ölçeklendirmesinin gerçekleştirilmesinin çok fazla etkisi olmayabilir. Dikkat edilmesi gereken birkaç önemli nokta: • Ortalama merkezleme kovaryans matrisini etkilemez. • Değişkenlerin ölçeklendirilmesi kovaryans matrisini etkiler. • Standardizasyon kovaryansı etkiler. Feature Scaling Yöntemleri Min-Max Scaler Standard Scaler Max Abs Scaler Robust Scaler Quantile Transformer Scaler Power Transformer Scaler Unit Vector Scaler Bu yöntemleri elimizdeki küçük veri seti ile açıklamaya başlayalım. 12345678import pandas as pdimport numpy as npimport matplotlib.pyplot as plt%matplotlib inlinedf = pd.DataFrame({'WEIGHT': [15, 18.5, 14,5,1], 'PRICE': [1,3,4,7,10]}, index = ['Pineapple','Apple','Strawberry','Watermelon',\"Fig\"])print(df) WEIGHT PRICE Pineapple 15.0 1 Apple 18.5 3 Strawberry 14.0 4 Watermelon 5.0 7 Fig 1.0 10 1)Min-Max scaler Min-max Scaler verilen aralığa göre özellikleri ölçekler. Bu tahmin aracı, her özelliği, eğitim setinde verilen aralıkta, örneğin sıfır ile bir arasında olacak şekilde tek tek ölçeklendirir ve çevirir. Bu ölçekleyici, negatif değerler varsa -1 ile 1 aralığında verileri küçültür. Aralığı [0,1] veya [0,5] veya [-1,1] gibi ayarlayabiliriz. Bu Ölçekleyici, standart sapma küçükse ve dağılım Gaussian değilse iyi sonuç verir. Min-max scaler, aykırı değerlere karşı hassastır. 12345678910111213from sklearn.preprocessing import MinMaxScalerscaler = MinMaxScaler()df1 = pd.DataFrame(scaler.fit_transform(df), index=['Pineapple','Apple','Strawberry','Watermelon','Fig'], columns= ['WEIGHT','PRICE'])ax = df.plot.scatter(x='WEIGHT', y='PRICE',color=['red','green','blue','yellow','purple'], marker = '*',s=100, label='BREFORE SCALING');df1.plot.scatter(x='WEIGHT', y='PRICE', color=['red','green','blue','yellow','purple'], marker = \"2\",s=100,label='AFTER SCALING', ax = ax,figsize=(12,6));plt.axhline(0, color='cyan',alpha=0.9)plt.axvline(0, color='cyan',alpha=0.9);plt.show() 2) Standard Scaler Standart Scaler, verilerin normal olarak her bir özelliğe dağıtıldığını varsayar ve bunları, 1’lik bir standart sapma ile dağıtım 0 civarında ortalanacak şekilde ölçeklendirir. Merkezleme ve ölçeklendirme, training setideki örnekler üzerindeki ilgili istatistikleri hesaplayarak her özellik için bağımsız olarak gerçekleşir. Veriler normal olarak dağıtılmıyorsa, bu kullanılacak en iyi ölçekleyici değildir. 1234567891011from sklearn.preprocessing import StandardScalerscaler = StandardScaler()df2 = pd.DataFrame(scaler.fit_transform(df), columns=['WEIGHT','PRICE'], index = ['Pineapple','Apple','Strawberry','Watermelon','Fig'])ax = df.plot.scatter(x='WEIGHT', y='PRICE',color=['red','green','blue','yellow','purple'], marker = '*',s=100, label='BREFORE SCALING');df2.plot.scatter(x='WEIGHT', y='PRICE', color=['red','green','blue','yellow','purple'], marker = \"d\",s=100,label='AFTER SCALING', ax = ax, figsize=(12,6));plt.axhline(0, color='cyan',alpha=0.9);plt.axvline(0, color='cyan',alpha=0.9); 3) Max Abs ScalerMax Abs Scaler her özelliği maksimum mutlak değerine göre ölçekler. Bu ölçekleyici, eğitim setindeki her bir özelliğin maksimum mutlak değeri 1.0 olacak şekilde her özelliği ayrı ayrı ölçeklendirir ve çevirir. Verileri kaydırmaz, ortalamaz ve dolayısıyla herhangi bir seyrekliği yok etmez. Yalnızca pozitif verilerde, bu ölçekleyici Min-Maks ölçekleyiciye benzer şekilde davranır ve bu nedenle önemli aykırı değerlerin varlığından da muzdariptir. 1234567891011from sklearn.preprocessing import MaxAbsScalerscaler = MaxAbsScaler()df4 = pd.DataFrame(scaler.fit_transform(df), columns=['WEIGHT','PRICE'], index = ['Pineapple','Apple','Strawberry','Watermelon','Fig'])ax = df.plot.scatter(x='WEIGHT', y='PRICE',color=['red','green','blue','yellow','purple'], marker = '*',s=100, label='BREFORE SCALING');df4.plot.scatter(x='WEIGHT', y='PRICE', color=['red','green','blue','yellow','purple'], marker = '3',s=100,label='AFTER SCALING', ax = ax, figsize=(12,6))plt.axhline(0, color='cyan',alpha=0.9)plt.axvline(0, color='cyan',alpha=0.9); 4) Robust ScalerBu ölçekleyici aykırı değerlere karşı sağlamdır. Verilerimiz çok sayıda aykırı değer içeriyorsa, verilerin ortalamasını ve standart sapmasını kullanarak ölçeklendirme iyi sonuç vermeyecektir. Bu ölçekleyici medyanı kaldırır ve verileri nicelik aralığına göre ölçeklendirir ( IQR: Çeyrekler Arası Aralık). IQR, 1. çeyrek (25.inci kuantil) ile 3. çeyrek (75.inci kuantil) arasındaki aralıktır. Bu ölçekleyicinin merkezleme ve ölçeklendirme istatistikleri yüzdelik dilimlere dayanmaktadır ve bu nedenle birkaç sayıdaki büyük marjinal aykırı değerlerden etkilenmez. Aykırı değerlerin kendilerinin dönüştürülmüş verilerde hala mevcut olduğuna unutmayın. Ayrı bir aykırı değer kırpılması isteniyorsa, doğrusal olmayan bir dönüşüm gereklidir. 1234567891011from sklearn.preprocessing import RobustScalerscaler = RobustScaler()df3 = pd.DataFrame(scaler.fit_transform(df), columns=['WEIGHT','PRICE'], index = ['Pineapple','Apple','Strawberry','Watermelon','Fig'])ax = df.plot.scatter(x='WEIGHT', y='PRICE',color=['red','green','blue','yellow','purple'], marker = '*',s=100, label='BREFORE SCALING');df3.plot.scatter(x='WEIGHT', y='PRICE', color=['red','green','blue','yellow','purple'], marker = 'v',s=100,label='AFTER SCALING', ax = ax,figsize=(12,6))plt.axhline(0, color='cyan',alpha=0.9)plt.axvline(0, color='cyan',alpha=0.9); Şimdi bir aykırı değer sunarsak ve Standart Scaler ve Robust Scaler kullanarak ölçeklendirmenin etkisini görürsek ne olacağını görelim (karo şekil aykırı değeri gösterir). 12345678910111213141516171819202122dfr = pd.DataFrame({'WEIGHT': [15, 18, 12,10,50], 'PRICE': [1,3,2,5,20]}, index = ['Apricot','Apple','Banana','Grape','Cherry'])print(dfr)from sklearn.preprocessing import StandardScalerscaler = StandardScaler()df21 = pd.DataFrame(scaler.fit_transform(dfr), columns=['WEIGHT','PRICE'], index = ['Apricot','Apple','Banana','Grape','Cherry'])ax = dfr.plot.scatter(x='WEIGHT', y='PRICE',color=['purple','green','blue','yellow','black'], marker = '*',s=80, label='BREFORE SCALING');df21.plot.scatter(x='WEIGHT', y='PRICE', color=['purple','green','blue','yellow','black'], marker = 'd',s=50,label='STANDARD', ax = ax,figsize=(12,6))from sklearn.preprocessing import RobustScalerscaler = RobustScaler()df31 = pd.DataFrame(scaler.fit_transform(dfr), columns=['WEIGHT','PRICE'], index = ['Apricot','Apple','Banana','Grape','Cherry'])df31.plot.scatter(x='WEIGHT', y='PRICE', color=['purple','green','blue','yellow','black'], marker = 'v',s=50,label='ROBUST', ax = ax,figsize=(12,6))plt.axhline(0, color='cyan',alpha=0.9)plt.axvline(0, color='cyan',alpha=0.9); WEIGHT PRICE Apricot 15 1 Apple 18 3 Banana 12 2 Grape 10 5 Cherry 50 20 5) Quantile Transformer ScalerNicelik bilgilerini kullanarak özellikleri dönüştürür. Bu yöntem, özellikleri tek tip veya normal bir dağılım izleyecek şekilde dönüştürür. Bu nedenle, belirli bir özellik için, bu dönüşüm en sık görülen değerleri yayma eğilimindedir. Aynı zamanda (marjinal) aykırı değerlerin etkisini de azaltır: bu nedenle bu, Robust bir preprocessing şemasıdır. Bir özelliğin kümülatif dağılım işlevi, orijinal değerleri yansıtmak için kullanılır. Bu dönüşümün doğrusal olmadığını ve aynı ölçekte ölçülen değişkenler arasındaki doğrusal korelasyonları bozabileceğini, ancak farklı ölçeklerde ölçülen değişkenleri daha doğrudan karşılaştırılabilir hale getirdiğini unutmayın. Bu aynı zamanda bazen Rank Scaler olarak da adlandırılır. 1234567891011from sklearn.preprocessing import QuantileTransformerscaler = QuantileTransformer()df6 = pd.DataFrame(scaler.fit_transform(df), columns=['WEIGHT','PRICE'], index = ['Pineapple','Apple','Strawberry','Watermelon','Fig'])ax = df.plot.scatter(x='WEIGHT', y='PRICE',color=['red','green','blue','yellow','purple'], marker = '*',s=100, label='BREFORE SCALING');df6.plot.scatter(x='WEIGHT', y='PRICE', color=['red','green','blue','yellow','purple'], marker = 'X',s=100,label='AFTER SCALING', ax = ax,figsize=(12,6))plt.axhline(0, color='cyan',alpha=0.9)plt.axvline(0, color='cyan',alpha=0.9); C:\\Users\\kader\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (5). n_quantiles is set to n_samples. % (self.n_quantiles, n_samples)) 6)Power Transformer ScalerParametrik, monoton dönüşümler ailesinden olan Power Transformatörü, verileri daha Gaussian benzeri hale getirmek için uygulanır. Bu yöntem, aralık boyunca eşit olmayan bir değişkenin değişkenliği (farklı varyans) veya normalliğin istendiği durumlar ile ilgili sorunları modellemek için yararlıdır. Power Transformatörü, maksimum olasılık tahmini yoluyla varyansı stabilize etmede ve çarpıklığı en aza indirmede optimum ölçeklendirme faktörünü bulur. Şu anda, PowerTransformer’ın Sklearn uygulaması Box-Cox transformu ve Yeo-Johnson transformu desteklemektedir. Varyansı sabitlemek ve çarpıklığı en aza indirmek için en uygun parametre maksimum olasılıkla tahmin edilir. Box-Cox, giriş verilerinin kesinlikle pozitif olmasını gerektirirken, Yeo-Johnson hem pozitif hem de negatif verileri destekler. 1234567891011from sklearn.preprocessing import PowerTransformerscaler = PowerTransformer(method='yeo-johnson')df5 = pd.DataFrame(scaler.fit_transform(df), columns=['WEIGHT','PRICE'], index = ['Pineapple','Apple','Strawberry','Watermelon','Fig'])ax = df.plot.scatter(x='WEIGHT', y='PRICE',color=['red','green','blue','yellow','purple'], marker = '*',s=100, label='BREFORE SCALING');df5.plot.scatter(x='WEIGHT', y='PRICE', color=['red','green','blue','yellow','purple'], marker = '&lt;',s=100,label='AFTER SCALING', ax = ax, figsize=(12,6))plt.axhline(0, color='cyan',alpha=0.9)plt.axvline(0, color='cyan',alpha=0.9); 7) Unit Vector ScalerÖlçeklendirme, bütün özellik vektörünün birim uzunluk olduğu düşünülerek yapılır. Bu genellikle her bileşeni vektörün Öklid uzunluğuna (L2 Normu) bölmek anlamına gelir. Bazı uygulamalarda (örn. histogram özellikleri), özellik vektörünün L1 normunu kullanmak daha pratik olabilir. L1 normu, oldukça açık nedenlerden dolayı L2 normundan daha sağlamdır: L2 normunun kareleri değerleri, dolayısıyla aykırı değerlerin maliyetini üssel olarak artırır; L1 normu yalnızca mutlak değeri alır, bu nedenle onları doğrusal olarak değerlendirir. Min-Maks ölçeklendirmede olduğu gibi, birim vektör tekniği [0,1] aralığında değerler üretir. Katı sınırları olan özelliklerle uğraşırken bu oldukça kullanışlıdır. Örneğin, görüntü verileriyle uğraşırken renkler yalnızca 0 ile 255 arasında değişebilir. 1234## Unit vector with L1 normdf8 =df.apply(lambda x:x/np.linalg.norm(x,1))df8 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } WEIGHT PRICE Pineapple 0.280374 0.04 Apple 0.345794 0.12 Strawberry 0.261682 0.16 Watermelon 0.093458 0.28 Fig 0.018692 0.40 1234## Unit vector with L2 normdf9 =df.apply(lambda x:x/np.linalg.norm(x,2))df9 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } WEIGHT PRICE Pineapple 0.533930 0.075593 Apple 0.658513 0.226779 Strawberry 0.498334 0.302372 Watermelon 0.177977 0.529150 Fig 0.035595 0.755929 Aşağıdaki diyagram, verilerin tüm farklı ölçekleme teknikleri için nasıl yayıldığını ve görebileceğimiz gibi, birkaç noktanın üst üste geldiğini, dolayısıyla ayrı ayrı görünmediğini göstermektedir. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162dfr = pd.DataFrame({'WEIGHT': [15, 18, 12,10,50], 'PRICE': [1,3,2,5,20]}, index = ['Apricot','Apple','Banana','Grape','Cherry'])print(dfr)from sklearn.preprocessing import MinMaxScalerscaler1 = MinMaxScaler()df11 = pd.DataFrame(scaler1.fit_transform(dfr), columns=['WEIGHT','PRICE'], index = ['Apricot','Apple','Banana','Grape','Cherry'])ax = dfr.plot.scatter(x='WEIGHT', y='PRICE',color=['purple','green','blue','yellow','red'], marker = '*',s=50, label='BREFORE SCALING');df11.plot.scatter(x='WEIGHT', y='PRICE', color=['purple','green','blue','yellow','red'], marker = '2',s=100,label='MİN-MAX SCALİNG', ax = ax,figsize=(12,6))from sklearn.preprocessing import StandardScalerscaler2 = StandardScaler()df21 = pd.DataFrame(scaler2.fit_transform(dfr), columns=['WEIGHT','PRICE'], index = ['Apricot','Apple','Banana','Grape','Cherry'])df21.plot.scatter(x='WEIGHT', y='PRICE', color=['purple','green','blue','yellow','red'], marker = 'd',s=50,label='STANDARD SCALİNG', ax = ax,figsize=(12,6))from sklearn.preprocessing import RobustScalerscaler3 = RobustScaler()df31 = pd.DataFrame(scaler3.fit_transform(dfr), columns=['WEIGHT','PRICE'], index = ['Apricot','Apple','Banana','Grape','Cherry'])df31.plot.scatter(x='WEIGHT', y='PRICE', color=['purple','green','blue','yellow','red'], marker = 'v',s=50,label='ROBUST SCALİNG', ax = ax,figsize=(12,6))from sklearn.preprocessing import MaxAbsScalerscaler4 = MaxAbsScaler()df41 = pd.DataFrame(scaler4.fit_transform(dfr), columns=['WEIGHT','PRICE'], index = ['Apricot','Apple','Banana','Grape','Cherry'])df41.plot.scatter(x='WEIGHT', y='PRICE', color=['purple','green','blue','yellow','red'], marker = '3',s=50,label='MAX ABS SCALİNG', ax = ax,figsize=(12,6))from sklearn.preprocessing import QuantileTransformerscaler5 = QuantileTransformer()df51 = pd.DataFrame(scaler5.fit_transform(df), columns=['WEIGHT','PRICE'], index = ['Apricot','Apple','Banana','Grape','Cherry'])df51.plot.scatter(x='WEIGHT', y='PRICE', color=['purple','green','blue','yellow','red'], marker = '&lt;',s=50,label='QUANTİLE TRANSFORM SCALİNG', ax = ax,figsize=(12,6))from sklearn.preprocessing import PowerTransformerscaler6 = PowerTransformer(method='yeo-johnson')df61 = pd.DataFrame(scaler6.fit_transform(df), columns=['WEIGHT','PRICE'], index = ['Apricot','Apple','Banana','Grape','Cherry'])df61.plot.scatter(x='WEIGHT', y='PRICE', color=['purple','green','blue','yellow','red'], marker = 'X',s=50,label='POWER TRANSFORM SCALİNG', ax = ax,figsize=(12,6))plt.axhline(0, color='cyan',alpha=0.9)plt.axvline(0, color='cyan',alpha=0.9); WEIGHT PRICE Apricot 15 1 Apple 18 3 Banana 12 2 Grape 10 5 Cherry 50 20 C:\\Users\\kader\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (5). n_quantiles is set to n_samples. % (self.n_quantiles, n_samples)) Feature Scaling, Makine öğrenimi pre-processing kısmında önemli bir adımdır. Derin öğrenme, daha hızlı yakınsama için feature scaling gerektirir ve bu nedenle hangi feature scaling yöntemini kullanılacağına karar vermek çok önemlidir. Çeşitli algoritmalar için ölçeklendirme yöntemlerinin birçok karşılaştırma araştırması vardır. Yine de, diğer makine öğrenimi adımlarının çoğu gibi, özellik ölçeklendirme de bir deneme yanılma sürecidir.","link":"/Featurescaling/"},{"title":"Classification","text":"Supervised Learning(denetimli öğrenme) ve Unsupervised Learning(denetimsiz öğrenme) olan en yaygın iki öğrenme türünden Supervised Learning’den Classification(Sınıflandırma) problemi konusuna bakalım. Ayrıntılara girmeden önce Regresyon Problemi ile Sınıflandırma Problemi arasındaki fark nedir? Cevabı etiket türüdür.Regresyonda sürekli sayı varken sınıflandırmada aykırı sayı vardır. Regresyon problemi için ev fiyatları(etiket) için m^2 ve fiyatlarının olduğu verisetinde değerler gerçek ve sürekli değerlerdir. Buna bir diger örnek olarak hava durumu tahminlemesi eklenebilir. Sınıflandırma problemindeki etiket ise “kategori” yi temsil etmektedir. İkili sınıf(binary class) problemi için meme kanseri teşhisini örnek alıyoruz. Meme kanseri teşhisinde en çok ilgilendiğimiz şey tümör tipi yani kötü huylu veya iyi huyludur. Kolaylık sağlamak için, basitçe kötü huylu(malignant) ve zararsız(benign) olarak sırasıyla 0 ve 1 olarak etiketledik. Ayrık sayının (0 ve 1) verilerin etiketi (tümör tipi) anlamına geldiğine dikkat edin. y∈ {0,1} 0: “Negative Class” (e.g. benign tumor) 1: “Positive Class” (e.g. malignant tumor) Sınıflandırmada örnekler: Email: Spam/ Not Spam? Online Transactions : Fraudulent (Yes/No)? Tümor : Malignant /Benign? Feature : Size(cm) Label : Tumor Type Logistic RegressionHypothesis FunctionEtiket türü Regresyon Probleminden farklı olduğundan, Sınıflandırma problemini çözmek için başka bir hipotez kullanmalıyız.Bu problemi çözmek için Lojistik Regresyonu kullanılır. **Lojistik Regresyon, gerçek sayıları olasılıklara eşleyen bir sigmoid işlevi olarak da adlandırılır, [0, 1] aralığındadır. Dolayısıyla, sigmoid fonksiyonunun değeri, verilerin bir kategoriye ne kadar kesin ait olduğu anlamına gelir. Y’nin etiketi temsil ettiğini, y = 1’in hedef etiketi ve y = 0’ın diğer etiket olduğunu unutmamalıyız. Sigmoid işlevinde her zaman hedef etiketiyle ilgileniyoruz. Çoğu durumda, olasılık eşiği olarak 0,5 alırız. Eğer h (x) ≥0.5 ise, verilerin etiket 1’e ait olduğunu, h (x) &lt;0.5 ise, verilerin etiket 0’a ait olduğunu tahmin ediyoruz. Aşağıdaki görselde Lineer ve Lojistik Regresyonun farkını daha iyi görebiliriz. Lojistik regresyondan çizgi “S” şeklini alıyor. Eğri hipotezin ( kötü huylu tümor(1) veya iyi huylu tümor(0)) doğru olma olasılığını söylüyor. Lineer Regresyonda, en uygun çizgiyi tahmin etmek için Ordinary Least Squares (OLS) yöntemini kullanıyoruz, benzer şekilde burada da lojistik eğrimizi seçmek için Maximum Likelihood tahminini kullanıyoruz. Lineer regresyonda kullandığımız hipotez formülü: hΘ(x) = β₀ + β₁X Lojistik regresyonda biraz değiştirmemiz gerekiyor. σ(Z) = σ(β₀ + β₁X) Z = β₀ + β₁X hΘ(x) = sigmoid(Z) hΘ(x) = 1/(1 + e^-(β₀ + β₁X) Decision BoundarySınıflandırıcımızın, girdileri bir tahmin fonksiyonundan geçirip 0 ile 1 arasında bir olasılık puanı döndürdüğümüzde olasılığa dayalı bir dizi çıktı veya sınıf vermesini bekliyoruz. Örneğin, 2 sınıfımız var, onları kedi ve köpek gibi alalım (1 - köpek, 0 - kedi). Temel olarak, değerleri Sınıf 1 olarak sınıflandırdığımız ve değerin eşiğin (threshold) altına düştüğü bir eşik değeri ile karar veririz ve ardından bunu Sınıf 2’de sınıflandırırız. Yukarıdaki grafikte gösterildiği gibi eşiği 0.5 olarak seçtik, eğer tahmin fonksiyonu 0.7 değerini döndürdüyse bu gözlemi Sınıf 1 (köpek) olarak sınıflandırdık. Tahminimiz 0,2 değerini döndürdüyse, gözlemi Sınıf 2 (kedi) olarak sınıflandırdık. hθ(x) = g(θ0 + θ1x1 + θ2x2) Örnek olarak;θ0 = -3θ1 = 1θ2 = 1 Yani parametre vektörümüz yukarıdaki değerlere sahip bir sütun vektörüdür. Yani,θT bir satır vektörü = [-3,1,1] Peki, ne anlama geliyor? Buradaki z, θT x olur. Eğer “y = 1” ise bunu tahmin ediyoruz. -3x0 + 1x1 + 1x2 &gt;= 0 -3 + x1 + x2 &gt;= 0 Bunu şu şekilde de yazabiliriz: Eğer (x1 + x2&gt; = 3) ise y = 1’i tahmin ediyoruz. Eğer bunu görselleştirirsek; x1 + x2 = 3 karar sınırımızı(decision boundary) grafik olarak çiziyoruz. Grafikte bu iki bölgeye sahip olduğumuz anlamına gelir. Mavi = Yanlış Pembe = Doğru Çizgi = Karar Sınırı Somut olarak, düz çizgi, tam olarak hθ (x) = 0,5 olan noktalar kümesidir. Karar sınırı, hipotezin bir özelliğidir. Herhangi bir veri olmadan hipotez ve parametrelerle sınır oluşturabileceğimiz anlamına gelir. Daha sonra verileri parametre değerlerini belirlemek için kullanırız. Eğer y=1 5 - x1 &gt; 0 5 &gt; x1 Non-Linear Decision Boundaries Doğrusal olmayan karmaşık bir veri kümesine lojistik regresyon uygulayalım. Polinom regresyonu gibi daha yüksek mertebeden terimler ekleyelim. Öyleyse sahip olduğumuz hipotezimiz şöyle olur; Θ vektörünün transpozu ile giriş vektörünü çarpıyoruz. ΘT [-1,0,0,1,1] “Y = 1” olan durumu tahmin edelim. Bu bize yarıçapı 1, 0 civarında olan bir daire verir. Bu (görece) basit hipoteze karmaşık parametreleri yerleştirerek daha karmaşık karar sınırları oluşturabileceğimiz anlamına gelir. Daha karmaşık karar sınırları? Daha yüksek dereceden polinom terimleri kullanarak daha da karmaşık karar sınırları elde edebiliriz. Cost Function (J(θ))Lineer Regresyonda cost fonksiyonu; Cost function optimizasyon hedefini temsil ediyor, yani bir maliyet fonksiyonu oluşturuyor ve minimum hatayla doğru bir model geliştirebilmemiz için bunu en aza indiriyoruz. Lojistik regresyon için cost fonksiyonu ; Sonucu bize konveks olmayan sonuç verecektir. Global minimuma ulaşmaya çalışan Gradiyen Descent için lokal optimada kalan bu sonuç büyük bir problem verecektir. −log(hθ(x)) eğer y = 1 −log(1−hθ(x)) eğer y = 0 Bu tek bir örneğin cost fonksiyonudur. İkili sınıflandırma problemleri için y her zaman 0 veya 1’dir Bu nedenle, maliyet fonksiyonunu yazmanın daha basit bir yolunu bulabiliriz.θ parametreleri için maliyet fonksiyonumuz şu şekilde tanımlanabilir: Diğer maliyet fonksiyonları varken neden bu fonksiyonu seçiyoruz? Bu cost fonksiyonu, maksimum olasılık tahmini(maximum likehood estimation) ilkesi kullanılarak istatistiklerden türetilebilir. Bunun, özelliklerin dağıtımıyla ilgili temel bir Gauss varsayımı olduğu anlamına geldiğini unutmayın. Dışbükey olması da güzel bir özelliğe sahiptir. Parametreleri sığdırmak için θ: J (θ) ‘yı en aza indiren θ parametreleri bulunur. Bu, modelimizde gelecekteki tahminler için kullanacağımız bir dizi parametremiz olduğu anlamına gelir. Ardından, x özellik kümesiyle yeni bir örnek verilirse, oluşturduğumuz θ’yı alabilir ve tahminimizi çıkarabiliriz. Lojistik regresyon’da cost fonksiyonu nasıl en aza indirilir? J (θ) ‘yi nasıl minimize edeceğimizi bulmalıyız.Gradient Descenti eskisi gibi kullanacağız.Bir öğrenme oranı (learning rate) kullanarak her parametre tekrar tekrar güncellenir. Eğer n feature olsaydı, θ vektörünüz için n + 1 sütun olurdu. Bu denklem, doğrusal regresyon kuralı ile aynıdır.Tek fark, hipotez tanımımızın değişmiş olmasıdır. Gradient descent lojistik regresyon için aynı şeyi burada yapabilir. Gradyan inişli lojistik regresyon uygularken, tüm θ değerlerini (θ0’dan θn’ye) aynı anda güncellemeliyiz Bir for döngüsü kullanabilir. Vektörize bir uygulama daha iyi olur. Lojistik regresyon için gradyan inişi için özellik ölçeklendirme(feature scaling) burada da geçerlidir. Advanced Optimization Daha önce maliyet fonksiyonunu en aza indirmek için gradyan inişine bakmıştık. Lojistik regresyon için maliyet fonksiyonunu en aza indirmek için gelişmiş kavramlara bakalım. Büyük makine öğrenimi problemleri için iyidir (ör. Çok büyük feature seti) Gradyan inişi aslında ne yapıyor? Diyelim ki maliyet fonksiyonumuz J (θ) var ve bunu en aza indirmek istiyoruz. Girdi olarak θ alabilen ve aşağıdakileri hesaplayabilen bir kod yazmalıyız. J (θ) J’ye göre J (θ) ise kısmi türev (burada j = 0 ila j = n) Bu iki şeyi yapabilen kod verildiğinde; Gradyan inişi, aşağıdaki güncellemeyi tekrar tekrar yapar. Yani her j içindeki θ sırayla güncellenir. (θ) ve türevlerini hesaplamak için kod yazılır. Sonra bu değerleri gradyan inişine konur. Alternatif olarak, maliyet(cost) fonksiyonunu en aza indirmek için Conjugate gradient BFGS (Broyden-Fletcher - Goldfarb-Shanno) L-BFGS (Limited Memory - BFGS)gradyan inişi yerine kullanabilir. Bunlar, aynı girdiyi alan ve maliyet fonksiyonunu en aza indiren daha optimize edilmiş algoritmalardır.Bunlar çok karmaşık algoritmalardır. Avantajlar Manuel olarak alfa (öğrenme oranı) seçmeye gerek yok. Bir grup alfa değerini deneyen ve iyi bir tane seçen akıllı bir iç döngüye (line search algoritması) sahiptir. Genellikle gradyan inişinden daha hızlıdır. İyi bir öğrenme oranı seçmekten fazlasını yapar. Karmaşıklıklarını anlamadan başarıyla kullanılabilir. Dezavantajlar Hata ayıklamayı daha zor hale getirebilir. Kendileri uygulanmamalıdır. Farklı kitaplıklar farklı uygulamalar kullanabilir. Performansı etkileyebilir. Multiclass classification problemsLojistik regresyonda birden fazla sınıf olduğunda one vs. all tekniği kullanılır. Multiclass - evet veya hayır(1 veya 0)’dan fazlasıdır. Üç sınıflı bir veri kümesi verildiğinde, bir öğrenme algoritmasının çalışmasını nasıl sağlayabiliriz? Tüm sınıflandırmaya karşı birini kullanıp, ikili sınıflandırmayı çok sınıflı sınıflandırma için çalışır hale getiririz. One vs. all classification Eğitim setini üç ayrı ikili sınıflandırma problemine bölebiliriz. Yeni sahte bir trainning set oluşturup Üçgenler(1) vs çarpılar ve kareler(o) hθ1(x) P(y=1 | x1; θ) Kareler(1) vs üçgen ve çarpılar (o) hθ2(x) P(y=1 | x2; θ) Çarpılar (1) vs üçgen and kareler (o) hθ3(x) P(y=1 | x3; θ) y = i olasılığını tahmin etmek için her i sınıfı için bir lojistik regresyon sınıflandırıcı hθ (i) (x) eğitilir. Yeni bir girdide, x tahmin yapmak için, hθ (i) (x) = 1 olasılığını en üst düzeye çıkaran i sınıfı seçilir.","link":"/Classification/"},{"title":"Artificial Neural Networks","text":"Yapay Sinir Ağları, günümüzün en popüler makine öğrenimi algoritmalarıdır. Bu sinir ağlarının icadı 1970’lerde gerçekleşti, ancak şu anda neredeyse her yerde bulundukları için hesaplama gücündeki son artış nedeniyle büyük popülerlik elde ettiler. Kullandığınız her uygulamada, sinir ağları güçlü bir arayüzle bağlanmanızı sağlar. İlk nörobilgisayarın mucidi Dr. Robert Hecht-Nielsen bir sinir ağını şu şekilde tanımlar: “… bilgileri harici girdilere dinamik durum tepkileri ile işleyen, basit, birbiriyle son derece bağlantılı işleme öğelerinden oluşan bir bilgi işlem sistemi.” Basic Structure of Artificial Neural Networks (ANNs)ANN fikri, insan beyninin doğru bağlantıları yaparak çalışmasının, canlı nöron ve dendrit olarak silikon ve teller kullanılarak taklit edilebileceği inancına dayanmaktadır. İnsan beyni, nöron adı verilen 86 milyar sinir hücresinden oluşur. Aksonlar tarafından diğer bin hücreye bağlanırlar. Dış çevreden gelen uyarılar veya duyu organlarından gelen girdiler dendritler tarafından kabul edilir. Bu girdiler, sinir ağında hızla dolaşan elektrik uyarıları yaratır. Bir nöron daha sonra mesajı başka bir nörona gönderebilir veya iletiyi iletmez.ANN’ler, insan beyninin biyolojik nöronlarını taklit eden çoklu düğümlerden oluşur. Nöronlar bağlantılarla bağlıdır ve birbirleriyle etkileşime girerler. Düğümler giriş verilerini alabilir ve veriler üzerinde basit işlemler gerçekleştirebilir. Bu işlemlerin sonucu diğer nöronlara aktarılır. Her düğümdeki çıktıya aktivasyon veya düğüm değeri denir. Her bağlantı ağırlık ile ilişkilidir. ANN’ler, ağırlık değerlerini değiştirerek gerçekleşen öğrenme yeteneğine sahiptir. Aşağıdaki şekilde basit bir ANN gösterilmektedir. Yapay Sinir Ağları, insan beyninden sonra modellenen özel bir makine öğrenme algoritması türüdür. Yani tıpkı sinir sistemimizdeki nöronların geçmiş verilerden nasıl öğrenebildikleri gibi ANNs de verilerden öğrenip tahminler veya sınıflandırmalar şeklinde yanıtlar verebilir. Görüntü tanıma, konuşma tanıma, makine çevirisi ve tıbbi teşhis gibi çeşitli görevler bu yapay sinir ağlarını kullanır. ANNs’lerin önemli bir avantajı, örnek veri setlerinden öğrenmesidir. ANNs’lerin en yaygın kullanımı, rastgele fonksiyon yaklaşımıdır. Bu tür araçlarla, dağıtımı tanımlayan çözümlere ulaşmak için uygun maliyetli bir yöntem elde edilebilir. ANNs ayrıca çıktı sonucunu sağlamak için tüm veri kümesinden ziyade örnek verileri alabilir. ANNS ile, gelişmiş tahmin yetenekleri sayesinde mevcut veri analizi teknikleri geliştirilebilir. Yapay Sinir Ağlarının işleyişi, sinir sistemimizde nöronların çalışma şekline benzer. Sinir Ağları, Warren S McCulloch ve Walter Pitts’in bu terimi icat ettiği 1970’lerin başlarına kadar uzanıyor. ANN’lerın işleyişini anlamak için önce nasıl yapılandırıldığını anlayalım. Bir sinir ağında üç temel katman vardır. Input LayersGiriş katmanı(input layer), giriş bilgilerini çeşitli metinler, sayılar, ses dosyaları, görüntü pikselleri vb. biçiminde alan bir ANN’nın ilk katmanıdır. Hidden LayersANN modelinin ortasında gizli katmanlar(hidden layer) bulunur. Algılayıcı veya birden çok gizli katman durumunda olduğu gibi tek bir gizli katman olabilir. Bu gizli katmanlar, giriş verileri üzerinde çeşitli matematiksel hesaplamalar gerçekleştirir ve parçası olan kalıpları tanır. Output LayerÇıktı katmanında(output layer), orta katman tarafından yapılan titiz hesaplamalarla elde ettiğimiz sonucu elde ederiz. Bir sinir ağında, modelin performansını etkileyen çok sayıda parametre ve hiperparametre vardır. ANNs çıktıları çoğunlukla bu parametrelere bağlıdır. Bu parametrelerden bazıları weight, bias, learning rate, batch size vb .’dir. ANNS’deki her düğümün bir ağırlığı(weight) vardır. Ağdaki her düğümün kendisine atanmış bazı ağırlıkları vardır. Girişlerin ve sapmanın ağırlıklı toplamını hesaplamak için bir transfer fonksiyonu kullanılır. Transfer fonksiyonu toplamı hesapladıktan sonra, aktivasyon fonksiyonu sonucu alır. Alınan çıktıya bağlı olarak, etkinleştirme işlevleri düğümden uygun sonucu ateşler. Örneğin, alınan çıktı 0.5’in üzerindeyse, aktivasyon işlevi 1’i ateşler, aksi takdirde 0 kalır. Yapay Sinir Ağlarında kullanılan popüler aktivasyon işlevlerinden bazıları Sigmoid, RELU, Softmax, tanh vb. Düğümün ateşlediği değere bağlı olarak, son çıktıyı elde ederiz. Ardından, hata işlevlerini kullanarak, tahmin edilen çıktı ile ortaya çıkan çıktı arasındaki tutarsızlıklarını hesaplıyoruz ve geri yayılım(back propagation) olarak bilinen bir işlemle sinir ağının ağırlıklarını ayarlıyoruz. ANNs, Derin Öğrenme olarak bilinen Makine Öğreniminde yeni ortaya çıkan bir alanın parçasıdır. Back Propagation in Artificial Neural NetworksBir sinir ağını eğitmek için, ona girdi-çıktı eşleme örnekleri veriyoruz. Son olarak, sinir ağı eğitimi tamamladığında, bu haritalamaları sağlamadığımız sinir ağını test ediyoruz. Sinir ağı çıktıyı tahmin eder ve çeşitli hata fonksiyonlarını kullanarak çıktının ne kadar doğru olduğunu değerlendiririz.Sonuca göre model zincir kuralı üzerinden gradyan inişini takiben ağı optimize etmek için sinir ağlarının ağırlıklarını ayarlar. Types of Artificial Neural Networksİki önemli Yapay Sinir Ağı türü vardır: FeedForward Neural Network FeedBack Neural Network FeedForward Neural Networksİleri beslemeli(FeedForward) ANN’lerde, bilgi akışı yalnızca bir yönde gerçekleşir. Yani, bilgi akışı girdi katmanından gizli katmana ve son olarak çıktıya doğrudur. Bu sinir ağında hiçbir geri bildirim döngüsü yoktur. Bu tür sinir ağları çoğunlukla sınıflandırma, görüntü tanıma vb. durumlar için denetimli öğrenmede(supervised learning) kullanılır. Bunları, verilerin doğası gereği sıralı olmadığı durumlarda kullanırız. FeedBack Neural NetworkGeri besleme(FeedBack) ANN’lerde, geribildirim döngüleri bunun bir parçasıdır. Bu tür sinir ağları, Yinelenen Sinir Ağları(Recurrent Neural Networks(RNN) durumunda olduğu gibi, esas olarak bellek tutma içindir. Bu tür ağlar, verilerin sıralı veya zamana bağlı olduğu alanlar için en uygun olanıdır. Machine Learning in ANNsANNs’ler öğrenme yeteneğine sahiptir ve eğitilmeleri gerekir. Birkaç öğrenme stratejisi var. Supervised Learning - ANNs’lerin kendisinden daha bilgili olan bir öğretmeni içerir. Örneğin, öğretmen, öğretmenin cevapları zaten bildiği bazı örnek veriler ile verileri besler. Örneğin, örüntü tanıma(pattern recognizing). ANN, tanıma yaparken tahminlerle gelir. Sonra öğretmen ANN’ye cevapları sağlar. Ağ daha sonra tahminlerini öğretmenin “doğru” yanıtlarıyla karşılaştırır ve hatalara göre ayarlamalar yapar. Unsupervised Learning Bilinen yanıtlarla örnek veri kümesi olmadığında gereklidir. Örneğin, gizli bir örüntü aramak için kullanılır. Bu durumda, kümeleme, yani bir dizi öğeyi bilinmeyen bir modele göre, mevcut veri kümelerine dayalı olarak gruplara ayırma gerçekleştirilir. Reinforcement Learning Bu strateji gözlem üzerine inşa edilmiştir. ANN, çevresini gözlemleyerek bir karar verir. Gözlem olumsuz ise ağ, bir dahaki sefere farklı bir gerekli kararı verebilmek için ağırlıklarını ayarlar. Back Propagation AlgorithmEğitim veya öğrenme algoritmasıdır. Verilen örneklerden öğrenir. Algoritmaya ağın ne yapmasını istediğinize dair bir örnek gönderirseniz, ağın ağırlıklarını değiştirir, böylece eğitimin bitiminde belirli bir girdi için istenen çıktıyı üretebilir. Back Propagation ağları basit Pattern Recognition ve Mapping Tasks için idealdir. Bayes NetworksBu tür sinir ağları, olasılığı hesaplamak için Bayesian Çıkarımını kullanan olasılıklı bir grafik modele sahiptir. Bu tür Bayes Ağları, Belief Ağları olarak da bilinir. Bu Bayes Ağlarında, bu tür rastgele değişkenler arasında bulunan olasılık bağımlılıkları temsil eden düğümleri birbirine bağlayan kenarlar vardır. Etkinin yönü öyledir ki, bir düğüm diğerini etkiliyorsa, o zaman aynı etki çizgisine düşerler. Her düğümle ilişkili olasılık, ilişkinin gücünü belirler. İlişkiye dayalı olarak, grafikteki rastgele değişkenlerden çeşitli faktörlerin yardımıyla çıkarım yapılabilir. Bu ağların uyması gereken tek kısıtlama, yönlendirilmiş yaylar üzerinden düğüme geri dönememesidir. Bu nedenle, Bayes Ağları Directed Acyclic Graphs (DAGs) olarak anılır. Bu Bayes Ağları, çok değerli değişkenleri idare edebilir ve iki boyuttan oluşur. Range of Prepositions Her preposition’nın atanmış olma olasılığı. Sonlu kümenin her değişkeni X = {x1, x2… xn} ile gösterilecek ve her X değişkeni, Değer {x1} olacak şekilde sonlu kümede bulunan değerlerden alacak şekilde sonlu bir rastgele değişkenler kümesi olduğunu varsayalım. Xi değişkeninden Xj değişkenine yönlendirilmiş bir bağlantı varsa, Xi, Xj’nin bu değişkenler arasındaki doğrudan bağımlılıkları gösteren ebeveyni olacaktır. Bayesian Networks’ün yardımıyla, önceki bilgilerle birlikte gözlemlenen veriler birleştirilebilir. Bayes Ağları temel olarak nedensel ilişkileri öğrenmek ve ayrıca alan bilgisini anlayıp gelecekteki olayı tahmin etmek için kullanılır. Bu, eksik veri durumunda bile gerçekleşir. Sinir Ağlarının Avantajları ve DezavantajlarıMakine Öğrenimi için Yapay Sinir Ağının birkaç avantajını ve dezavantajını görelim: Sinir ağları, doğrusal ve doğrusal olmayan verilerle iyi performans gösterir, ancak sinir ağlarının, özellikle robotikte yaygın bir eleştirisi, gerçek dünya operasyonları için çok çeşitli eğitim gerektirmeleridir. Bunun nedeni, herhangi bir öğrenen makinenin yeni vakalara genellemesine izin veren temel yapıyı yakalamak için yeterli temsili örneklere ihtiyaç duymasıdır. Sinir ağları, bir veya birkaç birim ağa yanıt vermede başarısız olsa bile çalışır, ancak büyük ve etkili yazılım sinir ağları uygulamak için, çok sayıda işleme ve depolama kaynağının işlenmesi gerekir. Beyin, bir nöron grafiği aracılığıyla sinyalleri işleme görevine göre uyarlanmış donanıma sahipken, Von Neumann teknolojisinde en basitleştirilmiş bir formu simüle etmek bile bir sinir ağı tasarımcısını bağlantıları için milyonlarca veritabanı satırını doldurmaya zorlayabilir - bu da çok miktarda tüketebilir bilgisayar belleği ve sabit disk alanı. Sinir ağı, analiz edilen verilerden öğrenir ve yeniden programlamaya ihtiyaç duymaz ancak bunlara kara kutu(black box) modelleri denir ve bu modellerin gerçekte ne yaptığına dair çok az fikir verir. Kullanıcının sadece girdiyi beslemesi ve eğitmesini izlemesi ve çıktıyı beklemesi gerekir.","link":"/ANN/"},{"title":"Debugging Learning Algorithm","text":"Makine öğrenimi modelimizi verilere uydurduktan sonra ne yapmalıyız? Açıkçası, onu değerlendirmemiz ve çalışıp çalışmadığını anlamamız ve özellikle son durumda, iyileştirmek için bazı değişiklikler yapmamız gerekiyor. Makine öğrenimi eğitimi sırasında daha iyi veri yakalama, gerçek zamanlı izleme ve zamanında müdahale ile zamandan ve maliyetlerden tasarruf etmemize yardımcı olacaktır. Evaluating Error of the ModelModelimizi oluşturmak için aşağıdaki görselde regülarizasyon yapılmış cost fonksiyon formülünü incelenirse: Doğrusal bir regresyon modelimiz olduğunu ve müşterimizin ürünlerinin satışını tahmin etmek istediğimizi varsayalım. Peki ya modelimiz çalışmazsa ya da biz de onun performansını iyileştirmek istiyorsak? Pekala, farklı yaklaşımlar deneyebiliriz, örneğin: Modele daha fazla eğitim verisi eklenebilir. → (Yüksek Varyans’ı düzeltir) Daha küçük bir feature seti kullanılabilir → ( Yüksek Bias’ı düzeltir) Ek feature örnekleri eklenebilir. → (Yüksek Bias’ı düzeltir) Polinom derecesi yükseltilebilir. → (Yüksek Bias’ı düzeltir.) Regularizasyon katsayısı(ƛ) arttırılabilir. → (Yüksek Varyans’ı düzeltir.) Regularizasyon katsayısı1 azaltılabilir. → (Yüksek Bias’ı düzeltir.) Elbette olasılıklardan biri, farklı parametrelerle rastgele farklı yaklaşımları denemek ve sonucu kontrol etmektir, ancak daha fazla veri elde etmek için büyük çaba gerektiren bazı değişiklikler yaparsak, özellikle zaman kaybı olabilir. Daha fazla veri elde ettikten sonra modelimizin performansının değişmediğini görürsek? Hangi yolu seçmenin daha iyi olduğunu anlamamıza yardımcı olabilecek bazı değerlendirme veya teşhis yöntemlerimiz var. Machine Learning DiagnosticÖnyargı(Bias): Bir işlevin öğrenilmesini kolaylaştırmak için bir model tarafından yapılan varsayımlar.Varyans(Variance): Verilerinizi eğitim verileri üzerinde eğitip ve çok düşük bir hata alırsanız, verileri değiştirdikten sonra aynı modeli değiştirdiğiniz verilerle eğittikten sonra yüksek hata ile karşılaşırsanız, bu varyanstır. Yüksek varyans: Bu sorun, algoritma eğitim verilerine mükemmel bir şekilde uyduğunda ortaya çıkacaktır. Başka bir deyişle, bu, modelin genelleme konusunda kötü olduğu anlamına gelir. Tahmin edilebileceği gibi, bu model görünmeyen veriler üzerinde kötü performans gösterecektir. Bu soruna aşırı uyum( overfitting) da denir. Genelleme hatası, modeliniz için önceden görülmemiş veriler üzerinde ölçülen hatadır. Yüksek sapma: Bu sorun, algoritma eğitim verilerini doğru şekilde uydurmadığında ortaya çıkar. Başka bir deyişle, bu, modelin girdi özellikleri ve tahmin edilen çıktı arasındaki ilgili ilişkileri kaçırdığı anlamına gelir. Tahmin edilebileceği gibi, bu model eğitim verilerinin kendisinde ve görünmeyen verilerde kötü performans gösterecektir. Bu soruna yetersiz uyum(high bias) da denir. Eğitim hatası, modelinizi eğitmek için kullanılan verilerde ölçülen model hatasıdır. UnderfittingBir istatistiksel modelin veya bir makine öğrenme algoritmasının, verilerin temelindeki eğilimi yakalayamadığında yetersiz olduğu söylenir. Yetersiz uyum(underfitting), makine öğrenimi modelimizin doğruluğunu yok eder. Oluşması, modelimizin veya algoritmanın verilere yeterince uymadığı anlamına gelir. Genellikle doğru bir model oluşturmak için daha az veriye sahip olduğumuzda ve ayrıca doğrusal olmayan verilerle doğrusal bir model oluşturmaya çalıştığımızda olur. Bu gibi durumlarda, makine öğrenimi modelinin kuralları bu kadar minimal verilere uygulanamayacak kadar kolay ve esnektir ve bu nedenle model muhtemelen çok sayıda yanlış tahmin yapacaktır. Daha fazla veri kullanılarak ve özellik seçimi ile özellikleri azaltarak yetersiz uyum önlenebilir. Yetersiz uyumu azaltma teknikleri: Model karmaşıklığını artırın Feature Engineering yaparak özelliklerin sayısını artırın Verilerden gürültüyü kaldırın. Daha iyi sonuçlar elde etmek için epoch sayısını artırın veya eğitim süresini artırın. OverfittingÇok fazla veriyle eğittiğimizde istatistiksel bir modelin gereğinden fazla uygun(overfitting) olduğu söylenir. Bir model bu kadar çok veriyle eğitildiğinde, veri setimizdeki gürültü ve hatalı veri girişlerinden öğrenmeye başlar. O zaman model, çok fazla ayrıntı ve gürültü nedeniyle verileri doğru bir şekilde kategorize etmez. Aşırı uyumluluğun nedenleri parametrik olmayan ve doğrusal olmayan yöntemlerdir çünkü bu tür makine öğrenme algoritmaları modeli veri setine dayalı olarak oluşturmada daha fazla özgürlüğe sahiptir ve bu nedenle gerçekten gerçekçi olmayan modeller oluşturabilirler. Aşırı uyumu önlemek için bir çözüm, doğrusal verilerimiz varsa doğrusal bir algoritma kullanmak veya karar ağaçları kullanıyorsak maksimum derinlik gibi parametreleri kullanmaktır. Aşırı uyumu azaltma teknikleri: Eğitim verilerini artırın. Model karmaşıklığını azaltın. Eğitim aşaması sırasında erken durma (eğitim başlar başlamaz eğitim süresi boyunca kaybı gözden geçirin eğer kayıp artmaya başlarsa eğitimi durdurun). Ridge Regülarizasyonu ve Lasso Regülarizasyonu uygulayın. Aşırı uyumluluğun üstesinden gelmek için sinir ağlarını kullanın. Just FitAslında modelin 0 hata ile tahmin yapması durumunda verilere iyi uyduğu söylenir. Bu durum, aşırı uydurma(overfitting) ile yetersiz uydurma(underfitting) arasındaki bir noktada elde edilebilir. Bunu anlamak için, eğitim veri setinden öğrenirken modelimizin performansına zamanın geçişiyle bakmamız gerekecek. Zaman geçtikçe modelimiz öğrenmeye devam edecek ve böylece modelin eğitim ve test verilerindeki hatası azalmaya devam edecektir. Çok uzun süre öğrenecek olursa, model gürültü ve daha az kullanışlı ayrıntıların varlığı nedeniyle fazla takılmaya daha yatkın hale gelecektir. Dolayısıyla modelimizin performansı düşecektir. İyi bir uyum elde etmek için, hatanın artmaya başladığı bir noktada duracağız. Bu noktada, modelin eğitim veri kümeleri ve henüz görülmemiş test veri kümemiz konusunda iyi becerilere sahip olduğu söylenebilir. Başlangıçta verileri iki bölüme ayırmak iyi fikirdir; birincisi modelin eğitimi için kullanılacak ve ikincisi test için kullanılacak. Bu çok kullanışlıdır, özellikle eğitim için modelin doğruluğunun çok yüksek olacağı, test bize modelin o kadar mükemmel olmadığını söyleyecektir. Yani temelde 70 / 30’u böldük: eğitim seti (genellikle% 70) test seti (genellikle% 30) Bu bölünme ile, bir hata değeri ile maliyet fonksiyonumuzu en aza indiren eğitim setine dayalı bir model oluşturabiliriz (bu daha iyi çalışacaktır çünkü model, test setinin verilerinden etkilenmeyecektir). Modelimizi oluşturduktan sonra, tahminler ve gerçek değerler arasındaki tutarsızlıklara dayanarak hatayı hesaplayan modelin tahminini kullanarak hatayı test seti ile değerlendireceğiz. Model Selection ProblemVerilere daha iyi uyması için doğru derece polinom nasıl seçilir (doğrusal, ikinci dereceden, kübik….)?D parametresine (bu, polinomun derecesi olacaktır) dayalı olarak farklı modelleri hesaplayabilir ve her biri için test setindeki değer hatasını ölçebilir, daha iyi performans gösteren modeli seçebiliriz (minimum hata). Bu durumda verilerimizi 3 kısma ayırabiliriz: Eğitim Seti (genellikle% 60) Çapraz Doğrulama Seti(Cross Validation ) - CV (genellikle% 20) Test Seti (genellikle% 20) Modeli eğitim setimiz ile uyumlu hale getiriyoruz. Ardışık olarak, çapraz doğrulama seti adı verilen ikinci bir veri setindeki gözlemlere yönelik tepkileri tahmin etmek için uyumlu model kullanılır.Çapraz Doğrulama seti(Cross Validation Set), modelin hiperparametrelerini ayarlarken eğitim veri setine uyan bir modelin tarafsız bir değerlendirmesini sağlar; bu durumda hiperparametreler, polinom dereceleridir.Hiperparametreler ayarlanınca, Test Seti nihai modelin bir değerlendirmesini sağlamak için kullanılır.Modelimizde değiştirilecek şeyleri seçmemize yardımcı olacak modelimiz için dikkate alınması gereken önemli bir husus, Bias ve Varyans’tır.Farklı polinom derecelerine sahip aynı verilere farklı modeller uydurmanın bir örneğini aşağıdaki görselde görebiliriz. Polinom 1. derecede, sonuç yetersiz uyuyor(underfitting) (Yüksek Bias), polinom 4. derece ile sonuç aşırı uyuyor(overfitting) (Yüksek Varyans) Learning Curves Bu grafikleri birkaç m değeri için (1’den tüm eğitim setine kadar) oluşturduğumuzda, bize modelimizin problemlerini açıkça gösteren Öğrenme Eğrileri(Learning Curves) elde ederiz. Modelimiz yüksek önyargıdan(bias) muzdaripse, JTR ve JVAL, m büyüdükçe çok yakın sonuçlanacak, ancak oldukça büyük bir hata değerine yakınsayacaklar. Bu davranış, yüksek önyargının bir göstergesidir çünkü JTR bile büyük eğitim veri kümeleri için büyüktür. Aslında, aynı zamanda düşük bir varyans durumu ortaya çıkarır. Çünkü tamamen farklı bir setle (validation) değerlendirirken bile hata çok fazla değişmez. Daha fazla veri almanın hatayı azaltmaya yardımcı olmayacağını unutmayın. Modelimiz yüksek varyanstan muzdaripse, JTR ve JVAL m büyüdükçe yaklaşacaktr. Bu, iki çizgi arasındaki boşluk nedeniyle , çünkü çizgilerin nihayetinde birleştiği görünen hata değerinin küçük olduğunu gösterir. Bu durumda, hata çizgileri sonunda daha büyük m değerleri için birleşeceğinden, daha fazla veri almak iyi bir seçenek gibi görünmektedir. Artık modelimizin probleminin (yüksek önyargı veya yüksek varyans) farkındayız, bundan sonra ne yapabiliriz? Sahip olduğunuz veriler için çok karmaşık olduğu için yüksek varyansa (overfits) sahipse: Model karmaşıklığına daha iyi uyması için daha fazla eğitim verisi alın Bazı özellikleri kaldırarak modeli basitleştirin Düzenlilik(Regülarizasyon) faktörünü artırarak modeli yumuşatın Model, sahip olduğunuz veriler için çok basit olduğu için yüksek önyargıya (underfits) sahipse: Daha karmaşık bir model oluşturmak için daha fazla özellik edinin (lojistik regresyon veya K-en yakın komşu gibi doğrusal olmayan modeller kullanılarak uygulanabilir.) Düzenleme(Regülarizasyon) faktörünü azaltarak modeli keskinleştirin Örneğin bir eğitim(trainning) setine tek bir gizli katmana(hidden layer) sahip bir sinir ağı fit ettiğimizi varsayalım. JVAL değerinin JTR değerinden yüksek çıktığını görürsek ne yapmalıyız? Bir gizli katman daha eklememiz problemimizi çözer mi? Hayır, çünkü modelimiz yüksek varyans problemi yaşıyor ve gizli katman sayısı arttırmak çözüm olmayacaktır. Regülarizasyon kat sayısını(ƛ) arttırmak problemi çözmeye yarar. Model Evaluation MetricsSadece makine öğreniminde değil, genel hayatta özellikle iş hayatında da “Ürününüz ne kadar doğru?” veya “Makineniz ne kadar hassas?” gibi sorular duyacaksınız. İnsanlar “Alanındaki en doğru ürün bu!” veya “Bu makine akla gelebilecek en yüksek hassasiyete sahip!”, her iki yanıtla kendilerini rahat hissediyorlar. Değil mi? Aslında, doğru ve kesin terimler çoğu zaman birbirinin yerine kullanılır. Metinde daha sonra kesin tanımlar vereceğiz, ancak kısaca şunu söyleyebiliriz: Accuracy, bazı ölçümlerin belirli bir değere yakınlığı için bir ölçü iken, precision, ölçümlerin birbirine yakınlığıdır. Bu terimler, Makine Öğreniminde de son derece önemlidir. Makine öğrenimi algoritmalarını değerlendirmek veya sonuçlarını daha iyi hale getirmek için onlara ihtiyacımız var. Dört önemli ölçüm vardır. Bu ölçümler, sınıflandırmaların sonuçlarını değerlendirmek için kullanılır. Ölçümler şunlardır: Accuracy Precision Recall F1-Score Bunlara geçmeden önce Type I ve Type II hatalarını bilmek gerekiyor. Type I hatası , Yanlış pozitif(False Positive) ile eşdeğerdir. Type II hatası, Yanlış negatife eşdeğerdir. Type I hatası, kabul edilmesi gereken hipotezin kabul edilmemesini ifade eder. Type II hata, reddedilmesi gereken hipotezin kabul edilmesidir. Bir Biyometri örneği alalım. Birisi parmaklarını biyometrik tarama için taradığında, Type I hatası, yetkili bir eşleşme olsa bile reddedilme olasılığıdır. Type II hatası, yanlış / yetkisiz bir eşleşmeyle bile kabul olasılığıdır. Senaryo / Problem 1: Kansere çare olan bir ilaç için tıbbi denemeler Type I hatası: Durum olmadığında bir tedavi bulunduğunu tahmin etme. Type II hatası: Aslında durum söz konusu olduğunda bir tedavinin bulunamayacağını tahmin etmek. Bu durumda Type I hatası bir sorun değildir. Daha sonra daha fazla denemeyle düzeltilebilir. Type II hatası daha ciddidir, çünkü hiçbir tedavisi yoktur ve bir tedavi milyonlarca hayatı kurtarabilir. Senaryo / Problem İfadesi 2: Bir köprünün yapım modeli doğrudur. Type I hatası: Modelin doğru olmadığında doğru olduğunu tahmin etme. Type II hatası: Bir modelin doğru olduğunda doğru olmadığını tahmin etme. Bu durumda Type I hatası büyük bir risktir. Hatalı olan ve köprünün çökmesine neden olabilecek köprünün inşası anlamına gelebilir. Daha fazla modelden geçip yine de doğru olanı bulabildiğimiz için Type II hatası daha az risklidir. 1. AccuracyDoğruluk(Accuracy), ölçümlerin belirli bir değere yakınlığı için bir ölçüdür. 2.PrecisionKesinlik(Precision) ise ölçümlerin birbirine yakınlığıdır, yani belirli bir değere değil. Başka bir deyişle: Aynı miktarda tekrarlanan ölçümlerden bir dizi veri noktasına sahipsek, ortalamaları ölçülen miktarın gerçek değerine yakınsa setin doğru olduğu söylenir. Öte yandan, değerler birbirine yakınsa kümeyi kesin olarak adlandırıyoruz. İki kavram birbirinden bağımsızdır; bu, veri setinin doğru veya kesin olabileceği veya her ikisinin birden olabileceği veya hiçbirinin olamayacağı anlamına gelir. Bunu aşağıdaki diyagramda gösteriyoruz: Confusion MatrixBir sınıflandırıcının performansını görselleştirmek için bir sürekli tablo veya hata matrisi olarak da adlandırılan bir confusion matrix kullanılır. Matrisin sütunları, tahmin edilen sınıfların örneklerini temsil eder ve satırlar gerçek sınıfın örneklerini temsil eder. (Not: Bunun tam tersi de olabilir.) İkili sınıflandırma durumunda, tabloda 2 satır ve 2 sütun vardır. Konsepti bir örnekle göstermek istiyoruz. Misal:Bu, sınıflandırıcının 42 durumda bir kediyi doğru şekilde tahmin ettiği ve 8 kedi örneğini köpek olarak yanlış tahmin ettiği anlamına gelir. Köpek olarak 32 örneği doğru bir şekilde tahmin etti. 18 vaka yanlışlıkla köpek yerine kedi olarak tahmin edilmiş. Doğruluk(Accuracy), bir sınıflandırıcı tarafından yapılan doğru tahminlerin (hem True Posistives (TP) hem de True Negatives (TN)) bölümünün, False Positives (FP) dahil sınıflandırıcı tarafından yapılan tüm tahminlerin toplamına bölünmesi olarak tanımlanan istatistiksel bir ölçüdür. Bu nedenle, ikili doğruluğu ölçmenin formülü şöyledir: TP = True positive; FP = False positive; TN = True negative; FN = False negative Şimdi kedi-köpek sınıflandırması sonuçlarının doğruluğunu hesaplayacağız. “True” ve “False” yerine burada “cat” ve “dog” görüyoruz. Accuracy şu şekilde hesaplayabiliriz: 12345678TP = 42TN = 32FP = 8FN = 18Accuracy = (TP + TN)/(TP + TN + FP + FN)print(Accuracy)0.74 Kesinlik(Precision), doğru olarak tanımlanan pozitif vakaların tahmin edilen tüm pozitif vakalara, yani pozitif olarak tahmin edilen doğru ve yanlış vakalara oranıdır. Precision, sorguyla ilgili alınan belgelerin oranıdır. Formül: 123456TP = 114FP = 14# FN (0) ve TN (12) bu formülde gerekmiyor!precision = TP / (TP + FP)print(f\"precision: {precision:4.2f}\")precision: 0.89 3. RecallDuyarlılık(recall), doğru olarak tanımlanan pozitif vakaların, “False Negatives” ve “True Positives” toplamı olan tüm True Positive vakalara oranıdır. 123456TP = 114FN = 0# FT (14) ve TN (12) bu formülde gerekmiyor!recall = TP / (TP + FN)print(f\"recall: {recall:4.2f}\")recall: 1.00 1 değeri, spam olmayan mesajların yanlışlıkla spam olarak etiketlenmediği anlamına gelir. İyi bir spam filtresi için bu değerin 1 olması önemlidir. 4. F1 ScoreF1 skoru, harmonik ortalamayı kullanarak precision ve recall birleştiren tek metriktir.Son metriğimiz F1 skoru formülü: 12345678910111213141516TP = 42TN = 32FP = 8FN = 18precision = TP / (TP + FP)accuracy = (TP + TN)/(TP + TN + FP + FN)recall = TP / (TP + FN)f1_score = 2 * precision * recall / (precision + recall)print(f\"accuracy: {accuracy:4.2f}\")print(f\"precision: {precision:4.2f}\")print(f\"recall: {recall:4.2f}\")print(f\"f1_score: {f1_score:4.2f}\")accuracy: 0.74precision: 0.84recall: 0.70f1_score: 0.76 Precision ve recall, son derece önemli iki model değerlendirme ölçütüdür. Precision, sonuçlarınıza uygun olanların yüzdesini ifade ederken, recall, algoritmanız tarafından doğru bir şekilde sınıflandırılan toplam alakalı sonuçların yüzdesini ifade eder. Ne yazık ki, her iki metriği aynı anda maksimize etmek mümkün değildir, çünkü biri diğerinin maliyetine sahiptir. Basit olması için, F-1 skoru adı verilen ve precision ve recall’un harmonik bir ortalaması olan başka bir metrik mevcuttur. Hem precision hem de recall’un önemli olduğu problemler için, bu F-1 puanını en üst düzeye çıkaran bir model seçilebilir. Diğer sorunlar için, bir değiş tokuşa ihtiyaç vardır ve precision’nın mı yoksa recall’un mu maksimize edileceğine karar verilmelidir. ROC CurveBir ROC curve (receiver operating characteristic curve), tüm sınıflandırma eşiklerinde bir sınıflandırma modelinin performansını gösteren bir grafiktir. Bu eğri iki parametreyi çizer: True Positive Rate False Positive Rate True Positive Rate (TPR), recall’ın eşanlamlısıdır ve bu nedenle aşağıdaki gibi tanımlanır: False Positive Rate (FPR) aşağıdaki şekilde tanımlanır: Bir ROC eğrisi, TPR’ye karşı FPR’yi farklı sınıflandırma eşiklerinde çizer. Sınıflandırma eşiğini düşürmek için daha fazla öğeyi pozitif olarak sınıflandırır, böylece hem False Positive’ler hem de True Positive’ler artar. Aşağıdaki şekil tipik bir ROC eğrisini göstermektedir. Bir ROC eğrisindeki noktaları hesaplamak için, bir lojistik regresyon modelini birçok kez farklı sınıflandırma eşikleri ile değerlendirebilirdik, ancak bu verimsiz olacaktır. Neyse ki, bu bilgiyi bize sağlayabilen AUC adında verimli, sıralama tabanlı bir algoritma var. AUCAUC(Area Under the ROC Curve), (0,0) ‘dan (1,1)’ e kadar tüm ROC eğrisinin altındaki iki boyutlu alanın tamamını ölçer (integral hesabı düşünün). AUC, tüm olası sınıflandırma eşiklerinde toplu bir performans ölçüsü sağlar. AUC’yi yorumlamanın bir yolu, modelin rastgele bir pozitif örneği rastgele bir negatif örnekten daha yüksek sıralama olasılığıdır. Örneğin, lojistik regresyon tahminlerinin artan sırasına göre soldan sağa düzenlenen aşağıdaki örnekler verildiğinde: AUC, rastgele bir pozitif (yeşil) örneğin rastgele bir negatif (kırmızı) örneğin sağına yerleştirilme olasılığını temsil eder.AUC, 0 ile 1 arasındadır. Tahminleri% 100 yanlış olan bir modelin AUC değeri 0,0; Tahminleri% 100 doğru olan birinin AUC’si 1,0’dır. AUC, aşağıdaki iki nedenden dolayı arzu edilir: AUC, ölçekle değişmez. Kesin değerlerinden ziyade tahminlerin ne kadar iyi sıralandığını ölçer. AUC, sınıflandırma eşiği ile değişmez. Hangi sınıflandırma eşiğinin seçildiğine bakılmaksızın modelin tahminlerinin kalitesini ölçer. Bununla birlikte, bu iki neden de bazı kullanım durumlarında AUC’nin yararlılığını sınırlayabilecek uyarılarla birlikte gelir: Ölçek değişmezliği her zaman arzu edilen bir şey değildir. Örneğin, bazen gerçekten iyi kalibre edilmiş olasılık çıktılarına ihtiyacımız olur ve AUC bize bundan bahsetmez. Sınıflandırma eşiği değişmezliği her zaman arzu edilen bir durum değildir. Yanlış negatiflere karşı yanlış pozitiflerin maliyetinde büyük farklılıklar olduğu durumlarda, bir tür sınıflandırma hatasını en aza indirmek kritik olabilir. Örneğin, e-posta spam tespiti yaparken, muhtemelen false positive’leri en aza indirmeye öncelik vermek istersiniz (bu, false negative’lerde önemli bir artışla sonuçlansa bile). AUC, bu tür optimizasyon için kullanışlı bir ölçüm değildir.","link":"/Algorithm/"},{"title":"Support Vector Machines (SVMs)","text":"Vladimir Vapnik Sovyet Birliği’nden Amerika’ya 1991’ de göç ediyor. Kimse çalışmaları hakkında birşey bilmiyordu. Aslında Ph.D yaparken Moskova’da SVM’leri 1960’lı yılların başında yazmıştı.Ama o zamanlar bilgisayar olmadığı için test edecek imkanı bulamamıştı.Sonraki 25 yıl Sovyet Birliği’nde Onkoloji Enstitüsünde çalıştı bir yandan da başvurular yapıyordu. Bell Labs’ta birileri onu keşfetti ve Amerika’ya davet etti. Sonrasında Amerika’ya taşınan Vapnik 3 makalesini NIPS (Neural Information Processing System) Journal’a gönderdi ve hepsi reddedildi.Hala buna üzgün ama bu onu motive etti. 1992-1993 yıllarında Bell Labs hand-written recognation ile ilgileniyordu. Vapnik neural networkün yetersiz olduğu SVM’lerin bu konuda daha iyi olduğuna dair çalışma arkadaşlarıyla iddiaya girdi. Çalışma arkadaşları bu konuda SVM kernelde n=2 olarak denediler ve sonuç lineer olmayan verileri sınıflandırmada harikaydı. Peki ik defa mı birileri kernel kullandı? Aslında Vapnik tezinde yazmıştı ama bunun önemli olduğunu düşünmemişti. Vapnik kernel fikrini yeniden canlandırdı ve geliştirmeye başladı. Vapnik’in kernelleri anlaması ve bunların önemini takdir etmesi arasında 30 yıl geçti ve işler böyle yürür. Harika fikirlerin ardından hiçbir şeyin olmadığı uzun dönemler gelir. Ardından orjinal fikrin biraz değişimiyle büyük bir güce sahip gibi göründüğü bir aydınlanma anı gelir. 90’ların başına kadar kimsenin adını bile duymadığı Vapnik, bugün makine öğrenmesiyle uğraşan herkesin tanıdığı bir üne kavuştu. Gelin Vapnik’in dünyaya kazandırdığı SVM ve Kernel kavramına yakından bakalım. Support Vector Machines(SVMs)SVM’ler, makine öğrenimi algoritmalarında sınıflandırma için en popüler algoritmadır. SVM’lerin matematiksel arkaplanı, iki sınıf arasındaki geometrik ayrım için temel bloğu oluşturmada mükemmeldir. Destek Vektör Makineleri(SVM), sınıflandırma ve regresyon analizi için verilerin analizini sağlayan bir tür denetimli makine öğrenme algoritmasıdır. Regresyon için kullanılabilirlerse de, SVM çoğunlukla sınıflandırma için kullanılır. N boyutlu uzayda çizim yapıyoruz. Her özelliğin değeri aynı zamanda belirli koordinatın değeridir. Ardından, iki sınıf arasında farklılaşan ideal hiper düzlemi buluyoruz. Bu destek vektörleri, bireysel gözlemlerin koordinat temsilleridir. İki sınıfı ayırmak için bir sınır yöntemidir. Destek vektör makinelerinin çalışmasının arkasındaki temel ilke basittir. Veri kümesini sınıflara ayıran bir hiper düzlem oluşturun. Örnek bir problemle başlayalım. Verilen bir veri kümesi için kırmızı üçgenleri mavi dairelerden sınıflandırmanız gerektiğini varsayalım. Amacınız, verileri iki sınıfa ayıran, kırmızı üçgenler ve mavi daireler arasında bir ayrım oluşturan bir çizgi oluşturmaktır. İki sınıfı birbirinden ayıran net bir çizgi varsayılabilirken, bu işi yapabilecek birçok satır olabilir. Bu nedenle, bu görevi yerine getirebilecek üzerinde anlaşabileceğiniz tek bir satır yoktur. İki sınıf arasında ayrım yapabilen bazı satırları aşağıdaki gibi görselleştirelim: SVM’ye göre, her iki sınıfa da en yakın olan noktaları bulmalıyız. Bu noktalar, destek vektörleri olarak bilinir. Bir sonraki adımda, ayıran düzlemimiz ile destek vektörleri arasındaki yakınlığı buluyoruz. Noktalar ve bölme çizgisi arasındaki mesafe, margin olarak bilinir. Bir SVM algoritmasının amacı, bu marjı maksimize etmektir.Margin maksimuma ulaştığında, hiper düzlem en uygun olanı olur. Pekala bu marjini adım adım hesaplamaya başlayalım. Görselde olduğu gibi (+) ve (-) leri ayırmamız gerekiyor böylece Decision Boundary çizmemizi sağlayacak eğrimizi bulabiliriz. Gutter denilen aslında görselde caddeye benzeyen şekle dik olan veya şeklin medyanına doğru giden uzunluğunu bilmediğimiz w vektörümüz olduğunu varsayalım. w vektörümüzden ayrılan ve caddenin hangi tarafında olduğunu bilmediğimiz u vektörümüz olduğunu düşünelim. Şimdi asıl ilgilendiğimiz şey bilinmeyenin sokağın sağ tarafında mı yoksa sol tarafında mı olduğu. Bu u vektörünü sokağa dik olan w vektörüne yansıtmak istiyoruz. Çünkü o zaman bu yöndeki mesafeye veya bu yönde bununla orantılı bir sayıya sahip olacağız. Ve ne kadar uzağa gidersek, sokağın sağ tarafına o kadar yaklaşırız. Vektörleri çarpıp b sabit sayısı ile topladıktan sonra değer 1’dan büyük ise seçtiğimiz (+) veya (-)sınıfında olduğunu belirleriz.Eğer eşitlik görseldeki gibi 0 ‘a eşit olursa xi noktamız gutter veya caddeye benzettiğimiz noktadadır. Lagrange Multipliersİki vektörün farkını alırsak ve w vektörüyle çarpıp w vektör büyüklüğüne bölersek cadde dediğimiz alanın uzunluğunu bulabiliriz.Bulduğumuz sonucu maksimum yapmak istiyoruz. Matematiksel optimizasyonda Lagrange Çarpanları(Lagrange Multipliers) yöntemini kullanacağız. Her iki tarafı 2 ile çarpıp w vektörüne göre diferansiyel alınca w vektörü eşitliğini elde ederiz. Bulduğumuz w vektör eşitliğini bir üstte yer alan Lagrange eşitliğinde yerine yazarız. Ardından yine her iki tarafı 2 ile çarpıp b’ ye göre diferansiyel alırız. Burda elde ettiğimiz sonuç işimize yarayacaktır. Bu sonucları lagrange denklemimizde yerine yazalım. İşte bulmak istediğimiz sonucu elde ettik.Peki yıldızlarla işaretlediğimiz yere bakalım.Tek yapmamız gereken bu iç çarpımları hesaplamaktı. Peki neden bu kadar zahmete girdik? Çünkü bu ifadenin bağımlılığını bulmak istedim. Bu maksimizasyonun bu vektörlere göre neye bağlı olduğunu bulmak istiyorum, x örnek vektörü ve keşfettiğim şey, optimizasyonun yalnızca örnek çiftlerinin iç çarpımına bağlı olduğudur. İki boyutlu ve 3 boyutlu olarak en uygun hiper düzlemi grafiklerde daha iyi görebiliriz: SVM modeli, iyi tanımlanmış bir karar sınırı oluşturarak iki sınıf arasındaki mesafeyi genişletmeye çalışır. Yukarıdaki durumda, hiper düzlemimiz verileri böldü. Verilerimiz 2 boyutlu iken, hiper düzlem 1 boyutluydu. Daha yüksek boyutlar için, örneğin n-boyutlu bir Öklid Uzayı için, alanı iki bağlantısız bileşene bölen n-1 boyutlu bir alt kümemiz var. Peki lineer olmayan durumlarda ne yapacağız?Aslında gerçek hayatta verisetleri genellikle tam ayrışmayan verilerden oluşuyor. Bu durumda SVM’lerin doğrusal olarak ayrılmaz verileri sınıflandırmak için kullandığı Soft Margin Formulation ve Kernel Trick kavramlarına bakalım. Aşağıdaki görselde olduğu gibi tam olarak ayrılmayan verileri grafikte inceleyelim. Şekilden, verileri mükemmel bir şekilde ayırabilecek belirli bir doğrusal karar sınırı olmadığı açıktır, yani veriler doğrusal olarak ayrılmazdır. Daha yüksek boyutlu temsillerde de benzer bir duruma sahip olabiliriz. Bu, genellikle verilerden elde ettiğimiz özelliklerin, iki sınıfı açıkça ayırabilmemiz için yeterli bilgi içermediği gerçeğine bağlanabilir. Çoğu gerçek dünya uygulamasında durum budur. Soft Margin FormulationBu fikir basit bir önermeye dayanmaktadır: SVM’nin belirli sayıda hata yapmasına izin verin ve marjı olabildiğince geniş tutun, böylece diğer noktalar hala doğru şekilde sınıflandırılabilir. Bu, SVM’nin amacını değiştirerek yapılabilir. Bu tür bir formülasyona sahip olmanın nedenini kısaca gözden geçirelim. Daha önce belirtildiği gibi, neredeyse tüm gerçek dünya uygulamaları doğrusal olarak ayrılmaz verilere sahiptir. Verilerin doğrusal olarak ayrılabildiği nadir durumlarda, aşırı uyumu önlemek için verileri mükemmel şekilde ayıran bir karar sınırı seçmek istemeyebiliriz. Örneğin, aşağıdaki diyagramı düşünün: Burada kırmızı karar sınırı, tüm eğitim noktalarını mükemmel bir şekilde ayırır. Ancak, bu kadar az marjla bir karar sınırına sahip olmak gerçekten iyi bir fikir mi? Bu tür bir karar sınırının görünmeyen veriler üzerinde iyi bir genelleme yapacağını düşünüyor musunuz? Cevabımız, tabi ki hayır. Yeşil karar sınırının, görünmeyen veriler üzerinde iyi bir şekilde genelleme yapmasına izin verecek daha geniş bir marjı vardır. Bu anlamda, Soft Margin Formulation, aşırı uyum sorununu önlemeye de yardımcı olacaktır. Burada C, marjı maksimize etmek ile hataları en aza indirmek arasındaki değiş tokuşa karar veren bir hiperparametredir. C küçük olduğunda, sınıflandırma hatalarına daha az önem verilir ve marjı maksimize etmeye daha çok odaklanırken, C büyük olduğunda, marjı küçük tutmak pahasına yanlış sınıflandırmadan kaçınmaya odaklanır. Ancak bu noktada, tüm hataların eşit olmadığını da belirtmeliyiz. Karar sınırından çok uzakta yanlış tarafında bulunan veri noktaları, daha yakın olanlara göre daha fazla ceza almalıdır. Aşağıdaki diyagramın yardımıyla bunun nasıl birleştirilebileceğini görelim. Buradaki fikir şudur: Her xi veri noktası için, bir gevşek değişken ξi sunuyoruz. Görselde olduğu gibi A,B ve C bölgelerinde ξ farklı değerler alır. C çok büyük olursa fonksiyon bütün ξ parametrelerini çok küçültmeye çalışacaktır. Daha dar bir marjin elde ederiz. Bu da , düşük bias ve yüksek varyansı meydana getirir (Overfitting). C çok küçük olursa daha gevşek, geniş bir marjin elde edilir ve ξ değeri büyük olur. Bu da yüksek bias ve düşük varyansı meyadan getirir (Underfitting). Kernels TrickŞimdi, doğrusal ayrılmazlık problemini çözmek için “Kernel Trick” i kullanmanın ikinci çözümünü inceleyelim. Ama önce Kernel fonksiyonlarının ne olduğunu öğrenmeliyiz. Kernel FunctionsKernel fonksiyonları, iki vektörü (herhangi bir boyuttan) girdi olarak alan ve girdi vektörlerinin ne kadar benzer olduğunu gösteren bir puan veren genelleştirilmiş işlevlerdir. Basit bir Kernel işlevi, nokta çarpım işlevidir: iç çarpım küçükse, vektörlerin farklı olduğu sonucuna varırız ve iç çarpım büyükse, vektörlerin daha benzer olduğu sonucuna varırız. The “Trick”Doğrusal olarak ayrılabilir durum için amaç fonksiyonuna bakalım: Fonksiyonda w ve b değerlerini yerine yazınca aşağıdaki fonksiyonu elde ederiz. Bir Kernel fonksiyonundan başka bir şey olmayan girdi vektör çiftlerinin (xi. xj) iç çarpımına bağlıdır. Şimdi burada iyi bir şey var: Nokta ürün gibi basit bir kernel işleviyle sınırlı kalmamıza gerek yok. Hesaplama maliyetlerini fazla artırmadan, daha yüksek boyutlarda benzerliği ölçme kabiliyetine sahip nokta ürün yerine herhangi bir süslü Kernel işlevini kullanabiliriz. Bu aslında Kernel Trick olarak bilinir. Burada x ve y giriş vektörleridir, ϕ bir dönüşüm fonksiyonudur ve &lt;,&gt; nokta çarpım işlemini belirtir. Nokta çarpım fonksiyonu durumunda, ϕ sadece giriş vektörünü kendisine eşler. 2d uzayda veri noktalarını mükemmel şekilde ayırabilecek doğrusal bir karar sınırı olmadığını görüyoruz. Dairesel (veya ikinci dereceden) bir karar sınırı işi yapabilir, ancak doğrusal sınıflandırıcılar bu tür karar sınırlarını bulamaz. Şekilde, her bir P noktası 2D uzayda (x, y) formunun özellikleriyle temsil edilmektedir. Arzu edilen karar sınırına baktığımızda, bir P noktası için ϕ dönüşüm fonksiyonunu ϕ (P) = (x ^ 2, y ^ 2, √2xy) olarak tanımlayabiliriz. İki nokta P_1 ve P_2 için bu tür dönüşüm için Kernel işlevinin neye benzediğini görelim. Kernel işlevinin son halini gözlemlersek, bu bir daireden başka bir şey değildir! Bu, benzerlik kavramımızı değiştirdiğimiz anlamına gelir: benzerliği noktaların ne kadar yakın olduğuna göre ölçmek yerine (iç çarpımı kullanarak), benzerliği noktaların bir daire içinde olup olmadığına göre ölçüyoruz. Bu anlamda, böyle bir dönüşümü tanımlamak, 2D uzayda doğrusal olmayan bir karar sınırına sahip olmamızı sağladı (orijinal 3D uzayda hala doğrusaldır). Daha iyi anlamak için aşağıdaki videoyu izleyelim. Kernel fonsiyonunu yeniden yazdığımızda aşağıdaki sonucu elde ederiz. Öyleyse Kernel fonksiyonunun değeri (dolayısıyla, 3D uzaydaki noktalar arasındaki benzerlik), 2D uzaydaki noktalar arasındaki nokta çarpımının sadece karesidir. Oldukça harika, değil mi ? Ama bu nasıl oldu? Bunun nedeni, dönüşüm fonksiyonumuzu akıllıca seçmiş olmamızdır. Ve bunu yapmaya devam ettiğimiz sürece, dönüştürme adımını atlayabilir ve Kernel işlevinin değerini doğrudan 2D uzaydaki noktalar arasındaki benzerlikten hesaplayabiliriz. Bu da aynı zamanda hesaplama maliyetlerini de azaltacaktır. Bu güzel özelliğe sahip ve kutudan çıktığı gibi kullanılabilen birçok popüler Kernel fonksiyonumuz var (mükemmeli aramamıza gerek yok ϕ). SVM Avantajları Garantili Optimallik: Konveks Optimizasyonun doğası gereği, çözüm her zaman local minimum değil global minimum olacaktır. SVM, doğrusal olarak ayrılabilir ve doğrusal olmayan şekilde ayrılabilir veriler için kullanılabilir. Doğrusal olarak ayrılabilir veriler kesin marjin, doğrusal olmayan şekilde ayrılabilir veriler soft marjin oluşturur. SVM’ler, yarı denetimli öğrenme modellerine uyum sağlar. Verilerin etiketlendiği ve etiketlenmediği alanlarda kullanılabilir. Yalnızca Transdüktif SVM olarak bilinen en aza indirme problemi için bir koşul gerektirir. Feature Mapping, eskiden modelin genel eğitim performansının hesaplama karmaşıklığına oldukça yük oluyordu. Bununla birlikte, Kernel Trick’in yardımıyla SVM, basit iç çarpım kullanarak feature mapping gerçekleştirebilir. SVM Dezavantajları SVM, metin yapılarını işleyemez. Bu, sıralı bilgi kaybına ve dolayısıyla daha kötü performansa yol açar. Vanilya SVM, lojistik regresyona benzer olasılıklı güven değerini döndüremez. Tahmin güveni birçok uygulamada önemli olduğundan, bu çok fazla açıklama sağlamaz. Çekirdek seçimi, destek vektör makinesinin belki de en büyük sınırlamasıdır. Bu kadar çok çekirdeğin mevcut olduğu düşünüldüğünde, veriler için doğru olanı seçmek zorlaşıyor.","link":"/SVM/"}],"tags":[{"name":"Model","slug":"Model","link":"/tags/Model/"},{"name":"Representation","slug":"Representation","link":"/tags/Representation/"},{"name":"CostFunction","slug":"CostFunction","link":"/tags/CostFunction/"},{"name":"Regression","slug":"Regression","link":"/tags/Regression/"},{"name":"Linear Regression","slug":"Linear-Regression","link":"/tags/Linear-Regression/"},{"name":"Polynomial Regression","slug":"Polynomial-Regression","link":"/tags/Polynomial-Regression/"},{"name":"NLP","slug":"NLP","link":"/tags/NLP/"},{"name":"GPT-3","slug":"GPT-3","link":"/tags/GPT-3/"},{"name":"OpenAI","slug":"OpenAI","link":"/tags/OpenAI/"},{"name":"Feature Scaling","slug":"Feature-Scaling","link":"/tags/Feature-Scaling/"},{"name":"Min-Max Scaler","slug":"Min-Max-Scaler","link":"/tags/Min-Max-Scaler/"},{"name":"Standard Scaler","slug":"Standard-Scaler","link":"/tags/Standard-Scaler/"},{"name":"Max Abs Scaler","slug":"Max-Abs-Scaler","link":"/tags/Max-Abs-Scaler/"},{"name":"Robust Scaler","slug":"Robust-Scaler","link":"/tags/Robust-Scaler/"},{"name":"Quantile Transformer Scaler","slug":"Quantile-Transformer-Scaler","link":"/tags/Quantile-Transformer-Scaler/"},{"name":"Power Transformer Scaler","slug":"Power-Transformer-Scaler","link":"/tags/Power-Transformer-Scaler/"},{"name":"Unit Vector Scaler","slug":"Unit-Vector-Scaler","link":"/tags/Unit-Vector-Scaler/"},{"name":"Classification","slug":"Classification","link":"/tags/Classification/"},{"name":"Logistic Regression","slug":"Logistic-Regression","link":"/tags/Logistic-Regression/"},{"name":"Decision Boundary","slug":"Decision-Boundary","link":"/tags/Decision-Boundary/"},{"name":"Binary Classification","slug":"Binary-Classification","link":"/tags/Binary-Classification/"},{"name":"Multiclass Classification","slug":"Multiclass-Classification","link":"/tags/Multiclass-Classification/"},{"name":"Artificial Neural Networks (ANNs)","slug":"Artificial-Neural-Networks-ANNs","link":"/tags/Artificial-Neural-Networks-ANNs/"},{"name":"Input Layer","slug":"Input-Layer","link":"/tags/Input-Layer/"},{"name":"Hidden Layer","slug":"Hidden-Layer","link":"/tags/Hidden-Layer/"},{"name":"Output Layer","slug":"Output-Layer","link":"/tags/Output-Layer/"},{"name":"Back Propagation Algorithm","slug":"Back-Propagation-Algorithm","link":"/tags/Back-Propagation-Algorithm/"},{"name":"FeedForward Neural Networks","slug":"FeedForward-Neural-Networks","link":"/tags/FeedForward-Neural-Networks/"},{"name":"FeedBack Neural Network","slug":"FeedBack-Neural-Network","link":"/tags/FeedBack-Neural-Network/"},{"name":"Bayes Networks","slug":"Bayes-Networks","link":"/tags/Bayes-Networks/"},{"name":"Directed Acyclic Graphs (DAGs)","slug":"Directed-Acyclic-Graphs-DAGs","link":"/tags/Directed-Acyclic-Graphs-DAGs/"},{"name":"Bias","slug":"Bias","link":"/tags/Bias/"},{"name":"Variance","slug":"Variance","link":"/tags/Variance/"},{"name":"Underfitting","slug":"Underfitting","link":"/tags/Underfitting/"},{"name":"Overfitting","slug":"Overfitting","link":"/tags/Overfitting/"},{"name":"Model Selection","slug":"Model-Selection","link":"/tags/Model-Selection/"},{"name":"Cross Validation","slug":"Cross-Validation","link":"/tags/Cross-Validation/"},{"name":"Learning Curve","slug":"Learning-Curve","link":"/tags/Learning-Curve/"},{"name":"Error Analysis","slug":"Error-Analysis","link":"/tags/Error-Analysis/"},{"name":"Model Evaluation Metrics","slug":"Model-Evaluation-Metrics","link":"/tags/Model-Evaluation-Metrics/"},{"name":"Accuracy","slug":"Accuracy","link":"/tags/Accuracy/"},{"name":"Precision","slug":"Precision","link":"/tags/Precision/"},{"name":"Recall","slug":"Recall","link":"/tags/Recall/"},{"name":"F1 Score","slug":"F1-Score","link":"/tags/F1-Score/"},{"name":"ROC","slug":"ROC","link":"/tags/ROC/"},{"name":"AUC","slug":"AUC","link":"/tags/AUC/"},{"name":"Support Vector Machine","slug":"Support-Vector-Machine","link":"/tags/Support-Vector-Machine/"},{"name":"Lagrange Multipliers","slug":"Lagrange-Multipliers","link":"/tags/Lagrange-Multipliers/"},{"name":"Soft Margin Formulation","slug":"Soft-Margin-Formulation","link":"/tags/Soft-Margin-Formulation/"},{"name":"Kernels Tricks","slug":"Kernels-Tricks","link":"/tags/Kernels-Tricks/"}],"categories":[{"name":"Machine Learning","slug":"Machine-Learning","link":"/categories/Machine-Learning/"},{"name":"Deep Learning","slug":"Deep-Learning","link":"/categories/Deep-Learning/"}]}