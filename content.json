{"pages":[],"posts":[{"title":"Model Representation","text":"Makine öğrenimi algoritmasının çoğunun temel amacı bir model oluşturmaktır. Bu modelden hipotez olarak söz edebiliriz. Hipotez temel olarak girdiyi çıktıya eşler. Girdi değişkeni özelliği ve çıktı değişkeni hedefi belirtir. Öğrenmek için kullanacağımız veri kümesine eğitim seti(trainning set) denir. Amacımız, bir eğitim seti verildiğinde, h: X → Y fonksiyonunu öğrenmek, böylece h (x), y’nin karşılık gelen değeri için “iyi” bir tahmin edici model diyebiliriz. Gelin bunu bir örnekle açıklayalım. Diyelim ki ev fiyatları tahmini yapmak istiyoruz. Elimizde evlerin m2 ölçüleri ve fiyatları var. Burada dikkat etmemiz gereken girdilerimiz yani “x” , fiyatını tahmin edeceğimiz çıktı “y” olacak. Eğer biz verilerimizden fiyat tahmini yapmak istiyorsak bunun için regresyon (regression) kullancağız. Eğer yaşam alanının ( villa, arsa , apartman vs.) ne olduğunu bulmak istiyorsak bunun için sınıflandırma (classification) kullanacağız. Hedefimiz fiyat tahmini bu yüzden regresyon kullancağız. Hipotez formülü : hQ(x) =θ0+θ1X Tetalar (θ) bizim parametrelerimizdir. Katsayılarımızı düzgün seçmeliyiz çünkü verilerimiz görselleştirdiğimizde eğimi 0 olduğunda tahminimiz yani y değeri hep 0 gelecektir.NOT: Model oluşturmanın amacı parametreleri veya teta değerlerini doğru seçmektir, böylece h (x) training verilerimiz olan x’ler için ulaşmak istedğimiz y değerine yakın olur. Eğer θ1 değerimizi yani eğimi veren değer 0 olursa aşağıdaki gibi grafik elde ederiz ve istediğimiz y değerine ulaşamayız. 1234import matplotlib.pyplot as pltplt.plot([1, 2, 3, 4], [1,1,1,1])plt.ylabel('some numbers')plt.show() Şimdi örnek verimizi görselleştirerek anlatalım.Elimizde evlerin ölçüleri ve fiyatları olsun burada eğim 0 olmadığından girdiğimiz her x değerimize karşılık y değeri geliyor bu da bize regression kullanarak fiyat tahmini yapmamızı sağlıyor.Aşağıdaki örnekteki gibi küçük bir verimiz olsun. 123import pandas as pddf = pd.DataFrame({'x': [0, 0.5, 1,1.5,2,2.5,3], 'hθ(x)': [1.0,1.5,2.0,2.5,3.0,3.5,4.0]})df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x hθ(x) 0 0.0 1.0 1 0.5 1.5 2 1.0 2.0 3 1.5 2.5 4 2.0 3.0 5 2.5 3.5 6 3.0 4.0 1234plt.plot([852, 1416,1534,2104], [178,232,315,460], color='blue')plt.ylabel('Price($) in 1000s')plt.xlabel('Size in house feet^2 (x)')plt.show() Üstteki grafikte olduğu gibi kırmızı noktalarla işaretlediğimiz 1750 feet^2 olan evimizin tahmini değeri 375000 $ civarı oluyor.İşte modelimizin bize tahminde bulunmasını istediğimiz değerleri böyle örneklendirebiliriz.","link":"/ModelRepresentation/"},{"title":"Cost Function","text":"Öncelikle lineer regresyonda tahmin edilen y değeri ile gerçek y değeri arasındaki hatayı minimuma indirebilmek için teta(θ) değerleri bulmalıyız. Maliyet fonksiyonunu (cost function) minimize etmeliyiz. Maliyet fonksiyonu diye gerçek y değerleri ile tahmin edilen y değerleri arasındaki farka deriz.Maliyet fonksiyonumuz test setindeki çıktıları ne kadar iyi tahmin ettiğini ölçer.Tahmin edilen değer ile gerçek değer arasındaki fark ne kadar az ise modelimiz o kadar iyi tahminde bulunur. Amaç, maliyeti en aza indiren bir dizi ağırlık(weight) ve önyargı(bias) bulmaktır. Bunun için y’nin gerçek değeri ile y’nin tahmini değeri (tahmin) arasındaki farkı ölçen ortalama kare hatası(the mean squared error)kullanılır. Aşağıdaki regresyon çizgisinin denklemi, sadece iki parametreye sahip olan hθ (x) = θ0 + θ1x’tir: weight(θ1) ve bias(θ0) Minimising Cost functionHerhangi bir makine öğrenmesi modelinin amacı cost fuction’ı (maliyet fonksiyonu) en aza indirgemektir. Gelin, yukarıdaki görselimizi anlayalım. Kırmızı olan tepecikler random olarak seçtiğimiz teta parametrelerimizin bulunduğu yeri temsil ediyor.Hedefimiz koyu mavi ile gösterilen “global minimum” dediğimiz yere doğru adım adım ilerlemek. Şekilde görüldüğü gibi ikinci bir mavi noktamız var buraya da “local minimum” diyoruz ama bu noktaya ilerlemiyoruz.Çünkü istediğimiz şey costu minimize etmek(hatalı değerlerimizi minimuma indirgemek) local minimumda değerimiz global minimuma göre daha yüksek çıkacağından hedefimiz her zaman global minimuma gitmek olmalıdır.Peki nasıl global minimuma varacağız. Bunun için etkili bir optimizasyon algoritması olan Gradient Descent Algoritmasını kullanacağız. Gradient Descent AlgorithmGradient Descent (Degrade İniş), hesaplamayı kullanarak belirli maliyet işlevinin minimum değerine karşılık gelen parametrelerin optimal değerlerini bulmak için yinelemeli olarak çalışır. Matematiksel olarak, ‘türev’ tekniği maliyet işlevini en aza indirmek için son derece önemlidir, çünkü minimum noktayı elde etmeye yardımcı olur. Türev, matematikten gelen bir kavramdır ve belirli bir noktada fonksiyonun eğimini ifade eder. Eğimi bilmemiz gerekir, böylece bir sonraki yinelemede daha düşük bir maliyet elde etmek için katsayı değerlerini hareket ettirme yönünü (işaretini) biliriz. Her parametredeki bir fonksiyonun türevi (bizim durumumuzda, J (θ)) bize bu değişkene göre fonksiyonun hassasiyetini veya değişkeni değiştirmenin fonksiyon değerini nasıl etkilediğini söyler. Gradient descent, bu nedenle, öğrenme sürecinin modeli optimal bir parametre kombinasyonuna doğru hareket ettiren öğrenilmiş tahminlerde düzeltici güncellemeler yapmasını sağlar (θ). Cost , bir gradient descent algoritmasının her tekrarı için tüm training set kümesinde bir makine öğrenme algoritması için hesaplanır. Gradient Descent, algoritmanın bir yinelemesine bir “Batch Gradient Descent” deniyor. Bu her bir yinelemenin gradyanını hesaplamak için kullanılan bir training set kümesindeki toplam örnek sayısını belirtir. Bu yeni gradyan, maliyet fonksiyonumuzun mevcut konumumuzdaki eğimini (geçerli parametre değerleri) ve parametrelerimizi güncellemek için hareket etmemiz gereken yönü gösterir. Güncellememizin boyutu learning rate (α)(öğrenme oranı) tarafından kontrol edilmektedir. Learning rate (α) Gradient descent algoritmasında adımların boyutuna, ne kadar büyük adımlar attığımız konusunda bize ek kontrol sağlayan değere learning rate (α) denir. Büyük bir learning rate(α) sağ alt köşedeki görselde olduğu gibi, her adımda daha fazla yer atlayabiliriz, ancak tepenin eğimi sürekli değiştiği için en düşük noktayı aşma riskiyle karşı karşıyayız. Çok düşük bir learning rate(α) sağ üst köşedeki görselde olduğu gibi, negatif gradyan yönünde güvenle hareket edebiliriz, çünkü bunu çok sık yeniden hesaplıyoruz. Düşük bir learning rate(α) daha kesindir, ancak gradyanı hesaplamak zaman alıcıdır, bu nedenle en alt noktaya gelmek çok uzun zaman alacaktır. En sık kullanılan learning rate(α) değerleri: 0.001, 0.003, 0.01, 0.03, 0.1, 0.3 Şimdi Gradient descent algoritmasının üç varyantını tartışalım. Aralarındaki temel fark, her bir learning step(öğrenme adımı) için degradeleri hesaplarken kullandığımız veri miktarıdır. Aralarındaki değişim, her bir parametrenin güncellemesini gerçekleştirmek için zaman karmaşıklığına karşı degradenin doğruluğudur (learning step). Stochastic Gradient Descent (SGD)Batch Gradient Descent ile ilgili temel sorun, her adımda degradeleri hesaplamak için tüm eğitim setini kullanmasıdır, bu da eğitim seti büyük olduğunda çok yavaş olmasını sağlar. Stochastic Gradient Descent her adımda belirlenen eğitimde rastgele bir örnek seçer ve degradeleri yalnızca bu tek örneğe göre hesaplar. Algoritmayı çok daha hızlı hale getirir. Öte yandan, stokastik doğası nedeniyle, bu algoritma Batch Gradient Descent’ten çok daha az düzenlidir: minimum seviyeye ulaşıncaya kadar hafifçe azaltmak yerine, maliyet fonksiyonu yukarı ve aşağı sıçrar ve sadece ortalama olarak azalır. Zamanla minimum seviyeye çok yakın olacak, ancak oraya vardığında geri dönmeyecek, asla yerleşmeyecek. Dolayısıyla algoritma durduğunda, son parametre değerleri iyidir, ancak optimal değildir. Cost function çok düzensiz olduğunda, bu aslında algoritmanın local minimum dışına atlamasına yardımcı olabilir, bu nedenle Stochastic Gradient Descent, Batch Gradient Descent’ten daha fazla global minimum bulma şansına sahiptir. Bu nedenle, rasgelelik local optima’dan kaçmak için iyidir, diğer yandan kötüdür, çünkü algoritmanın asla minimumda yerleşemeyeceği anlamına gelir. Bu ikilemin bir çözümü learning rate(α) kademeli olarak azaltmaktır. Adımlar büyük başlar (hızlı ilerleme kaydetmeye ve yerel minimadan kaçmaya yardımcı olur), daha sonra gittikçe küçülür ve algoritmanın küresel minimumda yerleşmesine izin verir. Her yinelemede öğrenme hızını belirleyen işlev öğrenme çizelgesi olarak adlandırılır. Öğrenme oranı çok yavaş bir şekilde azalırsa, minimuma çok uzun bir süre sonra varabilir ve eğitimi çok erken durdurursanız, en uygun olmayan bir çözüm elde edebilirsiniz. Öğrenme oranı çok hızlı bir şekilde azalırsa, yerel bir minimumda takılabilir veya hatta en sonunda yarıya kadar donmuş olabilirsiniz. Öğrenme oranı çok yavaş bir şekilde azalırsa, minimum süre boyunca uzun süre atlayabilir ve eğitimi çok erken durdurursanız, en uygun olmayan bir çözüm elde edebilirsiniz. Stochastic Gradient Descent kullanıldığında, parametrelerin ortalama olarak global minimum değere doğru çekilmesini sağlamak için training set bağımsız ve aynı şekilde dağıtılmalıdır. Bunu sağlamanın basit bir yolu, eğitim sırasında örnekleri karıştırmaktır. Bunu yapmazsanız, örneğin örnekler etikete göre sıralanırsa, SGD bir etiket için, ardından bir sonraki öğe için optimizasyon yaparak başlayacaktır ve global minimum değere yakın yerleşmeyecektir. Mini-Batch Gradient DescentHer adımda, gradientleri tüm training sete (Batch GD’de olduğu gibi) veya yalnızca bir örneğe (Stochastic GD’de olduğu gibi) dayalı olarak hesaplamak yerine, Mini-Batch GD, gradientleri mini-batches adı verilen küçük rasgele örnek kümelerinde hesaplar. Mini-Batch GD’nin Stochastic GD’ye göre ana avantajı, özellikle GPU’ları kullanırken matris işlemlerinin donanım optimizasyonundan bir performans artışı elde edebilmenizdir. Algoritmanın parametre alanındaki ilerlemesi, özellikle oldukça büyük Mini-Batch’lerde SGD’den daha az düzensizdir. Sonuç olarak, Mini-Batch GD, SGD’den minimum seviyeye biraz daha yakın yürüyecektir. Ancak, diğer taraftan, yerel minimadan kaçmak daha zor olabilir. Hepsi minimum seviyeye yakın, ancak Batch GD’nin yolu aslında minimumda dururken, hem Stochastic GD hem de Mini-Batch GD dolaşmaya devam ediyor. Ancak, Batch GD’nin her adımı atması çok zaman aldığını ve iyi bir öğrenme programı kullandıysanız Stochastic GD ve Mini-Batch GD’nin de minimum seviyeye ulaşacağını unutmayın.","link":"/CostFunction-GradientDescent/"},{"title":"Linear and Polynomial Regression","text":"İki tür gözetimli(supervised) makine öğrenme algoritması vardır: Regresyon ve sınıflandırma.Örneğin, bir evin fiyatını dolar olarak tahmin etmek bir regression problemidir, bir tümörün kötü veya iyi huylu olup olmadığını tahmin etmek bir sınıflandırma problemidir. Bu yazıda , Python için en popüler makine öğrenimi kütüphanelerinden biri olan Scikit-Learn kullanarak doğrusal regresyonun ne olduğunu ve hem iki değişken hem de çoklu değişken için nasıl uygulanabileceğini kısaca inceleyeceğiz. Cebirde “doğrusallık” terimi, iki veya daha fazla değişken arasındaki doğrusal bir ilişkiyi ifade eder. Bu ilişkiyi iki boyutlu bir alanda (iki değişken arasında) çizersek, düz bir çizgi elde ederiz. Doğrusal regresyon, verilen bağımsız değişkeni (x) temel alarak bağımlı bir değişken değerini (y) tahmin etme görevini yerine getirir. Dolayısıyla, bu regresyon tekniği x (girdi) ve y (çıktı) arasında doğrusal bir ilişki bulur. Bu nedenle, adı Linear Regression(Doğrusal Regresyon) dur. Bağımsız değişkeni (x) x eksenine ve bağımlı değişkeni (y) y eksenine çizersek, doğrusal regresyon bize aşağıdaki şekilde gösterildiği gibi veri noktalarına en iyi uyan düz bir çizgi verir. Yukarıdaki çizginin denklemi: Y = mx + b Burada b kesişme noktası ve m doğrunun eğimidir. Temel olarak, lineer regresyon algoritması bize kesişme ve eğim için en uygun değeri verir (iki boyutta). Veri özellikleri oldukları ve değiştirilemedikleri için y ve x değişkenleri aynı kalır. Kontrol edebileceğimiz değerler kesişme noktası (b) ve eğimdir (m). Kesişim ve eğim değerlerine bağlı olarak birden fazla düz çizgi olabilir. Tek değişkeni olan bir regresyon modeli şu şekilde temsil edilebilir: y = b0 + m1b1 hQ(x) =θ0 + θ1X Multiple Linear RegressionTemel olarak doğrusal regresyon algoritmasının yaptığı şey, veri noktalarına birden çok satır sığdırması ve en az hatayla sonuçlanan çizgiyi döndürmesidir. Aynı kavram ikiden fazla değişkenin bulunduğu vakalara da genişletilebilir. Buna multiple linear regression(çoklu doğrusal regresyon) denir. Örneğin, evin fiyatını alanı, yatak odası sayısı, bölgedeki insanların ortalama geliri, evin yaşı vb. Temelinde tahmin etmeniz gereken bir senaryo düşünün. Bu durumda, bağımlı değişken (hedef değişken) birkaç bağımsız değişkene bağlıdır. Birden çok değişkeni içeren bir regresyon modeli şu şekilde temsil edilebilir: y = b0 + m1b1 + m2b2 + m3b3 + … mnbn hQ(x) =θ0 +θ1X1 + θ2X2 + θ3X3 + …θnXn Bu, bir hiper düzlemin denklemidir. Unutmayın, iki boyutta doğrusal bir regresyon modeli düz bir çizgidir; üç boyutta olan bir düzlemdir ve üçten fazla boyutta olan bir hyperplane(hiperdüzlem)dir. Polynomal Linear RegressionKullanacağınız veri setine göre veriler lineer olarak dağılım göstermeyebilir ve doğrusal olmayan(non-linear) diye adlandırılan dağılımı gösterebilir. Lineer regresyon burada istediğimiz sonucu vermeyecektir.Non-linear olan dağılımda polinomal regresyon istediğimiz sonuca bizi yaklaştıracaktır.Polinomal regresyonda bağımsız değişken x ve bağımlı değişken y arasındaki ilişkinin n’inci derece polinom olarak modellendiği bir doğrusal regresyon biçimidir. Unutmayın burada x’ler lineer ilerlemiyor.Zaten lineer dememizin sebebi θ0,θ1,θ2,θ3… değerleridir. n’inci derece polinom denklemi y = a + b1x + b2x^2 +….+ bnx^n hQ(x) =θ0 +θ1X1 + θ2X2^2 + θ3X3^3 + …θnXn^n Gelin küçük bir örnekle lineer ve polinomal regresyon için kodlayalım. Amaç: Sıcaklık ve basınç değerleri verilen bir veri setinde istenilen sıcaklık değerinde basıncın ne olacağını tahmin edebilmektir. 12345678# Importing the libraries import numpy as np import matplotlib.pyplot as plt import pandas as pd # Importing the dataset datas = pd.read_csv('data.csv') datas .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sno Temperature Pressure 0 1 0 0.0002 1 2 20 0.0012 2 3 40 0.0060 3 4 60 0.0300 4 5 80 0.0900 5 6 100 0.2700 123# for x axis we select temperature, for y axis we select pressureX = datas.iloc[:, 1:2].values y = datas.iloc[:, 2].values 12345# Fitting Linear Regression to the dataset from sklearn.linear_model import LinearRegression lin = LinearRegression() lin.fit(X, y) 12LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) 123456789# Visualising the Linear Regression results plt.scatter(X, y, color = 'blue') plt.plot(X, lin.predict(X), color = 'red') plt.title('Linear Regression') plt.xlabel('Temperature') plt.ylabel('Pressure') plt.show() 123456789# Fitting Polynomial Regression to the dataset from sklearn.preprocessing import PolynomialFeatures poly = PolynomialFeatures(degree = 4) X_poly = poly.fit_transform(X) poly.fit(X_poly, y) lin2 = LinearRegression() lin2.fit(X_poly, y) 12LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) 123456789# Visualising the Polynomial Regression results plt.scatter(X, y, color = 'blue') plt.plot(X, lin2.predict(poly.fit_transform(X)), color = 'red') plt.title('Polynomial Regression') plt.xlabel('Temperature') plt.ylabel('Pressure') plt.show() Görselimizde görüldüğü üzere regresyon çizgimiz değerlerimize yakın bile değil peki yakın(fit) olmaması sorun teşkil eder mi? Tabi ki eder modelimize uyguladığımızda modelimiz doğru tahminde bulunmayacaktır. 12# Predicting a new result with Linear Regression print(lin.predict([[197]])) 1[0.41050733] 12# Predicting a new result with Polynomial Regression lin2.predict(poly.fit_transform([[197]])) 1array([7.18740604]) Yukarıda aynı x sıcaklık değeri için basınç tahminleri arasındaki farkı görebiliriz.Polinomal regresyon modelimiz lineer regresyon modelimize göre daha iyi tahminde bulundu diyebiliriz. Polinomal regresyonda avantajlar: Polinom, bağımlı ve bağımsız değişken arasındaki ilişkiye en iyi yaklaşımı sağlar. Polinomal regresyonda dezavantajlar: Bunlar aykırı değerlere karşı çok hassastır. Verilerdeki bir veya iki aykırı değerin varlığı, doğrusal olmayan bir analizin sonuçlarını ciddi şekilde etkileyebilir. Ek olarak, maalesef doğrusal olmayan regresyonda aykırı değerlerin tespiti için doğrusal regresyon için olanlardan daha az model doğrulama aracı vardır.","link":"/Regression/"},{"title":"GPT-3","text":"Generative Pre-trained Transformer 3 (Türkçe: Üretken Ön İşlemeli Dönüştürücü 3) kısaca GPT-3, insanların yazdığı metinlere benzer içerik üretmek için derin öğrenmeyi kullanan özbağlanımlı dil modelidir. GPT-n serisindeki üçüncü nesil dil tahmin modeli olan GPT-3, San Francisco merkezli yapay zeka araştırma laboratuvarı OpenAI tarafından geliştirilmiştir. GPT-3’ün tam sürümü, veri işleyecek 175 milyar parametreye sahiptir. Bu rakam GPT-2’nin öğrenme kapasitesinin 2 katıdır. 14 Mayıs 2020’de tanıtılan ve Temmuz 2020 itibarıyla beta aşamasında olan GPT-3, önceden öğretilmiş dil örnekleriyle doğal dil işleme (NLP) sistemini kullanmaktadır. GPT-3’ün piyasaya sürülmesinden önce, en büyük dil modeli Microsoft’un Şubat 2020’de tanıttığı ve GPT-3’ün %10’undan daha az kapasiteye sahip olan (17 milyar parametre) Turing NLG idi.Wikipedia sitesinde bu şekilde açıklanıyor. Youtube panelinde GPT-3 hakkında sorulan sorulara Google Brain’de Araştırmacı olan Lukasz Kaiser şu açıklamaları yaptı: Transformerlardan öncesini yani derin öğrenme kısmında NLP’de RNN’ler her şeyi doğru yapıyordu. Derin öğrenmenin ve NLP’nin ilk büyük dalgasıydılar. İşleri adım adım yineleyerek yapmanız gerektiğine dair süper temel fikirlere sahiptiler, bu da çok sezgisel ancak modern donanımda gerçekten yavaştır çünkü hızlandırıcılar paralel işlem için inşa edilmiştir. Dikkat fikri NLP’de çok eski bir bir yöntem olan hizalamadan (alignment) geliyor. Diyelim ki bir cümleyi çevirmeye çalışıyorsunuz elinizde ingilizce ve fransızca cümleler var hangi kelimelerin hangi kelimelere karşılık geldiğini hizalamaya çalışıyorsunuz. Dolayısıyla, bu hizalama fikrini bir sinir ağına koyarsanız, elde ettiğiniz şey dikkat mekanizmasıdır. Kelimeleri daha önce gelen kelimelerle hizalamanın farklılaştırılabilir yumuşak bir versiyonudur ve öz-ilgi, aynı metni, daha önce görünen kelimelerle aynı hizaya getirecek şekilde hizalamaktır. Bu fikir, aldığınız sonuçlar açısından iyi işliyor, ancak aynı zamanda modern derin öğrenme hızlandırıcılarında iyi bir şekilde uygularsanız şaşırtıcı derecede hızlı da çalışıyor. Sonuçları bir gün veya bir ay beklemeniz gerekmiyor bu da büyük bir fark yaratıyor. Ama diğer bir şey de hizalama(alignment), nlp’de uzun zamandır bilinen gerçekten iyi bir fikir.Paragrafın tamamını çevirmek istiyorsanız, bu bölümü çevirmeye odaklandığınızda ve her seferinde sadece bu bölüme baktığınızda çok daha kolay. Her insanın yaptığı da budur. Bunu bir sinir ağına öncelikli olarak veriyorsunuz ve bu gerçekten işe yarıyor, bu yüzden dikkatin geldiği yer burasıdır ancak şunu söylemek isterim, her şey dalgalar halinde ilerlerken, RNN’leri kullanmak çok iyi bir fikirdir. Çünkü seyrek transformatörlerle ilgili, bu ilginin insanların düşündüğünden daha çok RNN’ e benzediğini gösteren modern makaleler var ve aslında buna tekrar eden bir ağ(recurrent network) eklemek onu daha da iyi hale getiriyor. İnsanlar tekrar eden ağa geri dönerse, tekrar bir şekilde tekrarlayan ağlara bile dönüşmesi bu yüzden şaşırtıcı olmaz. En yeni teknikten daha fazlasını öğrenmek, daha önce gelen şeyleri bilmek ve bununla ilgili her şeyi öğrenmek iyidir.Herkesin internette NLP’de derin öğrenme yaptığını düşünebilirsiniz ama ben bunun tam tersini düşünüyorum. Elbette bugünlerde her şey çevrimiçi olarak gerçekleşiyor, çok fazla hareket varmış gibi geliyor çünkü nlp dünyası onlarca yıl öncesine göre çok daha büyük ama bu derin modellerin aslında dil yapabildiği şeylerin yüzeyini zar zor çizdiğimizi hissediyorum. Bu dil son derece derin bir alandır. Evet, size bir hikaye oluşturabiliriz ve okuruz, tamam mıdır? Gerçekten anlamı var mı? Bu doğru şeyler yaratır mı? Bunu bize bildiğini söyleyebilir mi? Doğrulayabilir miyiz? Önyargılar(bias) hakkında konuştuğumuzu bildiğini bize söyleyebilir mi? Aslında dil modelinin bu kadar saldırgan olup olmadığını sorabilirsiniz ve çoğu durumda size bunun olup olmadığını söyleyecektir. Ancak insan benzeri olmayan bazı hatalar yapacaktır. Nedenini anlayabilir miyiz?Sadece birkaç hafta önce piyasaya sürülen GPT-3, gradyan inişi olmadan öğrenebileceğini gösteren ilk model, bir şeyleri girdi olarak modele koyabilirsiniz ve sanki onları eğitiyormuş gibi çalışır, bu yüzden bu çok yeni ve test etmesi çok zor çünkü büyük modele ihtiyacınız var .Yarım yıl veya yıl içinde, bunu uygulamalı olarak yapmaya başlayabileceğiniz modeller olacak. Öğrenmeye başlamak için harika bir zaman. Çünkü dile giren bu şeylerin çoğunun başlangıcı. Teknolojiyi aldık ama aslında dilin derinliklerine inerken hala önümüzde çok düşündüğümüz bu uygulamaları getirecek.GPT-3 transformer modeli tüm web üzerinden eğitildi. Gelecekteki öğrenmeyi biraz beklenmedik olan yeni görevlere genelleştirir, ancak gerçekten tüm web üzerinde eğitilmiştir. Yani bir anlamda o kadar da beklenmedik değil ve arabalarda eğiteceğimiz daha küçük modelleri bile göreceksiniz, onlar da genelleştiriyorlar. Bu yüzden şimdi GPT-3 size harika cevaplar veriyor ama bu cevaplar ne işe yarıyor ve belki görevleriniz soruya uyuyor. Ancak görevinizi çözmeniz gerekir, genellikle görevinizi çözmek için modeli kullanmak ister ve onunla oynarsınız.Tamam işe yaramaz bir görevi çözmelisin deneyim kazanıp, öğrenmen gerekiyor ama daha sonra gerçek dünya görevinde bir araç kullanmalısın ve harika çeviri modellerimiz var. Google Translate sadece bu model değil tam da bunun gibi derin öğrenme modeli başlatamazsın. Biraz regex eklemelisiniz. Korkunç bir çıktı üretip üretmediğini görmek için basit bir regexin için bile, tüm eski tekniklere ön işleme(pre-processing) koymanız gerekir. Kullanıcılarınıza, müşterilerinize sonuç olarak neyi çıkardığınıza bakmanız ve bunu doğrulamanız gerekir. Bu modelin neden belirli durumlarda kötü çıktılar verdiğini ve modeli nasıl tamir edeceğinizi bilmiyorsanız düşünmeye başlamanız gerekir.Hala bilmediğimiz çok şey var, o zaman buna karşı biraz savunma yapmanız gerekiyor, belki sadece modelin gerçekten kötü olduğu ve GPT-3’ün kötü olduğu durumları tespit edin. GPT-3 diğer pek çok durumda iyidir, bu yüzden onu nasıl kullanacağınızı gerçekten öğrenmeniz gereken bir araç olduğunu öğrenmeniz gerekir. Verimli bir şekilde kullanabileceğiniz her yerde deneyim kazanın, sadece alıp uygulamak işe yarıyor mu? Hayır. Ne zaman çalıştığını, nasıl çalıştığını anlamak için çok iş var. Yıllar geçtikçe, bu şeylerin gerçekte nasıl çalıştığını daha iyi anlayacağımızı umuyoruz. Bunlar dilde biraz daha derine inmemize, ancak yine de uzun bir yol kat etmemize olanak tanıyan araçlar. Onu nerede nasıl kullanabileceğimizi öğrenmemiz gereken uzun bir yolumuz var ama bizim de ihtiyacımız olan başka şeyler olabilir ve kesinlikle bir GPT-4 olacaktır, bu yolun sonu değil, ama bu yolda büyük bir adım. Bir diğer panelist olan makine öğrenmesi ve yapay zeka alanında verdiği eğitimlerle birçok insanın hayatına dokunan Prof. Andrew NG GPT-3 ün çıkışı hakkında şunları söyledi: “İnanılmaz görünen her şey, çok çalıştığımızda ve bunları iyileştirdiğimizde, niş görünse bile doğru uygulamaları bulduğumuzda, bir gün okuduğumuz ve hayran kaldığımız bu modelin nerede olduğunu hayal edin. Kol saatinizde koşacak mıyım bilmiyorum ama teknoloji bu şekilde daha kullanılabilir hale geliyor. Şu anda NLP alanında çok sayıda zayıf sinyal görüyorum. Bunun patlayacağını ve daha yetenekli ve daha yaygın hale geleceğini düşündüğüm şeylerle yapabilirsiniz. Umarım bu araçları öğrenerek bu devrime katılabilirsiniz.” GPT-3 parlak bir obje mi? Doğru zamanda mı piyasa sürüldü? İşlerimizi elimizden alacak mı? Bu tür sorulardan ziyade kendimizi güncel tutmalı öğrenebileceğimiz herşeyi öğrenmeli, tüm yetkinlikleri kazanmalıyız. Bu yetkinlikleri bir sonraki ürünü geliştirmek için kullanmalıyız. Bu GPT4, GPT-5 yada adı her ne ise kendimizi geliştirip bu henüz yüzeyinde olduğumuz dünyanın derinlerine inmeliyiz. O dünyanın nasıl olacağını belirleyenler arasında olmalıyız.","link":"/GPT-3/"}],"tags":[{"name":"Model","slug":"Model","link":"/tags/Model/"},{"name":"Representation","slug":"Representation","link":"/tags/Representation/"},{"name":"CostFunction","slug":"CostFunction","link":"/tags/CostFunction/"},{"name":"Regression","slug":"Regression","link":"/tags/Regression/"},{"name":"Linear Regression","slug":"Linear-Regression","link":"/tags/Linear-Regression/"},{"name":"Polynomial Regression","slug":"Polynomial-Regression","link":"/tags/Polynomial-Regression/"},{"name":"NLP","slug":"NLP","link":"/tags/NLP/"},{"name":"GPT-3","slug":"GPT-3","link":"/tags/GPT-3/"},{"name":"OpenAI","slug":"OpenAI","link":"/tags/OpenAI/"}],"categories":[{"name":"Machine Learning","slug":"Machine-Learning","link":"/categories/Machine-Learning/"},{"name":"Deep Learning","slug":"Deep-Learning","link":"/categories/Deep-Learning/"}]}