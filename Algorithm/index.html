<!doctype html>
<html lang="tr"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.0"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Debugging Learning Algorithm - KADER DURAK BLOG</title><meta description="Makine öğrenimi modelimizi verilere uydurduktan sonra ne yapmalıyız? Açıkçası, onu değerlendirmemiz ve çalışıp çalışmadığını anlamamız ve özellikle son durumda, iyileştirmek için bazı değişiklikler ya"><meta property="og:type" content="article"><meta property="og:title" content="Debugging Learning Algorithm"><meta property="og:url" content="https://kaderdurak.github.io/Algorithm/"><meta property="og:site_name" content="KADER DURAK BLOG"><meta property="og:description" content="Makine öğrenimi modelimizi verilere uydurduktan sonra ne yapmalıyız? Açıkçası, onu değerlendirmemiz ve çalışıp çalışmadığını anlamamız ve özellikle son durumda, iyileştirmek için bazı değişiklikler ya"><meta property="og:locale" content="tr_TR"><meta property="og:image" content="https://kaderdurak.github.io/Algorithm/aaa.jpg"><meta property="article:published_time" content="2020-11-14T17:02:46.000Z"><meta property="article:modified_time" content="2020-11-14T18:11:37.250Z"><meta property="article:author" content="Kader Durak"><meta property="article:tag" content="Bias"><meta property="article:tag" content="Variance"><meta property="article:tag" content="Underfitting"><meta property="article:tag" content="Overfitting"><meta property="article:tag" content="Model Selection"><meta property="article:tag" content="Cross Validation"><meta property="article:tag" content="Learning Curve"><meta property="article:tag" content="Error Analysis"><meta property="article:tag" content="Model Evaluation Metrics"><meta property="article:tag" content="Accuracy"><meta property="article:tag" content="Precision"><meta property="article:tag" content="Recall"><meta property="article:tag" content="F1 Score"><meta property="article:tag" content="ROC"><meta property="article:tag" content="AUC"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/Algorithm/aaa.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://kaderdurak.github.io/Algorithm/"},"headline":"KADER DURAK BLOG","image":["https://kaderdurak.github.io/Algorithm/aaa.jpg"],"datePublished":"2020-11-14T17:02:46.000Z","dateModified":"2020-11-14T18:11:37.250Z","author":{"@type":"Person","name":"Kader Durak"},"description":"Makine öğrenimi modelimizi verilere uydurduktan sonra ne yapmalıyız? Açıkçası, onu değerlendirmemiz ve çalışıp çalışmadığını anlamamız ve özellikle son durumda, iyileştirmek için bazı değişiklikler ya"}</script><link rel="canonical" href="https://kaderdurak.github.io/Algorithm/"><link rel="icon" href="/img/favicon.ico"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Oxanium:wght@300;400;600&amp;family=Roboto+Mono"><link rel="stylesheet" href="/css/cyberpunk.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="KADER DURAK BLOG" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Anasayfa</a><a class="navbar-item" href="/archives">Arşivler</a><a class="navbar-item" href="/categories">Katergoriler</a><a class="navbar-item" href="/tags">Etiketler</a><a class="navbar-item" href="/about">Hakkımda</a></div><div class="navbar-end"><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="thumbnail" src="/Algorithm/aaa.jpg" alt="Debugging Learning Algorithm"></span></div><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-11-14T17:02:46.000Z" title="2020-11-14T17:02:46.000Z">2020-11-14</time><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">31 dakika read (About 4661 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">Debugging Learning Algorithm</h1><div class="content"><p>Makine öğrenimi modelimizi verilere uydurduktan sonra ne yapmalıyız? Açıkçası, onu değerlendirmemiz ve çalışıp çalışmadığını anlamamız ve özellikle son durumda, iyileştirmek için bazı değişiklikler yapmamız gerekiyor. Makine öğrenimi eğitimi sırasında daha iyi veri yakalama, gerçek zamanlı izleme ve zamanında müdahale ile zamandan ve maliyetlerden tasarruf etmemize yardımcı olacaktır.<a id="more"></a></p>
<h2 id="Evaluating-Error-of-the-Model"><a href="#Evaluating-Error-of-the-Model" class="headerlink" title="Evaluating Error of the Model"></a>Evaluating Error of the Model</h2><p>Modelimizi oluşturmak için aşağıdaki görselde regülarizasyon yapılmış cost fonksiyon formülünü incelenirse:  </p>
<p><img src="/Algorithm/costfuncreg.jpg"></p>
<p>Doğrusal bir regresyon modelimiz olduğunu ve müşterimizin ürünlerinin satışını tahmin etmek istediğimizi varsayalım. Peki ya modelimiz çalışmazsa ya da biz de onun performansını iyileştirmek istiyorsak?</p>
<p>Pekala, farklı yaklaşımlar deneyebiliriz, örneğin:</p>
<ul>
<li>Modele daha fazla eğitim verisi eklenebilir.  → (Yüksek Varyans’ı düzeltir)</li>
<li>Daha küçük bir feature seti kullanılabilir → ( Yüksek Bias’ı düzeltir)</li>
<li>Ek feature örnekleri eklenebilir. → (Yüksek Bias’ı düzeltir)</li>
<li>Polinom derecesi yükseltilebilir. → (Yüksek Bias’ı düzeltir.)</li>
<li>Regularizasyon katsayısı(ƛ) arttırılabilir. → (Yüksek Varyans’ı düzeltir.)</li>
<li>Regularizasyon katsayısı1 azaltılabilir. → (Yüksek Bias’ı düzeltir.)</li>
</ul>
<p>Elbette olasılıklardan biri, farklı parametrelerle rastgele farklı yaklaşımları denemek ve sonucu kontrol etmektir, ancak daha fazla veri elde etmek için büyük çaba gerektiren bazı değişiklikler yaparsak, özellikle zaman kaybı olabilir. Daha fazla veri elde ettikten sonra modelimizin performansının değişmediğini görürsek?</p>
<p>Hangi yolu seçmenin daha iyi olduğunu anlamamıza yardımcı olabilecek bazı değerlendirme veya teşhis yöntemlerimiz var.</p>
<h3 id="Machine-Learning-Diagnostic"><a href="#Machine-Learning-Diagnostic" class="headerlink" title="Machine Learning Diagnostic"></a>Machine Learning Diagnostic</h3><p><strong>Önyargı(Bias):</strong> Bir işlevin öğrenilmesini kolaylaştırmak için bir model tarafından yapılan varsayımlar.<br><strong>Varyans(Variance):</strong> Verilerinizi eğitim verileri üzerinde eğitip ve çok düşük bir hata alırsanız, verileri değiştirdikten sonra aynı modeli değiştirdiğiniz verilerle eğittikten sonra yüksek hata ile karşılaşırsanız, bu varyanstır.</p>
<p><strong>Yüksek varyans:</strong>  Bu sorun, algoritma eğitim verilerine mükemmel bir şekilde uyduğunda ortaya çıkacaktır. Başka bir deyişle, bu, modelin genelleme konusunda kötü olduğu anlamına gelir. Tahmin edilebileceği gibi, bu model görünmeyen veriler üzerinde kötü performans gösterecektir. Bu soruna <strong>aşırı uyum( overfitting)</strong> da denir. Genelleme hatası, modeliniz için önceden görülmemiş veriler üzerinde ölçülen hatadır.</p>
<p><strong>Yüksek sapma:</strong> Bu sorun, algoritma eğitim verilerini doğru şekilde uydurmadığında ortaya çıkar. Başka bir deyişle, bu, modelin girdi özellikleri ve tahmin edilen çıktı arasındaki ilgili ilişkileri kaçırdığı anlamına gelir. Tahmin edilebileceği gibi, bu model eğitim verilerinin kendisinde ve görünmeyen verilerde kötü performans gösterecektir. Bu soruna <strong>yetersiz uyum(high bias)</strong> da denir. Eğitim hatası, modelinizi eğitmek için kullanılan verilerde ölçülen model hatasıdır.</p>
<h3 id="Underfitting"><a href="#Underfitting" class="headerlink" title="Underfitting"></a>Underfitting</h3><p>Bir istatistiksel modelin veya bir makine öğrenme algoritmasının, verilerin temelindeki eğilimi yakalayamadığında yetersiz olduğu söylenir.  <strong>Yetersiz uyum(underfitting),</strong> makine öğrenimi modelimizin doğruluğunu yok eder. Oluşması, modelimizin veya algoritmanın verilere yeterince uymadığı anlamına gelir. Genellikle doğru bir model oluşturmak için daha az veriye sahip olduğumuzda ve ayrıca doğrusal olmayan verilerle doğrusal bir model oluşturmaya çalıştığımızda olur. Bu gibi durumlarda, makine öğrenimi modelinin kuralları bu kadar minimal verilere uygulanamayacak kadar kolay ve esnektir ve bu nedenle model muhtemelen çok sayıda yanlış tahmin yapacaktır. Daha fazla veri kullanılarak ve  özellik seçimi ile özellikleri azaltarak yetersiz uyum önlenebilir.</p>
<p>Yetersiz uyumu azaltma teknikleri:</p>
<ol>
<li>Model karmaşıklığını artırın</li>
<li>Feature Engineering yaparak özelliklerin sayısını artırın</li>
<li>Verilerden gürültüyü kaldırın.</li>
<li>Daha iyi sonuçlar elde etmek için <strong>epoch</strong> sayısını artırın veya eğitim süresini artırın.</li>
</ol>
<h3 id="Overfitting"><a href="#Overfitting" class="headerlink" title="Overfitting"></a>Overfitting</h3><p>Çok fazla veriyle eğittiğimizde istatistiksel bir modelin gereğinden fazla uygun(overfitting) olduğu söylenir. Bir model bu kadar çok veriyle eğitildiğinde, veri setimizdeki gürültü ve hatalı veri girişlerinden öğrenmeye başlar. O zaman model, çok fazla ayrıntı ve gürültü nedeniyle verileri doğru bir şekilde kategorize etmez. Aşırı uyumluluğun nedenleri parametrik olmayan ve doğrusal olmayan yöntemlerdir çünkü bu tür makine öğrenme algoritmaları modeli veri setine dayalı olarak oluşturmada daha fazla özgürlüğe sahiptir ve bu nedenle gerçekten gerçekçi olmayan modeller oluşturabilirler. Aşırı uyumu önlemek için bir çözüm, doğrusal verilerimiz varsa doğrusal bir algoritma kullanmak veya karar ağaçları kullanıyorsak maksimum derinlik gibi parametreleri kullanmaktır.</p>
<p>Aşırı uyumu azaltma teknikleri:</p>
<ol>
<li>Eğitim verilerini artırın.</li>
<li>Model karmaşıklığını azaltın.</li>
<li>Eğitim aşaması sırasında erken durma (eğitim başlar başlamaz eğitim süresi boyunca kaybı gözden geçirin eğer kayıp artmaya başlarsa eğitimi durdurun).</li>
<li>Ridge Regülarizasyonu ve Lasso Regülarizasyonu uygulayın.</li>
<li>Aşırı uyumluluğun üstesinden gelmek için sinir ağlarını kullanın.</li>
</ol>
<h3 id="Just-Fit"><a href="#Just-Fit" class="headerlink" title="Just Fit"></a>Just Fit</h3><p>Aslında modelin 0 hata ile tahmin yapması durumunda verilere iyi uyduğu söylenir. Bu durum, aşırı uydurma(overfitting) ile yetersiz uydurma(underfitting) arasındaki bir noktada elde edilebilir. Bunu anlamak için, eğitim veri setinden öğrenirken modelimizin performansına zamanın geçişiyle bakmamız gerekecek. Zaman geçtikçe modelimiz öğrenmeye devam edecek ve böylece modelin eğitim ve test verilerindeki hatası azalmaya devam edecektir. Çok uzun süre öğrenecek olursa, model gürültü ve daha az kullanışlı ayrıntıların varlığı nedeniyle fazla takılmaya daha yatkın hale gelecektir. Dolayısıyla modelimizin performansı düşecektir. İyi bir uyum elde etmek için, hatanın artmaya başladığı bir noktada duracağız. Bu noktada, modelin eğitim veri kümeleri ve henüz görülmemiş test veri kümemiz konusunda iyi becerilere sahip olduğu söylenebilir.</p>
<p><img src="/Algorithm/f1.jpg"></p>
<p>Başlangıçta verileri iki bölüme ayırmak iyi fikirdir; birincisi modelin eğitimi için kullanılacak ve ikincisi test için kullanılacak. Bu çok kullanışlıdır, özellikle eğitim için modelin doğruluğunun çok yüksek olacağı, test bize modelin o kadar mükemmel olmadığını söyleyecektir.</p>
<p>Yani temelde 70 / 30’u böldük: </p>
<ul>
<li>eğitim seti (genellikle% 70) </li>
<li>test seti (genellikle% 30)</li>
</ul>
<p>Bu bölünme ile, bir hata değeri ile maliyet fonksiyonumuzu en aza indiren eğitim setine dayalı bir model oluşturabiliriz (bu daha iyi çalışacaktır çünkü model, test setinin verilerinden etkilenmeyecektir). Modelimizi oluşturduktan sonra, tahminler ve gerçek değerler arasındaki tutarsızlıklara dayanarak hatayı hesaplayan modelin tahminini kullanarak hatayı test seti ile değerlendireceğiz.</p>
<h3 id="Model-Selection-Problem"><a href="#Model-Selection-Problem" class="headerlink" title="Model Selection Problem"></a>Model Selection Problem</h3><p>Verilere daha iyi uyması için doğru derece polinom nasıl seçilir (doğrusal, ikinci dereceden, kübik….)?<br>D parametresine (bu, polinomun derecesi olacaktır) dayalı olarak farklı modelleri hesaplayabilir ve her biri için test setindeki değer hatasını ölçebilir, daha iyi performans gösteren modeli seçebiliriz (minimum hata). Bu durumda verilerimizi 3 kısma ayırabiliriz:</p>
<ul>
<li>Eğitim Seti (genellikle% 60)</li>
<li>Çapraz Doğrulama Seti(Cross Validation ) - CV (genellikle% 20)</li>
<li>Test Seti (genellikle% 20)</li>
</ul>
<p>Modeli eğitim setimiz ile uyumlu hale getiriyoruz. Ardışık olarak, çapraz doğrulama seti adı verilen ikinci bir veri setindeki gözlemlere yönelik tepkileri tahmin etmek için uyumlu model kullanılır.<br><strong>Çapraz Doğrulama seti(Cross Validation Set)</strong>, modelin hiperparametrelerini ayarlarken eğitim veri setine uyan bir modelin tarafsız bir değerlendirmesini sağlar; bu durumda hiperparametreler, polinom dereceleridir.<br>Hiperparametreler ayarlanınca, Test Seti nihai modelin bir değerlendirmesini sağlamak için kullanılır.<br>Modelimizde değiştirilecek şeyleri seçmemize yardımcı olacak modelimiz için dikkate alınması gereken önemli bir husus, Bias ve Varyans’tır.<br>Farklı polinom derecelerine sahip aynı verilere farklı modeller uydurmanın bir örneğini aşağıdaki görselde görebiliriz.</p>
<ul>
<li>Polinom 1.  derecede, sonuç yetersiz uyuyor(underfitting) (Yüksek Bias), polinom 4. derece ile sonuç aşırı uyuyor(overfitting) (Yüksek Varyans)</li>
</ul>
<p><img src="/Algorithm/f2.jpg"></p>
<h3 id="Learning-Curves"><a href="#Learning-Curves" class="headerlink" title="Learning Curves"></a>Learning Curves</h3><ul>
<li>Bu grafikleri birkaç m değeri için (1’den tüm eğitim setine kadar) oluşturduğumuzda, bize modelimizin problemlerini açıkça gösteren <strong>Öğrenme Eğrileri(Learning Curves)</strong> elde ederiz. Modelimiz yüksek önyargıdan(bias) muzdaripse, JTR ve JVAL, m büyüdükçe çok yakın sonuçlanacak, ancak oldukça büyük bir hata değerine yakınsayacaklar. Bu davranış, yüksek önyargının bir göstergesidir çünkü JTR bile büyük eğitim veri kümeleri için büyüktür. Aslında, aynı zamanda düşük bir varyans durumu ortaya çıkarır. Çünkü tamamen farklı bir setle (validation) değerlendirirken bile hata çok fazla değişmez. Daha fazla veri almanın hatayı azaltmaya yardımcı olmayacağını unutmayın.</li>
</ul>
<p><img src="/Algorithm/f3.jpg"></p>
<ul>
<li>Modelimiz yüksek varyanstan muzdaripse, JTR ve JVAL m büyüdükçe yaklaşacak, ancak bir hata değerine yakınlaşmayacaklar. Bu, (1) iki çizgi arasındaki boşluk nedeniyle yüksek varyansı ve (2) düşük yanlılığı, çünkü çizgilerin nihayetinde birleştiği görünen hata değerinin küçük olduğunu gösterir. Bu durumda, hata çizgileri sonunda daha büyük m değerleri için birleşeceğinden, daha fazla veri almak iyi bir seçenek gibi görünmektedir.</li>
</ul>
<p><img src="/Algorithm/f4.jpg"></p>
<p>Artık modelimizin probleminin (yüksek önyargı veya yüksek varyans) farkındayız, bundan sonra ne yapabiliriz?</p>
<ul>
<li>Sahip olduğunuz veriler için çok karmaşık olduğu için yüksek varyansa (overfits) sahipse:</li>
</ul>
<ol>
<li>Model karmaşıklığına daha iyi uyması için daha fazla eğitim verisi alın</li>
<li>Bazı özellikleri kaldırarak modeli basitleştirin</li>
<li>Düzenlilik(Regülarizasyon) faktörünü artırarak modeli yumuşatın</li>
</ol>
<ul>
<li>Model, sahip olduğunuz veriler için çok basit olduğu için yüksek önyargıya (underfits) sahipse:</li>
</ul>
<ol>
<li>Daha karmaşık bir model oluşturmak için daha fazla özellik edinin (lojistik regresyon veya K-en yakın komşu gibi doğrusal olmayan modeller kullanılarak uygulanabilir.)</li>
<li>Düzenleme(Regülarizasyon) faktörünü azaltarak modeli keskinleştirin</li>
</ol>
<p>Örneğin bir eğitim(trainning) setine tek bir gizli katmana(hidden layer) sahip bir sinir ağı fit  ettiğimizi varsayalım. JVAL değerinin JTR değerinden yüksek çıktığını görürsek ne yapmalıyız? Bir gizli katman daha eklememiz problemimizi çözer mi? Hayır, çünkü modelimiz yüksek varyans problemi yaşıyor ve gizli katman sayısı arttırmak çözüm olmayacaktır. Regülarizasyon kat sayısını(ƛ) arttırmak problemi çözmeye yarar.</p>
<h3 id="Model-Evaluation-Metrics"><a href="#Model-Evaluation-Metrics" class="headerlink" title="Model Evaluation Metrics"></a>Model Evaluation Metrics</h3><p>Sadece makine öğreniminde değil, genel hayatta özellikle iş hayatında da “Ürününüz ne kadar doğru?” veya “Makineniz ne kadar hassas?” gibi sorular duyacaksınız. İnsanlar “Alanındaki en doğru ürün bu!”  veya “Bu makine akla gelebilecek en yüksek hassasiyete sahip!”, her iki yanıtla kendilerini rahat hissediyorlar. Değil mi? Aslında, doğru ve kesin terimler çoğu zaman birbirinin yerine kullanılır. Metinde daha sonra kesin tanımlar vereceğiz, ancak kısaca şunu söyleyebiliriz: Doğruluk, bazı ölçümlerin belirli bir değere yakınlığı için bir ölçü iken, hassasiyet, ölçümlerin birbirine yakınlığıdır.</p>
<p>Bu terimler, Makine Öğreniminde de son derece önemlidir. Makine öğrenimi algoritmalarını değerlendirmek veya sonuçlarını daha iyi hale getirmek için onlara ihtiyacımız var. Dört önemli ölçüm vardır. Bu ölçümler, sınıflandırmaların sonuçlarını değerlendirmek için kullanılır. Ölçümler şunlardır:</p>
<ol>
<li>Accuracy</li>
<li>Precision</li>
<li>Recall</li>
<li>F1-Score</li>
</ol>
<p>Bunlara geçmeden önce <strong>Type I</strong> ve <strong>Type II</strong> hatalarını bilmek gerekiyor.</p>
<p><strong>Type I hatası</strong> , <strong>Yanlış pozitif(False Positive)</strong> ile eşdeğerdir. <strong>Type II hatası</strong>, <strong>Yanlış negatife</strong> eşdeğerdir. Type I hatası, kabul edilmesi gereken hipotezin kabul edilmemesini ifade eder. Type II hata, reddedilmesi gereken hipotezin kabul edilmesidir. Bir Biyometri örneği alalım. Birisi parmaklarını biyometrik tarama için taradığında, Type I hatası, yetkili bir eşleşme olsa bile reddedilme olasılığıdır. Type II hatası, yanlış / yetkisiz bir eşleşmeyle bile kabul olasılığıdır.</p>
<p> Senaryo / Problem 1: Kansere çare olan bir ilaç için tıbbi denemeler</p>
<p> <strong>Type I hatası:</strong> Durum olmadığında bir tedavi bulunduğunu tahmin etme.<br> <strong>Type II hatası:</strong>  Aslında durum söz konusu olduğunda bir tedavinin bulunamayacağını tahmin etmek.</p>
<p>  Bu durumda Type I hatası bir sorun değildir. Daha sonra daha fazla denemeyle düzeltilebilir. Type II hatası daha ciddidir, çünkü hiçbir tedavisi yoktur ve bir tedavi milyonlarca hayatı kurtarabilir.</p>
<p> Senaryo / Problem İfadesi 2: Bir köprünün yapım modeli doğrudur. </p>
<p> <strong>Type I hatası:</strong> Modelin doğru olmadığında doğru olduğunu tahmin etme.<br> <strong>Type II hatası:</strong> Bir modelin doğru olduğunda doğru olmadığını tahmin etme. </p>
<p> Bu durumda Type I hatası büyük bir risktir. Hatalı olan ve köprünün çökmesine neden olabilecek köprünün inşası anlamına gelebilir. Daha fazla modelden geçip yine de doğru olanı bulabildiğimiz için Type II hatası daha az risklidir.</p>
<h3 id="1-Accuracy"><a href="#1-Accuracy" class="headerlink" title="1. Accuracy"></a>1. Accuracy</h3><p><strong>Doğruluk(Accuracy)</strong>, ölçümlerin belirli bir değere yakınlığı için bir ölçüdür.</p>
<h3 id="2-Precision"><a href="#2-Precision" class="headerlink" title="2.Precision"></a>2.Precision</h3><p><strong>Kesinlik(Precision)</strong> ise ölçümlerin birbirine yakınlığıdır, yani belirli bir değere değil. Başka bir deyişle: Aynı miktarda tekrarlanan ölçümlerden bir dizi veri noktasına sahipsek, ortalamaları ölçülen miktarın gerçek değerine yakınsa setin doğru olduğu söylenir. Öte yandan, değerler birbirine yakınsa kümeyi kesin olarak adlandırıyoruz. İki kavram birbirinden bağımsızdır; bu, veri setinin doğru veya kesin olabileceği veya her ikisinin birden olabileceği veya hiçbirinin olamayacağı anlamına gelir. Bunu aşağıdaki diyagramda gösteriyoruz:</p>
<p><img src="/Algorithm/acvspre.jpg"></p>
<h3 id="Confusion-Matrix"><a href="#Confusion-Matrix" class="headerlink" title="Confusion Matrix"></a>Confusion Matrix</h3><p>Bir sınıflandırıcının performansını görselleştirmek için bir sürekli tablo veya hata matrisi olarak da adlandırılan bir <strong>confusion matrix</strong> kullanılır.</p>
<p>Matrisin sütunları, tahmin edilen sınıfların örneklerini temsil eder ve satırlar gerçek sınıfın örneklerini temsil eder. (Not: Bunun tam tersi de olabilir.)</p>
<p>İkili sınıflandırma durumunda, tabloda 2 satır ve 2 sütun vardır.</p>
<p>Konsepti bir örnekle göstermek istiyoruz.</p>
<p>Misal:<br><img src="/Algorithm/conmat.jpg"><br>Bu, sınıflandırıcının 42 durumda bir kediyi doğru şekilde tahmin ettiği ve 8 kedi örneğini köpek olarak yanlış tahmin ettiği anlamına gelir. Köpek olarak 32 örneği doğru bir şekilde tahmin etti. 18 vaka yanlışlıkla köpek yerine kedi olarak tahmin edilmiş.</p>
<p><strong>Doğruluk(Accuracy),</strong> bir sınıflandırıcı tarafından yapılan doğru tahminlerin (hem Gerçek pozitifler (TP) hem de Gerçek negatifler (TN)) bölümünün, Yanlış pozitifler (FP) dahil sınıflandırıcı tarafından yapılan tüm tahminlerin toplamına bölünmesi olarak tanımlanan istatistiksel bir ölçüdür. ve Yanlış negatifler (FN). Bu nedenle, ikili doğruluğu ölçmenin formülü şöyledir:<br><img src="/Algorithm/accuracy.jpg"></p>
<p>TP = True positive; FP = False positive; TN = True negative; FN = False negative<br><img src="/Algorithm/conmat2.jpg"></p>
<p>Şimdi kedi-köpek sınıflandırması sonuçlarının doğruluğunu hesaplayacağız. “True” ve “False” yerine burada “cat” ve “dog” görüyoruz. Doğruluğu şu şekilde hesaplayabiliriz:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">TP = <span class="number">42</span></span><br><span class="line">TN = <span class="number">32</span></span><br><span class="line">FP = <span class="number">8</span></span><br><span class="line">FN = <span class="number">18</span></span><br><span class="line"></span><br><span class="line">Accuracy = (TP + TN)/(TP + TN + FP + FN)</span><br><span class="line">print(Accuracy)</span><br></pre></td></tr></table></figure>

<p><strong>Kesinlik(Precision),</strong> doğru olarak tanımlanan pozitif vakaların tahmin edilen tüm pozitif vakalara, yani pozitif olarak tahmin edilen doğru ve yanlış vakalara oranıdır. Kesinlik, sorguyla ilgili alınan belgelerin oranıdır. Formül:<br><img src="/Algorithm/precision.jpg"><br><img src="/Algorithm/conmat3.jpg"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">TP = <span class="number">114</span></span><br><span class="line">FP = <span class="number">14</span></span><br><span class="line"><span class="comment"># FN (0) ve TN (12) bu formülde gerekmiyor!</span></span><br><span class="line">precision = TP / (TP + FP)</span><br><span class="line">print(<span class="string">f"precision: <span class="subst">&#123;precision:<span class="number">4.2</span>f&#125;</span>"</span>)</span><br></pre></td></tr></table></figure>
<h3 id="3-Recall"><a href="#3-Recall" class="headerlink" title="3. Recall"></a>3. Recall</h3><p><strong>Duyarlılık(recall)</strong>, doğru olarak tanımlanan pozitif vakaların, “False Negatives” ve “True Positives” toplamı olan tüm gerçek pozitif vakalara oranıdır.</p>
<p><img src="/Algorithm/recall.jpg"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">TP = <span class="number">114</span></span><br><span class="line">FN = <span class="number">0</span></span><br><span class="line"><span class="comment"># FT (14) ve TN (12) bu formülde gerekmiyor!</span></span><br><span class="line">recall = TP / (TP + FN)</span><br><span class="line">print(<span class="string">f"recall: <span class="subst">&#123;recall:<span class="number">4.2</span>f&#125;</span>"</span>)</span><br></pre></td></tr></table></figure>
<p>1 değeri, spam olmayan mesajların yanlışlıkla spam olarak etiketlenmediği anlamına gelir. İyi bir spam filtresi için bu değerin 1 olması önemlidir.</p>
<h3 id="4-F1-Score"><a href="#4-F1-Score" class="headerlink" title="4. F1 Score"></a>4. F1 Score</h3><p>F1 skoru, harmonik ortalamayı kullanarak precision ve recall birleştiren tek metriktir.<br>Son metriğimiz F1 skoru formülü:</p>
<p><img src="/Algorithm/f1score.jpg"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">TP = <span class="number">42</span></span><br><span class="line">TN = <span class="number">32</span></span><br><span class="line">FP = <span class="number">8</span></span><br><span class="line">FN = <span class="number">18</span></span><br><span class="line">precision = TP / (TP + FP)</span><br><span class="line">accuracy = (TP + TN)/(TP + TN + FP + FN)</span><br><span class="line">recall = TP / (TP + FN)</span><br><span class="line">f1_score = <span class="number">2</span> * precision * recall / (precision + recall)</span><br><span class="line">print(<span class="string">f"accuracy: <span class="subst">&#123;accuracy:<span class="number">4.2</span>f&#125;</span>"</span>,</span><br><span class="line">    <span class="string">f"precision: <span class="subst">&#123;precision:<span class="number">4.2</span>f&#125;</span>"</span>,</span><br><span class="line">    <span class="string">f"recall: <span class="subst">&#123;recall:<span class="number">4.2</span>f&#125;</span>"</span>,</span><br><span class="line">    <span class="string">f"f1_score: <span class="subst">&#123;f1_score:<span class="number">4.2</span>f&#125;</span>"</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>Precision ve recall, son derece önemli iki model değerlendirme ölçütüdür. Precision, sonuçlarınıza uygun olanların yüzdesini ifade ederken, recall, algoritmanız tarafından doğru bir şekilde sınıflandırılan toplam alakalı sonuçların yüzdesini ifade eder. Ne yazık ki, her iki metriği aynı anda maksimize etmek mümkün değildir, çünkü biri diğerinin maliyetine sahiptir. Basit olması için, F-1 skoru adı verilen ve hassasiyet ve geri çağırmanın harmonik bir ortalaması olan başka bir metrik mevcuttur. Hem kesinliğin hem de geri çağırmanın önemli olduğu problemler için, bu F-1 puanını en üst düzeye çıkaran bir model seçilebilir. Diğer sorunlar için, bir değiş tokuşa ihtiyaç vardır ve kesinliğin mi yoksa geri çağırmanın mı maksimize edileceğine karar verilmelidir.</p>
<h3 id="ROC-Curve"><a href="#ROC-Curve" class="headerlink" title="ROC Curve"></a>ROC Curve</h3><p>Bir <strong>ROC curve (receiver operating characteristic curve)</strong>, tüm sınıflandırma eşiklerinde bir sınıflandırma modelinin performansını gösteren bir grafiktir. Bu eğri iki parametreyi çizer:</p>
<ul>
<li>True Positive Rate</li>
<li>False Positive Rate</li>
</ul>
<p><strong>True Positive Rate (TPR),</strong> recall’ın eşanlamlısıdır ve bu nedenle aşağıdaki gibi tanımlanır:<br><img src="/Algorithm/tpr.jpg"></p>
<p><strong>False Positive Rate (FPR)</strong> aşağıdaki şekilde tanımlanır:<br><img src="/Algorithm/fpr.jpg"></p>
<p>Bir ROC eğrisi, TPR’ye karşı FPR’yi farklı sınıflandırma eşiklerinde çizer. Sınıflandırma eşiğini düşürmek için daha fazla öğeyi pozitif olarak sınıflandırır, böylece hem False Positive’ler hem de True Positive’ler artar. Aşağıdaki şekil tipik bir ROC eğrisini göstermektedir.<br><img src="/Algorithm/roc.jpg"></p>
<p>Bir ROC eğrisindeki noktaları hesaplamak için, bir lojistik regresyon modelini birçok kez farklı sınıflandırma eşikleri ile değerlendirebilirdik, ancak bu verimsiz olacaktır. Neyse ki, bu bilgiyi bize sağlayabilen AUC adında verimli, sıralama tabanlı bir algoritma var.</p>
<h3 id="AUC"><a href="#AUC" class="headerlink" title="AUC"></a>AUC</h3><p><strong>AUC(Area Under the ROC Curve),</strong> (0,0) ‘dan (1,1)’ e kadar tüm ROC eğrisinin altındaki iki boyutlu alanın tamamını ölçer (integral hesabı düşünün).<br><img src="/Algorithm/auc.jpg"></p>
<p>AUC, tüm olası sınıflandırma eşiklerinde toplu bir performans ölçüsü sağlar. AUC’yi yorumlamanın bir yolu, modelin rastgele bir pozitif örneği rastgele bir negatif örnekten daha yüksek sıralama olasılığıdır. Örneğin, lojistik regresyon tahminlerinin artan sırasına göre soldan sağa düzenlenen aşağıdaki örnekler verildiğinde:</p>
<p><img src="/Algorithm/auc2.jpg"></p>
<p>AUC, rastgele bir pozitif (yeşil) örneğin rastgele bir negatif (kırmızı) örneğin sağına yerleştirilme olasılığını temsil eder.<br>AUC, 0 ile 1 arasındadır. Tahminleri% 100 yanlış olan bir modelin AUC değeri 0,0; Tahminleri% 100 doğru olan birinin AUC’si 1,0’dır. </p>
<p>AUC, aşağıdaki iki nedenden dolayı arzu edilir: </p>
<ul>
<li>AUC, ölçekle değişmez. Kesin değerlerinden ziyade tahminlerin ne kadar iyi sıralandığını ölçer. </li>
<li>AUC, sınıflandırma eşiği ile değişmez. Hangi sınıflandırma eşiğinin seçildiğine bakılmaksızın modelin tahminlerinin kalitesini ölçer.</li>
</ul>
<p>Bununla birlikte, bu iki neden de bazı kullanım durumlarında AUC’nin yararlılığını sınırlayabilecek uyarılarla birlikte gelir:</p>
<p><strong>Ölçek değişmezliği her zaman arzu edilen bir şey değildir.</strong> Örneğin, bazen gerçekten iyi kalibre edilmiş olasılık çıktılarına ihtiyacımız olur ve AUC bize bundan bahsetmez. </p>
<p><strong>Sınıflandırma eşiği değişmezliği her zaman arzu edilen bir durum değildir.</strong> Yanlış negatiflere karşı yanlış pozitiflerin maliyetinde büyük farklılıklar olduğu durumlarda, bir tür sınıflandırma hatasını en aza indirmek kritik olabilir. Örneğin, e-posta spam tespiti yaparken, muhtemelen false positive’leri en aza indirmeye öncelik vermek istersiniz (bu, false negative’lerde önemli bir artışla sonuçlansa bile). AUC, bu tür optimizasyon için kullanışlı bir ölçüm değildir.</p>
</div><div class="article-tags size-small mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/Bias/">Bias</a><a class="link-muted mr-2" rel="tag" href="/tags/Variance/">Variance</a><a class="link-muted mr-2" rel="tag" href="/tags/Underfitting/">Underfitting</a><a class="link-muted mr-2" rel="tag" href="/tags/Overfitting/">Overfitting</a><a class="link-muted mr-2" rel="tag" href="/tags/Model-Selection/">Model Selection</a><a class="link-muted mr-2" rel="tag" href="/tags/Cross-Validation/">Cross Validation</a><a class="link-muted mr-2" rel="tag" href="/tags/Learning-Curve/">Learning Curve</a><a class="link-muted mr-2" rel="tag" href="/tags/Error-Analysis/">Error Analysis</a><a class="link-muted mr-2" rel="tag" href="/tags/Model-Evaluation-Metrics/">Model Evaluation Metrics</a><a class="link-muted mr-2" rel="tag" href="/tags/Accuracy/">Accuracy</a><a class="link-muted mr-2" rel="tag" href="/tags/Precision/">Precision</a><a class="link-muted mr-2" rel="tag" href="/tags/Recall/">Recall</a><a class="link-muted mr-2" rel="tag" href="/tags/F1-Score/">F1 Score</a><a class="link-muted mr-2" rel="tag" href="/tags/ROC/">ROC</a><a class="link-muted mr-2" rel="tag" href="/tags/AUC/">AUC</a></div><link rel="stylesheet" href="/css/share.css"><div><a class="resp-sharing-button__link" href="https://twitter.com/intent/tweet/?text=Debugging Learning Algorithm&amp;url=https://kaderdurak.github.io//Algorithm/" target="_blank" rel="noopener" aria-label=""><div class="resp-sharing-button resp-sharing-button--twitter resp-sharing-button--small"><div class="resp-sharing-button__icon resp-sharing-button__icon--solidcircle" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 0C5.38 0 0 5.38 0 12s5.38 12 12 12 12-5.38 12-12S18.62 0 12 0zm5.26 9.38v.34c0 3.48-2.64 7.5-7.48 7.5-1.48 0-2.87-.44-4.03-1.2 1.37.17 2.77-.2 3.9-1.08-1.16-.02-2.13-.78-2.46-1.83.38.1.8.07 1.17-.03-1.2-.24-2.1-1.3-2.1-2.58v-.05c.35.2.75.32 1.18.33-.7-.47-1.17-1.28-1.17-2.2 0-.47.13-.92.36-1.3C7.94 8.85 9.88 9.9 12.06 10c-.04-.2-.06-.4-.06-.6 0-1.46 1.18-2.63 2.63-2.63.76 0 1.44.3 1.92.82.6-.12 1.95-.27 1.95-.27-.35.53-.72 1.66-1.24 2.04z"></path></svg></div></div></a><a class="resp-sharing-button__link" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://kaderdurak.github.io//Algorithm/&amp;title=Debugging Learning Algorithm&amp;source=https://kaderdurak.github.io//Algorithm/" target="_blank" rel="noopener" aria-label=""><div class="resp-sharing-button resp-sharing-button--linkedin resp-sharing-button--small"><div class="resp-sharing-button__icon resp-sharing-button__icon--solidcircle" aria-hidden="true"><svg version="1.1" x="0px" y="0px" width="24px" height="24px" viewBox="0 0 24 24" enable-background="new 0 0 24 24"><path d="M12,0C5.383,0,0,5.383,0,12s5.383,12,12,12s12-5.383,12-12S18.617,0,12,0z M9.5,16.5h-2v-7h2V16.5z M8.5,7.5 c-0.553,0-1-0.448-1-1c0-0.552,0.447-1,1-1s1,0.448,1,1C9.5,7.052,9.053,7.5,8.5,7.5z M18.5,16.5h-3V13c0-0.277-0.225-0.5-0.5-0.5 c-0.276,0-0.5,0.223-0.5,0.5v3.5h-3c0,0,0.031-6.478,0-7h3v0.835c0,0,0.457-0.753,1.707-0.753c1.55,0,2.293,1.12,2.293,3.296V16.5z"></path></svg></div></div></a><a class="resp-sharing-button__link" href="mailto:?subject=Debugging Learning Algorithm&amp;body=Bunu mutlaka okumalısın. https://kaderdurak.github.io//Algorithm/" target="_self" rel="noopener" aria-label=""><div class="resp-sharing-button resp-sharing-button--email resp-sharing-button--small"><div class="resp-sharing-button__icon resp-sharing-button__icon--solidcircle" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 0C5.38 0 0 5.38 0 12s5.38 12 12 12 12-5.38 12-12S18.62 0 12 0zm8 16c0 1.1-.9 2-2 2H6c-1.1 0-2-.9-2-2V8c0-1.1.9-2 2-2h12c1.1 0 2 .9 2 2v8z"></path><path d="M17.9 8.18c-.2-.2-.5-.24-.72-.07L12 12.38 6.82 8.1c-.22-.16-.53-.13-.7.08s-.15.53.06.7l3.62 2.97-3.57 2.23c-.23.14-.3.45-.15.7.1.14.25.22.42.22.1 0 .18-.02.27-.08l3.85-2.4 1.06.87c.1.04.2.1.32.1s.23-.06.32-.1l1.06-.9 3.86 2.4c.08.06.17.1.26.1.17 0 .33-.1.42-.25.15-.24.08-.55-.15-.7l-3.57-2.22 3.62-2.96c.2-.2.24-.5.07-.72z"></path></svg></div></div></a><a class="resp-sharing-button__link" href="whatsapp://send?text=Debugging Learning Algorithmhttps://kaderdurak.github.io//Algorithm/" target="_blank" rel="noopener" aria-label=""><div class="resp-sharing-button resp-sharing-button--whatsapp resp-sharing-button--small"><div class="resp-sharing-button__icon resp-sharing-button__icon--solidcircle" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" height="24" width="24" viewBox="0 0 24 24"><path d="m12 0c-6.6 0-12 5.4-12 12s5.4 12 12 12 12-5.4 12-12-5.4-12-12-12zm0 3.8c2.2 0 4.2 0.9 5.7 2.4 1.6 1.5 2.4 3.6 2.5 5.7 0 4.5-3.6 8.1-8.1 8.1-1.4 0-2.7-0.4-3.9-1l-4.4 1.1 1.2-4.2c-0.8-1.2-1.1-2.6-1.1-4 0-4.5 3.6-8.1 8.1-8.1zm0.1 1.5c-3.7 0-6.7 3-6.7 6.7 0 1.3 0.3 2.5 1 3.6l0.1 0.3-0.7 2.4 2.5-0.7 0.3 0.099c1 0.7 2.2 1 3.4 1 3.7 0 6.8-3 6.9-6.6 0-1.8-0.7-3.5-2-4.8s-3-2-4.8-2zm-3 2.9h0.4c0.2 0 0.4-0.099 0.5 0.3s0.5 1.5 0.6 1.7 0.1 0.2 0 0.3-0.1 0.2-0.2 0.3l-0.3 0.3c-0.1 0.1-0.2 0.2-0.1 0.4 0.2 0.2 0.6 0.9 1.2 1.4 0.7 0.7 1.4 0.9 1.6 1 0.2 0 0.3 0.001 0.4-0.099s0.5-0.6 0.6-0.8c0.2-0.2 0.3-0.2 0.5-0.1l1.4 0.7c0.2 0.1 0.3 0.2 0.5 0.3 0 0.1 0.1 0.5-0.099 1s-1 0.9-1.4 1c-0.3 0-0.8 0.001-1.3-0.099-0.3-0.1-0.7-0.2-1.2-0.4-2.1-0.9-3.4-3-3.5-3.1s-0.8-1.1-0.8-2.1c0-1 0.5-1.5 0.7-1.7s0.4-0.3 0.5-0.3z"></path></svg></div></div></a><a class="resp-sharing-button__link" href="https://telegram.me/share/url?text=Debugging Learning Algorithm&amp;url=https://kaderdurak.github.io//Algorithm/" target="_blank" rel="noopener" aria-label=""><div class="resp-sharing-button resp-sharing-button--telegram resp-sharing-button--small"><div class="resp-sharing-button__icon resp-sharing-button__icon--solidcircle" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 23.5c6.35 0 11.5-5.15 11.5-11.5S18.35.5 12 .5.5 5.65.5 12 5.65 23.5 12 23.5zM2.505 11.053c-.31.118-.505.738-.505.738s.203.62.513.737l3.636 1.355 1.417 4.557a.787.787 0 0 0 1.25.375l2.115-1.72a.29.29 0 0 1 .353-.01L15.1 19.85a.786.786 0 0 0 .746.095.786.786 0 0 0 .487-.573l2.793-13.426a.787.787 0 0 0-1.054-.893l-15.568 6z" fill-rule="evenodd"></path></svg></div></div></a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/ANN/"><span class="level-item">Artificial Neural Networks</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatar.png" alt="Kader Durak"></figure><p class="title is-size-4 is-block line-height-inherit">Kader Durak</p><p class="is-size-6 is-block">Data Science Enthusiast</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>İstanbul</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Gönderiler</p><a href="/archives"><p class="title">8</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Kategoriler</p><a href="/categories"><p class="title">2</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Etiketler</p><a href="/tags"><p class="title">46</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/KaderDurak" target="_blank" rel="noopener">TAKİP ET</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/KaderDurak/"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="HackerRank" href="http://hackerrank.com/"><i class="fab fa-hackerrank"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Kaggle" href="https://www.kaggle.com/"><i class="fab fa-kaggle"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="http://medium.com/"><i class="fab fa-medium"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Faydalı Linkler</h3><ul class="menu-list"><li><a class="level is-mobile is-mobile" href="https://datacamp.com/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">DataCamp</span></span><span class="level-right"><span class="level-item tag">datacamp.com</span></span></a></li><li><a class="level is-mobile is-mobile" href="https://coursera.org/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Coursera</span></span><span class="level-right"><span class="level-item tag">coursera.org</span></span></a></li><li><a class="level is-mobile is-mobile" href="https://udemy.com/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Udemy</span></span><span class="level-right"><span class="level-item tag">udemy.com</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Arşivler</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2020/11/"><span class="level-start"><span class="level-item">Kasım 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/10/"><span class="level-start"><span class="level-item">Ekim 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/09/"><span class="level-start"><span class="level-item">Eylül 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/08/"><span class="level-start"><span class="level-item">Ağustos 2020</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/07/"><span class="level-start"><span class="level-item">Temmuz 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Kategoriler</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/Deep-Learning/"><span class="level-start"><span class="level-item">Deep Learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Machine-Learning/"><span class="level-start"><span class="level-item">Machine Learning</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">Son</h3><article class="media"><a class="media-left" href="/Algorithm/"><p class="image is-64x64"><img class="thumbnail" src="/Algorithm/aaa.jpg" alt="Debugging Learning Algorithm"></p></a><div class="media-content size-small"><p><time dateTime="2020-11-14T17:02:46.000Z">2020-11-14</time></p><p class="title is-6"><a class="link-muted" href="/Algorithm/">Debugging Learning Algorithm</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></p></div></article><article class="media"><a class="media-left" href="/ANN/"><p class="image is-64x64"><img class="thumbnail" src="/ANN/2f507880818753.5cec871f2d771.png" alt="Artificial Neural Networks"></p></a><div class="media-content size-small"><p><time dateTime="2020-11-04T14:45:43.000Z">2020-11-04</time></p><p class="title is-6"><a class="link-muted" href="/ANN/">Artificial Neural Networks</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></p></div></article><article class="media"><a class="media-left" href="/Classification/"><p class="image is-64x64"><img class="thumbnail" src="/Classification/b926c450441609.58d0ca93f0421.png" alt="Classification"></p></a><div class="media-content size-small"><p><time dateTime="2020-10-21T08:42:30.000Z">2020-10-21</time></p><p class="title is-6"><a class="link-muted" href="/Classification/">Classification</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></p></div></article><article class="media"><a class="media-left" href="/Featurescaling/"><p class="image is-64x64"><img class="thumbnail" src="/Featurescaling/f3dba971783255.Y3JvcCw4MDgsNjMyLDI4Niww.png" alt="Feature Scaling"></p></a><div class="media-content size-small"><p><time dateTime="2020-09-13T19:03:45.000Z">2020-09-13</time></p><p class="title is-6"><a class="link-muted" href="/Featurescaling/">Feature Scaling</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></p></div></article><article class="media"><a class="media-left" href="/GPT-3/"><p class="image is-64x64"><img class="thumbnail" src="/GPT-3/openai-23.gif" alt="GPT-3"></p></a><div class="media-content size-small"><p><time dateTime="2020-08-20T10:30:10.000Z">2020-08-20</time></p><p class="title is-6"><a class="link-muted" href="/GPT-3/">GPT-3</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Etiketler</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/AUC/"><span class="tag">AUC</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Accuracy/"><span class="tag">Accuracy</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Artificial-Neural-Networks-ANNs/"><span class="tag">Artificial Neural Networks (ANNs)</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Back-Propagation-Algorithm/"><span class="tag">Back Propagation Algorithm</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bayes-Networks/"><span class="tag">Bayes Networks</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bias/"><span class="tag">Bias</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Binary-Classification/"><span class="tag">Binary Classification</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Classification/"><span class="tag">Classification</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CostFunction/"><span class="tag">CostFunction</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Cross-Validation/"><span class="tag">Cross Validation</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Decision-Boundary/"><span class="tag">Decision Boundary</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Directed-Acyclic-Graphs-DAGs/"><span class="tag">Directed Acyclic Graphs (DAGs)</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Error-Analysis/"><span class="tag">Error Analysis</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/F1-Score/"><span class="tag">F1 Score</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Feature-Scaling/"><span class="tag">Feature Scaling</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FeedBack-Neural-Network/"><span class="tag">FeedBack Neural Network</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FeedForward-Neural-Networks/"><span class="tag">FeedForward Neural Networks</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GPT-3/"><span class="tag">GPT-3</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hidden-Layer/"><span class="tag">Hidden Layer</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Input-Layer/"><span class="tag">Input Layer</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Learning-Curve/"><span class="tag">Learning Curve</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linear-Regression/"><span class="tag">Linear Regression</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Logistic-Regression/"><span class="tag">Logistic Regression</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Max-Abs-Scaler/"><span class="tag">Max Abs Scaler</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Min-Max-Scaler/"><span class="tag">Min-Max Scaler</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Model/"><span class="tag">Model</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Model-Evaluation-Metrics/"><span class="tag">Model Evaluation Metrics</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Model-Selection/"><span class="tag">Model Selection</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Multiclass-Classification/"><span class="tag">Multiclass Classification</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/OpenAI/"><span class="tag">OpenAI</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Output-Layer/"><span class="tag">Output Layer</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Overfitting/"><span class="tag">Overfitting</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Polynomial-Regression/"><span class="tag">Polynomial Regression</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Power-Transformer-Scaler/"><span class="tag">Power Transformer Scaler</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Precision/"><span class="tag">Precision</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Quantile-Transformer-Scaler/"><span class="tag">Quantile Transformer Scaler</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ROC/"><span class="tag">ROC</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Recall/"><span class="tag">Recall</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Regression/"><span class="tag">Regression</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Representation/"><span class="tag">Representation</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Robust-Scaler/"><span class="tag">Robust Scaler</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Standard-Scaler/"><span class="tag">Standard Scaler</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Underfitting/"><span class="tag">Underfitting</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Unit-Vector-Scaler/"><span class="tag">Unit Vector Scaler</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Variance/"><span class="tag">Variance</span><span class="tag is-grey-lightest">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="KADER DURAK BLOG" height="28"></a><p class="size-small"><span>&copy; 2020 Kader Durak</span></p></div><p>Yazara ait blog yazıları eğitim amaçlıdır.<br>i&#039;m cyborg but that&#039;s ok</p><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("tr");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'https://kaderdurak.github.io',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="Zurück nach oben" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Bir şeyler yaz..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Bir şeyler yaz...","untitled":"(Untitled)","posts":"Gönderiler","pages":"Pages","categories":"Kategoriler","tags":"Etiketler"});
        });</script></body></html>