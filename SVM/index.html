<!doctype html>
<html lang="tr"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.0"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Support Vector Machines (SVMs) - KADER DURAK BLOG</title><meta description="Vladimir Vapnik  Sovyet Birliği’nden Amerika’ya 1991’ de göç ediyor. Kimse çalışmaları hakkında birşey bilmiyordu. Aslında Ph.D yaparken Moskova’da SVM’leri 1960’lı yılların başında  yazmıştı.Ama o za"><meta property="og:type" content="article"><meta property="og:title" content="Support Vector Machines (SVMs)"><meta property="og:url" content="https://kaderdurak.github.io/SVM/"><meta property="og:site_name" content="KADER DURAK BLOG"><meta property="og:description" content="Vladimir Vapnik  Sovyet Birliği’nden Amerika’ya 1991’ de göç ediyor. Kimse çalışmaları hakkında birşey bilmiyordu. Aslında Ph.D yaparken Moskova’da SVM’leri 1960’lı yılların başında  yazmıştı.Ama o za"><meta property="og:locale" content="tr_TR"><meta property="og:image" content="https://kaderdurak.github.io/SVM/bas.png"><meta property="article:published_time" content="2020-12-03T08:42:30.000Z"><meta property="article:modified_time" content="2020-12-03T10:32:38.223Z"><meta property="article:author" content="Kader Durak"><meta property="article:tag" content="Support Vector Machine"><meta property="article:tag" content="Lagrange Multipliers"><meta property="article:tag" content="Soft Margin Formulation"><meta property="article:tag" content="Kernels Tricks"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/SVM/bas.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://kaderdurak.github.io/SVM/"},"headline":"KADER DURAK BLOG","image":["https://kaderdurak.github.io/SVM/bas.png"],"datePublished":"2020-12-03T08:42:30.000Z","dateModified":"2020-12-03T10:32:38.223Z","author":{"@type":"Person","name":"Kader Durak"},"description":"Vladimir Vapnik  Sovyet Birliği’nden Amerika’ya 1991’ de göç ediyor. Kimse çalışmaları hakkında birşey bilmiyordu. Aslında Ph.D yaparken Moskova’da SVM’leri 1960’lı yılların başında  yazmıştı.Ama o za"}</script><link rel="canonical" href="https://kaderdurak.github.io/SVM/"><link rel="icon" href="/img/favicon.ico"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Oxanium:wght@300;400;600&amp;family=Roboto+Mono"><link rel="stylesheet" href="/css/cyberpunk.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="KADER DURAK BLOG" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Anasayfa</a><a class="navbar-item" href="/archives">Arşivler</a><a class="navbar-item" href="/categories">Katergoriler</a><a class="navbar-item" href="/tags">Etiketler</a><a class="navbar-item" href="/about">Hakkımda</a></div><div class="navbar-end"><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="thumbnail" src="/SVM/bas.png" alt="Support Vector Machines (SVMs)"></span></div><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-12-03T08:42:30.000Z" title="2020-12-03T08:42:30.000Z">2020-12-03</time><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item">23 dakika read (About 3454 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">Support Vector Machines (SVMs)</h1><div class="content"><p>Vladimir Vapnik  Sovyet Birliği’nden Amerika’ya 1991’ de göç ediyor. Kimse çalışmaları hakkında birşey bilmiyordu. Aslında Ph.D yaparken Moskova’da SVM’leri 1960’lı yılların başında  yazmıştı.Ama o zamanlar bilgisayar olmadığı için test edecek imkanı bulamamıştı.Sonraki 25 yıl Sovyet Birliği’nde Onkoloji Enstitüsünde çalıştı bir yandan da başvurular yapıyordu. Bell Labs’ta birileri onu keşfetti ve Amerika’ya davet etti. Sonrasında Amerika’ya taşınan Vapnik 3 makalesini NIPS (Neural Information Processing System) Journal’a gönderdi ve hepsi reddedildi.<br>Hala buna üzgün ama bu onu motive etti. 1992-1993 yıllarında Bell Labs hand-written recognation ile ilgileniyordu. Vapnik neural networkün yetersiz olduğu SVM’lerin bu konuda daha iyi olduğuna dair çalışma arkadaşlarıyla iddiaya girdi. Çalışma arkadaşları bu konuda SVM kernelde n=2 olarak denediler ve sonuç lineer olmayan verileri sınıflandırmada harikaydı. Peki ik defa mı birileri kernel kullandı? Aslında Vapnik tezinde yazmıştı ama bunun önemli olduğunu düşünmemişti. Vapnik kernel fikrini yeniden canlandırdı ve geliştirmeye başladı. Vapnik’in kernelleri anlaması ve bunların önemini takdir etmesi arasında 30 yıl geçti ve işler böyle yürür. </p>
<p>Harika fikirlerin ardından hiçbir şeyin olmadığı uzun dönemler gelir. Ardından orjinal fikrin biraz değişimiyle büyük bir güce sahip gibi göründüğü bir aydınlanma anı gelir. 90’ların başına kadar kimsenin adını bile duymadığı Vapnik, bugün makine öğrenmesiyle uğraşan herkesin tanıdığı bir üne kavuştu. Gelin Vapnik’in dünyaya kazandırdığı SVM ve Kernel kavramına yakından bakalım.</p>
<a id="more"></a>

<h3 id="Support-Vector-Machines-SVMs"><a href="#Support-Vector-Machines-SVMs" class="headerlink" title="Support Vector Machines(SVMs)"></a>Support Vector Machines(SVMs)</h3><p>SVM’ler, makine öğrenimi algoritmalarında sınıflandırma için en popüler algoritmadır. SVM’lerin matematiksel arkaplanı, iki sınıf arasındaki geometrik ayrım için temel bloğu oluşturmada mükemmeldir.</p>
<p>Destek Vektör Makineleri(SVM), sınıflandırma ve regresyon analizi için verilerin analizini sağlayan bir tür denetimli makine öğrenme algoritmasıdır. Regresyon için kullanılabilirlerse de, SVM çoğunlukla sınıflandırma için kullanılır. N boyutlu uzayda çizim yapıyoruz. Her özelliğin değeri aynı zamanda belirli koordinatın değeridir. Ardından, iki sınıf arasında farklılaşan ideal hiper düzlemi buluyoruz. Bu destek vektörleri, bireysel gözlemlerin koordinat temsilleridir. İki sınıfı ayırmak için bir sınır yöntemidir.<br><img src="/SVM/1.jpg"></p>
<p>Destek vektör makinelerinin çalışmasının arkasındaki temel ilke basittir. Veri kümesini sınıflara ayıran bir hiper düzlem oluşturun. Örnek bir problemle başlayalım. Verilen bir veri kümesi için kırmızı üçgenleri mavi dairelerden sınıflandırmanız gerektiğini varsayalım. Amacınız, verileri iki sınıfa ayıran, kırmızı üçgenler ve mavi daireler arasında bir ayrım oluşturan bir çizgi oluşturmaktır.<br><img src="/SVM/2.jpg"></p>
<p>İki sınıfı birbirinden ayıran net bir çizgi varsayılabilirken, bu işi yapabilecek birçok satır olabilir. Bu nedenle, bu görevi yerine getirebilecek üzerinde anlaşabileceğiniz tek bir satır yoktur. İki sınıf arasında ayrım yapabilen bazı satırları aşağıdaki gibi görselleştirelim:<br><img src="/SVM/3.jpg"></p>
<p>SVM’ye göre, her iki sınıfa da en yakın olan noktaları bulmalıyız. Bu noktalar, destek vektörleri olarak bilinir. Bir sonraki adımda, ayıran düzlemimiz ile destek vektörleri arasındaki yakınlığı buluyoruz. Noktalar ve bölme çizgisi arasındaki mesafe, <strong>margin</strong> olarak bilinir. Bir SVM algoritmasının amacı, bu marjı maksimize etmektir.<strong>Margin</strong> maksimuma ulaştığında, hiper düzlem en uygun olanı olur.<br><img src="/SVM/4.jpg"></p>
<p>Pekala bu marjini adım adım hesaplamaya başlayalım.</p>
<p><img src="/SVM/6.jpg"></p>
<p>Görselde olduğu gibi (+) ve (-) leri ayırmamız gerekiyor böylece Decision Boundary çizmemizi sağlayacak eğrimizi bulabiliriz. Gutter denilen aslında görselde caddeye benzeyen şekle dik olan veya şeklin medyanına doğru giden uzunluğunu bilmediğimiz w vektörümüz olduğunu varsayalım. w vektörümüzden ayrılan ve caddenin hangi tarafında olduğunu bilmediğimiz u vektörümüz  olduğunu düşünelim. Şimdi asıl ilgilendiğimiz şey bilinmeyenin sokağın sağ tarafında mı yoksa sol tarafında mı olduğu. Bu u vektörünü sokağa dik olan w vektörüne yansıtmak istiyoruz. Çünkü o zaman bu yöndeki mesafeye veya bu yönde bununla orantılı bir sayıya sahip olacağız. Ve ne kadar uzağa gidersek, sokağın sağ tarafına o kadar yaklaşırız.<br><img src="/SVM/7.jpg"></p>
<p>Vektörleri çarpıp b sabit sayısı ile topladıktan sonra değer 1’dan büyük ise seçtiğimiz (+) veya (-)sınıfında olduğunu belirleriz.<br>Eğer eşitlik görseldeki gibi 0 ‘a eşit olursa xi noktamız gutter veya caddeye benzettiğimiz noktadadır.<br><img src="/SVM/8.jpg"></p>
<h3 id="Lagrange-Multipliers"><a href="#Lagrange-Multipliers" class="headerlink" title="Lagrange Multipliers"></a>Lagrange Multipliers</h3><p>İki vektörün farkını alırsak ve w vektörüyle çarpıp w vektör büyüklüğüne bölersek cadde dediğimiz alanın uzunluğunu bulabiliriz.Bulduğumuz sonucu maksimum yapmak istiyoruz. Matematiksel optimizasyonda <strong>Lagrange Çarpanları(Lagrange Multipliers)</strong> yöntemini kullanacağız.<br><img src="/SVM/9.jpg"></p>
<p>Her iki tarafı 2 ile çarpıp w vektörüne göre diferansiyel alınca w vektörü eşitliğini elde ederiz. Bulduğumuz w vektör eşitliğini bir üstte yer alan Lagrange eşitliğinde yerine yazarız. Ardından yine her iki tarafı 2 ile çarpıp b’ ye göre diferansiyel alırız. Burda elde ettiğimiz sonuç işimize yarayacaktır. Bu sonucları lagrange denklemimizde yerine yazalım.<br><img src="/SVM/10.jpg"></p>
<p>İşte bulmak istediğimiz sonucu elde ettik.Peki yıldızlarla işaretlediğimiz yere bakalım.Tek yapmamız gereken bu iç çarpımları hesaplamaktı. </p>
<p>Peki neden bu kadar zahmete girdik? Çünkü bu ifadenin bağımlılığını bulmak istedim. Bu maksimizasyonun bu vektörlere göre neye bağlı olduğunu bulmak istiyorum, x örnek vektörü ve keşfettiğim şey, optimizasyonun yalnızca örnek çiftlerinin iç çarpımına bağlı olduğudur.</p>
<p>İki boyutlu ve 3 boyutlu olarak en uygun hiper düzlemi grafiklerde daha iyi görebiliriz:</p>
<p><img src="/SVM/5.jpg"></p>
<p><img src="https://miro.medium.com/max/600/0*MgG8zoCB6CY4Fa19.gif"></p>
<p>SVM modeli, iyi tanımlanmış bir karar sınırı oluşturarak iki sınıf arasındaki mesafeyi genişletmeye çalışır. Yukarıdaki durumda, hiper düzlemimiz verileri böldü. Verilerimiz 2 boyutlu iken, hiper düzlem 1 boyutluydu. Daha yüksek boyutlar için, örneğin n-boyutlu bir Öklid Uzayı için, alanı iki bağlantısız bileşene bölen n-1 boyutlu bir alt kümemiz var.</p>
<p>Peki lineer olmayan durumlarda ne yapacağız?Aslında gerçek hayatta verisetleri genellikle tam ayrışmayan verilerden oluşuyor. Bu durumda SVM’lerin doğrusal olarak ayrılmaz verileri sınıflandırmak için kullandığı Soft Margin Formulation ve Kernel Trick kavramlarına bakalım.</p>
<p>Aşağıdaki görselde olduğu gibi tam olarak ayrılmayan verileri grafikte inceleyelim.<br><img src="/SVM/12.jpg"></p>
<p>Şekilden, verileri mükemmel bir şekilde ayırabilecek belirli bir doğrusal karar sınırı olmadığı açıktır, yani veriler doğrusal olarak ayrılmazdır. Daha yüksek boyutlu temsillerde de benzer bir duruma sahip olabiliriz. Bu, genellikle verilerden elde ettiğimiz özelliklerin, iki sınıfı açıkça ayırabilmemiz için yeterli bilgi içermediği gerçeğine bağlanabilir. Çoğu gerçek dünya uygulamasında durum budur.</p>
<h3 id="Soft-Margin-Formulation"><a href="#Soft-Margin-Formulation" class="headerlink" title="Soft Margin Formulation"></a>Soft Margin Formulation</h3><p>Bu fikir basit bir önermeye dayanmaktadır: SVM’nin belirli sayıda hata yapmasına izin verin ve marjı olabildiğince geniş tutun, böylece diğer noktalar hala doğru şekilde sınıflandırılabilir. Bu, SVM’nin amacını değiştirerek yapılabilir.</p>
<p>Bu tür bir formülasyona sahip olmanın nedenini kısaca gözden geçirelim. Daha önce belirtildiği gibi, neredeyse tüm gerçek dünya uygulamaları doğrusal olarak ayrılmaz verilere sahiptir. Verilerin doğrusal olarak ayrılabildiği nadir durumlarda, aşırı uyumu önlemek için verileri mükemmel şekilde ayıran bir karar sınırı seçmek istemeyebiliriz. Örneğin, aşağıdaki diyagramı düşünün:</p>
<p><img src="/SVM/13.jpg"></p>
<p>Burada kırmızı karar sınırı, tüm eğitim noktalarını mükemmel bir şekilde ayırır. Ancak, bu kadar az marjla bir karar sınırına sahip olmak gerçekten iyi bir fikir mi? Bu tür bir karar sınırının görünmeyen veriler üzerinde iyi bir genelleme yapacağını düşünüyor musunuz? Cevabımız, tabi ki hayır. Yeşil karar sınırının, görünmeyen veriler üzerinde iyi bir şekilde genelleme yapmasına izin verecek daha geniş bir marjı vardır. Bu anlamda, <strong>Soft Margin Formulation</strong>, aşırı uyum sorununu önlemeye de yardımcı olacaktır.<br><img src="/SVM/15.jpg"></p>
<p>Burada C, marjı maksimize etmek ile hataları en aza indirmek arasındaki değiş tokuşa karar veren bir hiperparametredir. C küçük olduğunda, sınıflandırma hatalarına daha az önem verilir ve marjı maksimize etmeye daha çok odaklanırken, C büyük olduğunda, marjı küçük tutmak pahasına yanlış sınıflandırmadan kaçınmaya odaklanır.</p>
<p>Ancak bu noktada, tüm hataların eşit olmadığını da belirtmeliyiz. Karar sınırından çok uzakta  yanlış tarafında bulunan veri noktaları, daha yakın olanlara göre daha fazla ceza almalıdır. Aşağıdaki diyagramın yardımıyla bunun nasıl birleştirilebileceğini görelim.</p>
<p><img src="/SVM/14.jpg"></p>
<p>Buradaki fikir şudur: Her xi veri noktası için, bir gevşek değişken ξi sunuyoruz. </p>
<p><img src="/SVM/16.jpg"></p>
<p>Görselde olduğu gibi A,B ve C bölgelerinde ξ farklı değerler alır.<br><img src="/SVM/17.jpg"></p>
<ul>
<li><p><strong>C çok büyük olursa</strong> fonksiyon bütün ξ parametrelerini çok küçültmeye çalışacaktır. Daha dar bir marjin elde ederiz. Bu da , düşük bias ve yüksek varyansı meydana getirir <strong>(Overfitting)</strong>.</p>
</li>
<li><p><strong>C çok küçük olursa</strong> daha gevşek, geniş bir marjin elde edilir ve ξ değeri büyük olur. Bu da yüksek bias ve düşük varyansı meyadan getirir <strong>(Underfitting)</strong>.</p>
</li>
</ul>
<h3 id="Kernels-Trick"><a href="#Kernels-Trick" class="headerlink" title="Kernels Trick"></a>Kernels Trick</h3><p>Şimdi, doğrusal ayrılmazlık problemini çözmek için “Kernel Trick” i kullanmanın ikinci çözümünü inceleyelim. Ama önce Kernel fonksiyonlarının ne olduğunu öğrenmeliyiz.</p>
<h4 id="Kernel-Functions"><a href="#Kernel-Functions" class="headerlink" title="Kernel Functions"></a>Kernel Functions</h4><p>Kernel fonksiyonları, iki vektörü (herhangi bir boyuttan) girdi olarak alan ve girdi vektörlerinin ne kadar benzer olduğunu gösteren bir puan veren genelleştirilmiş işlevlerdir. Basit bir Kernel işlevi, nokta çarpım işlevidir: iç çarpım küçükse, vektörlerin farklı olduğu sonucuna varırız ve iç çarpım büyükse, vektörlerin daha benzer olduğu sonucuna varırız. </p>
<h4 id="The-“Trick”"><a href="#The-“Trick”" class="headerlink" title="The “Trick”"></a>The “Trick”</h4><p>Doğrusal olarak ayrılabilir durum için amaç fonksiyonuna bakalım:</p>
<p>Fonksiyonda w ve b değerlerini yerine yazınca aşağıdaki fonksiyonu elde ederiz.<br><img src="/SVM/18.jpg"></p>
<p>Bir Kernel fonksiyonundan başka bir şey olmayan girdi vektör çiftlerinin (xi. xj) iç çarpımına bağlıdır. Şimdi burada iyi bir şey var: Nokta ürün gibi basit bir kernel işleviyle sınırlı kalmamıza gerek yok. Hesaplama maliyetlerini fazla artırmadan, daha yüksek boyutlarda benzerliği ölçme kabiliyetine sahip nokta ürün yerine herhangi bir süslü Kernel işlevini kullanabiliriz. Bu aslında <strong>Kernel Trick</strong> olarak bilinir.</p>
<p><img src="/SVM/19.jpg"></p>
<p>Burada x ve y giriş vektörleridir, ϕ bir dönüşüm fonksiyonudur ve &lt;,&gt; nokta çarpım işlemini belirtir. Nokta çarpım fonksiyonu durumunda, ϕ sadece giriş vektörünü kendisine eşler.</p>
<p>2d uzayda veri noktalarını mükemmel şekilde ayırabilecek doğrusal bir karar sınırı olmadığını görüyoruz. Dairesel (veya ikinci dereceden) bir karar sınırı işi yapabilir, ancak doğrusal sınıflandırıcılar bu tür karar sınırlarını bulamaz.<br><img src="/SVM/20.jpg"></p>
<p>Şekilde, her bir P noktası 2D uzayda (x, y) formunun özellikleriyle temsil edilmektedir. Arzu edilen karar sınırına baktığımızda, bir P noktası için ϕ dönüşüm fonksiyonunu ϕ (P) = (x ^ 2, y ^ 2, √2xy) olarak tanımlayabiliriz. İki nokta P_1 ve P_2 için bu tür dönüşüm için Kernel işlevinin neye benzediğini görelim.</p>
<p><img src="/SVM/21.jpg"></p>
<p>Kernel işlevinin son halini gözlemlersek, bu bir daireden başka bir şey değildir! Bu, benzerlik kavramımızı değiştirdiğimiz anlamına gelir: benzerliği noktaların ne kadar yakın olduğuna göre ölçmek yerine (iç çarpımı kullanarak), benzerliği noktaların bir daire içinde olup olmadığına göre ölçüyoruz. Bu anlamda, böyle bir dönüşümü tanımlamak, 2D uzayda doğrusal olmayan bir karar sınırına sahip olmamızı sağladı (orijinal 3D uzayda hala doğrusaldır). Daha iyi anlamak için aşağıdaki videoyu izleyelim.</p>
<p><a href="http://www.youtube.com/watch?v=3liCbRZPrZA"><img src="http://img.youtube.com/vi/3liCbRZPrZA/0.jpg" alt="Watch THE VİDEO"></a></p>
<p>Kernel fonsiyonunu yeniden yazdığımızda aşağıdaki sonucu elde ederiz.</p>
<p><img src="/SVM/21.jpg"></p>
<p>Öyleyse Kernel fonksiyonunun değeri (dolayısıyla, 3D uzaydaki noktalar arasındaki benzerlik), 2D uzaydaki noktalar arasındaki nokta çarpımının sadece karesidir. Oldukça harika, değil mi ? Ama bu nasıl oldu?</p>
<p>Bunun nedeni, dönüşüm fonksiyonumuzu akıllıca seçmiş olmamızdır. Ve bunu yapmaya devam ettiğimiz sürece, dönüştürme adımını atlayabilir ve Kernel işlevinin değerini doğrudan 2D uzaydaki noktalar arasındaki benzerlikten hesaplayabiliriz. Bu da aynı zamanda hesaplama maliyetlerini de azaltacaktır. Bu güzel özelliğe sahip ve kutudan çıktığı gibi kullanılabilen birçok popüler Kernel fonksiyonumuz var (mükemmeli aramamıza gerek yok ϕ).</p>
<ul>
<li><p>SVM Avantajları</p>
<ul>
<li>Garantili Optimallik: Konveks Optimizasyonun doğası gereği, çözüm her zaman local minimum değil global minimum olacaktır. </li>
<li>SVM, doğrusal olarak ayrılabilir ve doğrusal olmayan şekilde ayrılabilir veriler için kullanılabilir. Doğrusal olarak ayrılabilir veriler kesin marjin,  doğrusal olmayan şekilde ayrılabilir veriler soft marjin oluşturur.</li>
<li>SVM’ler, yarı denetimli öğrenme modellerine uyum sağlar. Verilerin etiketlendiği ve etiketlenmediği alanlarda kullanılabilir. Yalnızca Transdüktif SVM olarak bilinen en aza indirme problemi için bir koşul gerektirir. </li>
<li>Feature Mapping, eskiden modelin genel eğitim performansının hesaplama karmaşıklığına oldukça yük oluyordu. Bununla birlikte, Kernel Trick’in yardımıyla SVM, basit iç çarpım kullanarak feature mapping gerçekleştirebilir.</li>
</ul>
</li>
<li><p>SVM Dezavantajları</p>
<ul>
<li>SVM, metin yapılarını işleyemez. Bu, sıralı bilgi kaybına ve dolayısıyla daha kötü performansa yol açar. </li>
<li>Vanilya SVM, lojistik regresyona benzer olasılıklı güven değerini döndüremez. Tahmin güveni birçok uygulamada önemli olduğundan, bu çok fazla açıklama sağlamaz. </li>
<li>Çekirdek seçimi, destek vektör makinesinin belki de en büyük sınırlamasıdır. Bu kadar çok çekirdeğin mevcut olduğu düşünüldüğünde, veriler için doğru olanı seçmek zorlaşıyor.</li>
</ul>
</li>
</ul>
</div><div class="article-tags size-small mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/Support-Vector-Machine/">Support Vector Machine</a><a class="link-muted mr-2" rel="tag" href="/tags/Lagrange-Multipliers/">Lagrange Multipliers</a><a class="link-muted mr-2" rel="tag" href="/tags/Soft-Margin-Formulation/">Soft Margin Formulation</a><a class="link-muted mr-2" rel="tag" href="/tags/Kernels-Tricks/">Kernels Tricks</a></div><link rel="stylesheet" href="/css/share.css"><div><a class="resp-sharing-button__link" href="https://twitter.com/intent/tweet/?text=Support Vector Machines (SVMs)&amp;url=https://kaderdurak.github.io//SVM/" target="_blank" rel="noopener" aria-label=""><div class="resp-sharing-button resp-sharing-button--twitter resp-sharing-button--small"><div class="resp-sharing-button__icon resp-sharing-button__icon--solidcircle" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 0C5.38 0 0 5.38 0 12s5.38 12 12 12 12-5.38 12-12S18.62 0 12 0zm5.26 9.38v.34c0 3.48-2.64 7.5-7.48 7.5-1.48 0-2.87-.44-4.03-1.2 1.37.17 2.77-.2 3.9-1.08-1.16-.02-2.13-.78-2.46-1.83.38.1.8.07 1.17-.03-1.2-.24-2.1-1.3-2.1-2.58v-.05c.35.2.75.32 1.18.33-.7-.47-1.17-1.28-1.17-2.2 0-.47.13-.92.36-1.3C7.94 8.85 9.88 9.9 12.06 10c-.04-.2-.06-.4-.06-.6 0-1.46 1.18-2.63 2.63-2.63.76 0 1.44.3 1.92.82.6-.12 1.95-.27 1.95-.27-.35.53-.72 1.66-1.24 2.04z"></path></svg></div></div></a><a class="resp-sharing-button__link" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://kaderdurak.github.io//SVM/&amp;title=Support Vector Machines (SVMs)&amp;source=https://kaderdurak.github.io//SVM/" target="_blank" rel="noopener" aria-label=""><div class="resp-sharing-button resp-sharing-button--linkedin resp-sharing-button--small"><div class="resp-sharing-button__icon resp-sharing-button__icon--solidcircle" aria-hidden="true"><svg version="1.1" x="0px" y="0px" width="24px" height="24px" viewBox="0 0 24 24" enable-background="new 0 0 24 24"><path d="M12,0C5.383,0,0,5.383,0,12s5.383,12,12,12s12-5.383,12-12S18.617,0,12,0z M9.5,16.5h-2v-7h2V16.5z M8.5,7.5 c-0.553,0-1-0.448-1-1c0-0.552,0.447-1,1-1s1,0.448,1,1C9.5,7.052,9.053,7.5,8.5,7.5z M18.5,16.5h-3V13c0-0.277-0.225-0.5-0.5-0.5 c-0.276,0-0.5,0.223-0.5,0.5v3.5h-3c0,0,0.031-6.478,0-7h3v0.835c0,0,0.457-0.753,1.707-0.753c1.55,0,2.293,1.12,2.293,3.296V16.5z"></path></svg></div></div></a><a class="resp-sharing-button__link" href="mailto:?subject=Support Vector Machines (SVMs)&amp;body=Bunu mutlaka okumalısın. https://kaderdurak.github.io//SVM/" target="_self" rel="noopener" aria-label=""><div class="resp-sharing-button resp-sharing-button--email resp-sharing-button--small"><div class="resp-sharing-button__icon resp-sharing-button__icon--solidcircle" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 0C5.38 0 0 5.38 0 12s5.38 12 12 12 12-5.38 12-12S18.62 0 12 0zm8 16c0 1.1-.9 2-2 2H6c-1.1 0-2-.9-2-2V8c0-1.1.9-2 2-2h12c1.1 0 2 .9 2 2v8z"></path><path d="M17.9 8.18c-.2-.2-.5-.24-.72-.07L12 12.38 6.82 8.1c-.22-.16-.53-.13-.7.08s-.15.53.06.7l3.62 2.97-3.57 2.23c-.23.14-.3.45-.15.7.1.14.25.22.42.22.1 0 .18-.02.27-.08l3.85-2.4 1.06.87c.1.04.2.1.32.1s.23-.06.32-.1l1.06-.9 3.86 2.4c.08.06.17.1.26.1.17 0 .33-.1.42-.25.15-.24.08-.55-.15-.7l-3.57-2.22 3.62-2.96c.2-.2.24-.5.07-.72z"></path></svg></div></div></a><a class="resp-sharing-button__link" href="whatsapp://send?text=Support Vector Machines (SVMs)https://kaderdurak.github.io//SVM/" target="_blank" rel="noopener" aria-label=""><div class="resp-sharing-button resp-sharing-button--whatsapp resp-sharing-button--small"><div class="resp-sharing-button__icon resp-sharing-button__icon--solidcircle" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" height="24" width="24" viewBox="0 0 24 24"><path d="m12 0c-6.6 0-12 5.4-12 12s5.4 12 12 12 12-5.4 12-12-5.4-12-12-12zm0 3.8c2.2 0 4.2 0.9 5.7 2.4 1.6 1.5 2.4 3.6 2.5 5.7 0 4.5-3.6 8.1-8.1 8.1-1.4 0-2.7-0.4-3.9-1l-4.4 1.1 1.2-4.2c-0.8-1.2-1.1-2.6-1.1-4 0-4.5 3.6-8.1 8.1-8.1zm0.1 1.5c-3.7 0-6.7 3-6.7 6.7 0 1.3 0.3 2.5 1 3.6l0.1 0.3-0.7 2.4 2.5-0.7 0.3 0.099c1 0.7 2.2 1 3.4 1 3.7 0 6.8-3 6.9-6.6 0-1.8-0.7-3.5-2-4.8s-3-2-4.8-2zm-3 2.9h0.4c0.2 0 0.4-0.099 0.5 0.3s0.5 1.5 0.6 1.7 0.1 0.2 0 0.3-0.1 0.2-0.2 0.3l-0.3 0.3c-0.1 0.1-0.2 0.2-0.1 0.4 0.2 0.2 0.6 0.9 1.2 1.4 0.7 0.7 1.4 0.9 1.6 1 0.2 0 0.3 0.001 0.4-0.099s0.5-0.6 0.6-0.8c0.2-0.2 0.3-0.2 0.5-0.1l1.4 0.7c0.2 0.1 0.3 0.2 0.5 0.3 0 0.1 0.1 0.5-0.099 1s-1 0.9-1.4 1c-0.3 0-0.8 0.001-1.3-0.099-0.3-0.1-0.7-0.2-1.2-0.4-2.1-0.9-3.4-3-3.5-3.1s-0.8-1.1-0.8-2.1c0-1 0.5-1.5 0.7-1.7s0.4-0.3 0.5-0.3z"></path></svg></div></div></a><a class="resp-sharing-button__link" href="https://telegram.me/share/url?text=Support Vector Machines (SVMs)&amp;url=https://kaderdurak.github.io//SVM/" target="_blank" rel="noopener" aria-label=""><div class="resp-sharing-button resp-sharing-button--telegram resp-sharing-button--small"><div class="resp-sharing-button__icon resp-sharing-button__icon--solidcircle" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 23.5c6.35 0 11.5-5.15 11.5-11.5S18.35.5 12 .5.5 5.65.5 12 5.65 23.5 12 23.5zM2.505 11.053c-.31.118-.505.738-.505.738s.203.62.513.737l3.636 1.355 1.417 4.557a.787.787 0 0 0 1.25.375l2.115-1.72a.29.29 0 0 1 .353-.01L15.1 19.85a.786.786 0 0 0 .746.095.786.786 0 0 0 .487-.573l2.793-13.426a.787.787 0 0 0-1.054-.893l-15.568 6z" fill-rule="evenodd"></path></svg></div></div></a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/Algorithm/"><span class="level-item">Debugging Learning Algorithm</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatar.png" alt="Kader Durak"></figure><p class="title is-size-4 is-block line-height-inherit">Kader Durak</p><p class="is-size-6 is-block">Data Science Enthusiast</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>İstanbul</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Gönderiler</p><a href="/archives"><p class="title">9</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Kategoriler</p><a href="/categories"><p class="title">2</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Etiketler</p><a href="/tags"><p class="title">50</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/KaderDurak" target="_blank" rel="noopener">TAKİP ET</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/KaderDurak/"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="HackerRank" href="http://hackerrank.com/"><i class="fab fa-hackerrank"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Kaggle" href="https://www.kaggle.com/"><i class="fab fa-kaggle"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="http://medium.com/"><i class="fab fa-medium"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Faydalı Linkler</h3><ul class="menu-list"><li><a class="level is-mobile is-mobile" href="https://datacamp.com/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">DataCamp</span></span><span class="level-right"><span class="level-item tag">datacamp.com</span></span></a></li><li><a class="level is-mobile is-mobile" href="https://coursera.org/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Coursera</span></span><span class="level-right"><span class="level-item tag">coursera.org</span></span></a></li><li><a class="level is-mobile is-mobile" href="https://udemy.com/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Udemy</span></span><span class="level-right"><span class="level-item tag">udemy.com</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Arşivler</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2020/12/"><span class="level-start"><span class="level-item">Aralık 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/11/"><span class="level-start"><span class="level-item">Kasım 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/10/"><span class="level-start"><span class="level-item">Ekim 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/09/"><span class="level-start"><span class="level-item">Eylül 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/08/"><span class="level-start"><span class="level-item">Ağustos 2020</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/07/"><span class="level-start"><span class="level-item">Temmuz 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Kategoriler</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/Deep-Learning/"><span class="level-start"><span class="level-item">Deep Learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Machine-Learning/"><span class="level-start"><span class="level-item">Machine Learning</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">Son</h3><article class="media"><a class="media-left" href="/SVM/"><p class="image is-64x64"><img class="thumbnail" src="/SVM/bas.png" alt="Support Vector Machines (SVMs)"></p></a><div class="media-content size-small"><p><time dateTime="2020-12-03T08:42:30.000Z">2020-12-03</time></p><p class="title is-6"><a class="link-muted" href="/SVM/">Support Vector Machines (SVMs)</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></p></div></article><article class="media"><a class="media-left" href="/Algorithm/"><p class="image is-64x64"><img class="thumbnail" src="/Algorithm/aaa.jpg" alt="Debugging Learning Algorithm"></p></a><div class="media-content size-small"><p><time dateTime="2020-11-14T17:02:46.000Z">2020-11-14</time></p><p class="title is-6"><a class="link-muted" href="/Algorithm/">Debugging Learning Algorithm</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></p></div></article><article class="media"><a class="media-left" href="/ANN/"><p class="image is-64x64"><img class="thumbnail" src="/ANN/2f507880818753.5cec871f2d771.png" alt="Artificial Neural Networks"></p></a><div class="media-content size-small"><p><time dateTime="2020-11-04T14:45:43.000Z">2020-11-04</time></p><p class="title is-6"><a class="link-muted" href="/ANN/">Artificial Neural Networks</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></p></div></article><article class="media"><a class="media-left" href="/Classification/"><p class="image is-64x64"><img class="thumbnail" src="/Classification/b926c450441609.58d0ca93f0421.png" alt="Classification"></p></a><div class="media-content size-small"><p><time dateTime="2020-10-21T08:42:30.000Z">2020-10-21</time></p><p class="title is-6"><a class="link-muted" href="/Classification/">Classification</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></p></div></article><article class="media"><a class="media-left" href="/Featurescaling/"><p class="image is-64x64"><img class="thumbnail" src="/Featurescaling/f3dba971783255.Y3JvcCw4MDgsNjMyLDI4Niww.png" alt="Feature Scaling"></p></a><div class="media-content size-small"><p><time dateTime="2020-09-13T19:03:45.000Z">2020-09-13</time></p><p class="title is-6"><a class="link-muted" href="/Featurescaling/">Feature Scaling</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Etiketler</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/AUC/"><span class="tag">AUC</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Accuracy/"><span class="tag">Accuracy</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Artificial-Neural-Networks-ANNs/"><span class="tag">Artificial Neural Networks (ANNs)</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Back-Propagation-Algorithm/"><span class="tag">Back Propagation Algorithm</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bayes-Networks/"><span class="tag">Bayes Networks</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bias/"><span class="tag">Bias</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Binary-Classification/"><span class="tag">Binary Classification</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Classification/"><span class="tag">Classification</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CostFunction/"><span class="tag">CostFunction</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Cross-Validation/"><span class="tag">Cross Validation</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Decision-Boundary/"><span class="tag">Decision Boundary</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Directed-Acyclic-Graphs-DAGs/"><span class="tag">Directed Acyclic Graphs (DAGs)</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Error-Analysis/"><span class="tag">Error Analysis</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/F1-Score/"><span class="tag">F1 Score</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Feature-Scaling/"><span class="tag">Feature Scaling</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FeedBack-Neural-Network/"><span class="tag">FeedBack Neural Network</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FeedForward-Neural-Networks/"><span class="tag">FeedForward Neural Networks</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GPT-3/"><span class="tag">GPT-3</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hidden-Layer/"><span class="tag">Hidden Layer</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Input-Layer/"><span class="tag">Input Layer</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Kernels-Tricks/"><span class="tag">Kernels Tricks</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Lagrange-Multipliers/"><span class="tag">Lagrange Multipliers</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Learning-Curve/"><span class="tag">Learning Curve</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linear-Regression/"><span class="tag">Linear Regression</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Logistic-Regression/"><span class="tag">Logistic Regression</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Max-Abs-Scaler/"><span class="tag">Max Abs Scaler</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Min-Max-Scaler/"><span class="tag">Min-Max Scaler</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Model/"><span class="tag">Model</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Model-Evaluation-Metrics/"><span class="tag">Model Evaluation Metrics</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Model-Selection/"><span class="tag">Model Selection</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Multiclass-Classification/"><span class="tag">Multiclass Classification</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/OpenAI/"><span class="tag">OpenAI</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Output-Layer/"><span class="tag">Output Layer</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Overfitting/"><span class="tag">Overfitting</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Polynomial-Regression/"><span class="tag">Polynomial Regression</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Power-Transformer-Scaler/"><span class="tag">Power Transformer Scaler</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Precision/"><span class="tag">Precision</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Quantile-Transformer-Scaler/"><span class="tag">Quantile Transformer Scaler</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ROC/"><span class="tag">ROC</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Recall/"><span class="tag">Recall</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Regression/"><span class="tag">Regression</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Representation/"><span class="tag">Representation</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Robust-Scaler/"><span class="tag">Robust Scaler</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Soft-Margin-Formulation/"><span class="tag">Soft Margin Formulation</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Standard-Scaler/"><span class="tag">Standard Scaler</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Support-Vector-Machine/"><span class="tag">Support Vector Machine</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Underfitting/"><span class="tag">Underfitting</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Unit-Vector-Scaler/"><span class="tag">Unit Vector Scaler</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Variance/"><span class="tag">Variance</span><span class="tag is-grey-lightest">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="KADER DURAK BLOG" height="28"></a><p class="size-small"><span>&copy; 2020 Kader Durak</span></p></div><p>Yazara ait blog yazıları eğitim amaçlıdır.<br>i&#039;m cyborg but that&#039;s ok</p><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("tr");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'https://kaderdurak.github.io',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="Zurück nach oben" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Bir şeyler yaz..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Bir şeyler yaz...","untitled":"(Untitled)","posts":"Gönderiler","pages":"Pages","categories":"Kategoriler","tags":"Etiketler"});
        });</script></body></html>