{"pages":[],"posts":[{"title":"Model Representation","text":"Makine öğrenimi algoritmasının çoğunun temel amacı bir model oluşturmaktır. Bu modelden hipotez olarak söz edebiliriz. Hipotez temel olarak girdiyi çıktıya eşler. Girdi değişkeni özelliği ve çıktı değişkeni hedefi belirtir. Öğrenmek için kullanacağımız veri kümesine eğitim seti(trainning set) denir. Amacımız, bir eğitim seti verildiğinde, h: X → Y fonksiyonunu öğrenmek, böylece h (x), y’nin karşılık gelen değeri için “iyi” bir tahmin edici model diyebiliriz. Gelin bunu bir örnekle açıklayalım. Diyelim ki ev fiyatları tahmini yapmak istiyoruz. Elimizde evlerin m2 ölçüleri ve fiyatları var. Burada dikkat etmemiz gereken girdilerimiz yani “x” , fiyatını tahmin edeceğimiz çıktı “y” olacak. Eğer biz verilerimizden fiyat tahmini yapmak istiyorsak bunun için regresyon (regression) kullancağız. Eğer yaşam alanının ( villa, arsa , apartman vs.) ne olduğunu bulmak istiyorsak bunun için sınıflandırma (classification) kullanacağız. Hedefimiz fiyat tahmini bu yüzden regresyon kullancağız. Hipotez formülü : hQ(x) =θ0+θ1X Tetalar (θ) bizim parametrelerimizdir. Katsayılarımızı düzgün seçmeliyiz çünkü verilerimiz görselleştirdiğimizde eğimi 0 olduğunda tahminimiz yani y değeri hep 0 gelecektir.NOT: Model oluşturmanın amacı parametreleri veya teta değerlerini doğru seçmektir, böylece h (x) training verilerimiz olan x’ler için ulaşmak istedğimiz y değerine yakın olur. Eğer θ1 değerimizi yani eğimi veren değer 0 olursa aşağıdaki gibi grafik elde ederiz ve istediğimiz y değerine ulaşamayız. 1234import matplotlib.pyplot as pltplt.plot([1, 2, 3, 4], [1,1,1,1])plt.ylabel('some numbers')plt.show() Şimdi örnek verimizi görselleştirerek anlatalım.Elimizde evlerin ölçüleri ve fiyatları olsun burada eğim 0 olmadığından girdiğimiz her x değerimize karşılık y değeri geliyor bu da bize regression kullanarak fiyat tahmini yapmamızı sağlıyor.Aşağıdaki örnekteki gibi küçük bir verimiz olsun. 123import pandas as pddf = pd.DataFrame({'x': [0, 0.5, 1,1.5,2,2.5,3], 'hθ(x)': [1.0,1.5,2.0,2.5,3.0,3.5,4.0]})df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x hθ(x) 0 0.0 1.0 1 0.5 1.5 2 1.0 2.0 3 1.5 2.5 4 2.0 3.0 5 2.5 3.5 6 3.0 4.0 1234plt.plot([852, 1416,1534,2104], [178,232,315,460], color='blue')plt.ylabel('Price($) in 1000s')plt.xlabel('Size in house feet^2 (x)')plt.show() Üstteki grafikte olduğu gibi kırmızı noktalarla işaretlediğimiz 1750 feet^2 olan evimizin tahmini değeri 375000 $ civarı oluyor.İşte modelimizin bize tahminde bulunmasını istediğimiz değerleri böyle örneklendirebiliriz.","link":"/ModelRepresentation/"},{"title":"Cost Function","text":"Öncelikle lineer regresyonda tahmin edilen y değeri ile gerçek y değeri arasındaki hatayı minimuma indirebilmek için teta(θ) değerleri bulmalıyız. Maliyet fonksiyonunu (cost function) minimize etmeliyiz. Maliyet fonksiyonu diye gerçek y değerleri ile tahmin edilen y değerleri arasındaki farka deriz.Maliyet fonksiyonumuz test setindeki çıktıları ne kadar iyi tahmin ettiğini ölçer.Tahmin edilen değer ile gerçek değer arasındaki fark ne kadar az ise modelimiz o kadar iyi tahminde bulunur. Amaç, maliyeti en aza indiren bir dizi ağırlık(weight) ve önyargı(bias) bulmaktır. Bunun için y’nin gerçek değeri ile y’nin tahmini değeri (tahmin) arasındaki farkı ölçen ortalama kare hatası(the mean squared error)kullanılır. Aşağıdaki regresyon çizgisinin denklemi, sadece iki parametreye sahip olan hθ (x) = θ0 + θ1x’tir: weight(θ1) ve bias(θ0) Minimising Cost functionHerhangi bir makine öğrenmesi modelinin amacı cost fuction’ı (maliyet fonksiyonu) en aza indirgemektir. Gelin, yukarıdaki görselimizi anlayalım. Kırmızı olan tepecikler random olarak seçtiğimiz teta parametrelerimizin bulunduğu yeri temsil ediyor.Hedefimiz koyu mavi ile gösterilen “global minimum” dediğimiz yere doğru adım adım ilerlemek. Şekilde görüldüğü gibi ikinci bir mavi noktamız var buraya da “local minimum” diyoruz ama bu noktaya ilerlemiyoruz.Çünkü istediğimiz şey costu minimize etmek(hatalı değerlerimizi minimuma indirgemek) local minimumda değerimiz global minimuma göre daha yüksek çıkacağından hedefimiz her zaman global minimuma gitmek olmalıdır.Peki nasıl global minimuma varacağız. Bunun için etkili bir optimizasyon algoritması olan Gradient Descent Algoritmasını kullanacağız. Gradient Descent AlgorithmGradient Descent (Degrade İniş), hesaplamayı kullanarak belirli maliyet işlevinin minimum değerine karşılık gelen parametrelerin optimal değerlerini bulmak için yinelemeli olarak çalışır. Matematiksel olarak, ‘türev’ tekniği maliyet işlevini en aza indirmek için son derece önemlidir, çünkü minimum noktayı elde etmeye yardımcı olur. Türev, matematikten gelen bir kavramdır ve belirli bir noktada fonksiyonun eğimini ifade eder. Eğimi bilmemiz gerekir, böylece bir sonraki yinelemede daha düşük bir maliyet elde etmek için katsayı değerlerini hareket ettirme yönünü (işaretini) biliriz. Her parametredeki bir fonksiyonun türevi (bizim durumumuzda, J (θ)) bize bu değişkene göre fonksiyonun hassasiyetini veya değişkeni değiştirmenin fonksiyon değerini nasıl etkilediğini söyler. Gradient descent, bu nedenle, öğrenme sürecinin modeli optimal bir parametre kombinasyonuna doğru hareket ettiren öğrenilmiş tahminlerde düzeltici güncellemeler yapmasını sağlar (θ). Cost , bir gradient descent algoritmasının her tekrarı için tüm training set kümesinde bir makine öğrenme algoritması için hesaplanır. Gradient Descent, algoritmanın bir yinelemesine bir “Batch Gradient Descent” deniyor. Bu her bir yinelemenin gradyanını hesaplamak için kullanılan bir training set kümesindeki toplam örnek sayısını belirtir. Bu yeni gradyan, maliyet fonksiyonumuzun mevcut konumumuzdaki eğimini (geçerli parametre değerleri) ve parametrelerimizi güncellemek için hareket etmemiz gereken yönü gösterir. Güncellememizin boyutu learning rate (α)(öğrenme oranı) tarafından kontrol edilmektedir. Learning rate (α) Gradient descent algoritmasında adımların boyutuna, ne kadar büyük adımlar attığımız konusunda bize ek kontrol sağlayan değere learning rate (α) denir. Büyük bir learning rate(α) sağ alt köşedeki görselde olduğu gibi, her adımda daha fazla yer atlayabiliriz, ancak tepenin eğimi sürekli değiştiği için en düşük noktayı aşma riskiyle karşı karşıyayız. Çok düşük bir learning rate(α) sağ üst köşedeki görselde olduğu gibi, negatif gradyan yönünde güvenle hareket edebiliriz, çünkü bunu çok sık yeniden hesaplıyoruz. Düşük bir learning rate(α) daha kesindir, ancak gradyanı hesaplamak zaman alıcıdır, bu nedenle en alt noktaya gelmek çok uzun zaman alacaktır. En sık kullanılan learning rate(α) değerleri: 0.001, 0.003, 0.01, 0.03, 0.1, 0.3 Şimdi Gradient descent algoritmasının üç varyantını tartışalım. Aralarındaki temel fark, her bir learning step(öğrenme adımı) için degradeleri hesaplarken kullandığımız veri miktarıdır. Aralarındaki değişim, her bir parametrenin güncellemesini gerçekleştirmek için zaman karmaşıklığına karşı degradenin doğruluğudur (learning step). Stochastic Gradient Descent (SGD)Batch Gradient Descent ile ilgili temel sorun, her adımda degradeleri hesaplamak için tüm eğitim setini kullanmasıdır, bu da eğitim seti büyük olduğunda çok yavaş olmasını sağlar. Stochastic Gradient Descent her adımda belirlenen eğitimde rastgele bir örnek seçer ve degradeleri yalnızca bu tek örneğe göre hesaplar. Algoritmayı çok daha hızlı hale getirir. Öte yandan, stokastik doğası nedeniyle, bu algoritma Batch Gradient Descent’ten çok daha az düzenlidir: minimum seviyeye ulaşıncaya kadar hafifçe azaltmak yerine, maliyet fonksiyonu yukarı ve aşağı sıçrar ve sadece ortalama olarak azalır. Zamanla minimum seviyeye çok yakın olacak, ancak oraya vardığında geri dönmeyecek, asla yerleşmeyecek. Dolayısıyla algoritma durduğunda, son parametre değerleri iyidir, ancak optimal değildir. Cost function çok düzensiz olduğunda, bu aslında algoritmanın local minimum dışına atlamasına yardımcı olabilir, bu nedenle Stochastic Gradient Descent, Batch Gradient Descent’ten daha fazla global minimum bulma şansına sahiptir. Bu nedenle, rasgelelik local optima’dan kaçmak için iyidir, diğer yandan kötüdür, çünkü algoritmanın asla minimumda yerleşemeyeceği anlamına gelir. Bu ikilemin bir çözümü learning rate(α) kademeli olarak azaltmaktır. Adımlar büyük başlar (hızlı ilerleme kaydetmeye ve yerel minimadan kaçmaya yardımcı olur), daha sonra gittikçe küçülür ve algoritmanın küresel minimumda yerleşmesine izin verir. Her yinelemede öğrenme hızını belirleyen işlev öğrenme çizelgesi olarak adlandırılır. Öğrenme oranı çok yavaş bir şekilde azalırsa, minimuma çok uzun bir süre sonra varabilir ve eğitimi çok erken durdurursanız, en uygun olmayan bir çözüm elde edebilirsiniz. Öğrenme oranı çok hızlı bir şekilde azalırsa, yerel bir minimumda takılabilir veya hatta en sonunda yarıya kadar donmuş olabilirsiniz. Öğrenme oranı çok yavaş bir şekilde azalırsa, minimum süre boyunca uzun süre atlayabilir ve eğitimi çok erken durdurursanız, en uygun olmayan bir çözüm elde edebilirsiniz. Stochastic Gradient Descent kullanıldığında, parametrelerin ortalama olarak global minimum değere doğru çekilmesini sağlamak için training set bağımsız ve aynı şekilde dağıtılmalıdır. Bunu sağlamanın basit bir yolu, eğitim sırasında örnekleri karıştırmaktır. Bunu yapmazsanız, örneğin örnekler etikete göre sıralanırsa, SGD bir etiket için, ardından bir sonraki öğe için optimizasyon yaparak başlayacaktır ve global minimum değere yakın yerleşmeyecektir. Mini-Batch Gradient DescentHer adımda, gradientleri tüm training sete (Batch GD’de olduğu gibi) veya yalnızca bir örneğe (Stochastic GD’de olduğu gibi) dayalı olarak hesaplamak yerine, Mini-Batch GD, gradientleri mini-batches adı verilen küçük rasgele örnek kümelerinde hesaplar. Mini-Batch GD’nin Stochastic GD’ye göre ana avantajı, özellikle GPU’ları kullanırken matris işlemlerinin donanım optimizasyonundan bir performans artışı elde edebilmenizdir. Algoritmanın parametre alanındaki ilerlemesi, özellikle oldukça büyük Mini-Batch’lerde SGD’den daha az düzensizdir. Sonuç olarak, Mini-Batch GD, SGD’den minimum seviyeye biraz daha yakın yürüyecektir. Ancak, diğer taraftan, yerel minimadan kaçmak daha zor olabilir. Hepsi minimum seviyeye yakın, ancak Batch GD’nin yolu aslında minimumda dururken, hem Stochastic GD hem de Mini-Batch GD dolaşmaya devam ediyor. Ancak, Batch GD’nin her adımı atması çok zaman aldığını ve iyi bir öğrenme programı kullandıysanız Stochastic GD ve Mini-Batch GD’nin de minimum seviyeye ulaşacağını unutmayın.","link":"/CostFunction-GradientDescent/"},{"title":"Linear and Polynomial Regression","text":"İki tür gözetimli(supervised) makine öğrenme algoritması vardır: Regresyon ve sınıflandırma.Örneğin, bir evin fiyatını dolar olarak tahmin etmek bir regression problemidir, bir tümörün kötü veya iyi huylu olup olmadığını tahmin etmek bir sınıflandırma problemidir. Bu yazıda , Python için en popüler makine öğrenimi kütüphanelerinden biri olan Scikit-Learn kullanarak doğrusal regresyonun ne olduğunu ve hem iki değişken hem de çoklu değişken için nasıl uygulanabileceğini kısaca inceleyeceğiz. Cebirde “doğrusallık” terimi, iki veya daha fazla değişken arasındaki doğrusal bir ilişkiyi ifade eder. Bu ilişkiyi iki boyutlu bir alanda (iki değişken arasında) çizersek, düz bir çizgi elde ederiz. Doğrusal regresyon, verilen bağımsız değişkeni (x) temel alarak bağımlı bir değişken değerini (y) tahmin etme görevini yerine getirir. Dolayısıyla, bu regresyon tekniği x (girdi) ve y (çıktı) arasında doğrusal bir ilişki bulur. Bu nedenle, adı Linear Regression(Doğrusal Regresyon) dur. Bağımsız değişkeni (x) x eksenine ve bağımlı değişkeni (y) y eksenine çizersek, doğrusal regresyon bize aşağıdaki şekilde gösterildiği gibi veri noktalarına en iyi uyan düz bir çizgi verir. Yukarıdaki çizginin denklemi: Y = mx + b Burada b kesişme noktası ve m doğrunun eğimidir. Temel olarak, lineer regresyon algoritması bize kesişme ve eğim için en uygun değeri verir (iki boyutta). Veri özellikleri oldukları ve değiştirilemedikleri için y ve x değişkenleri aynı kalır. Kontrol edebileceğimiz değerler kesişme noktası (b) ve eğimdir (m). Kesişim ve eğim değerlerine bağlı olarak birden fazla düz çizgi olabilir. Tek değişkeni olan bir regresyon modeli şu şekilde temsil edilebilir: y = b0 + m1b1 hQ(x) =θ0 + θ1X Multiple Linear RegressionTemel olarak doğrusal regresyon algoritmasının yaptığı şey, veri noktalarına birden çok satır sığdırması ve en az hatayla sonuçlanan çizgiyi döndürmesidir. Aynı kavram ikiden fazla değişkenin bulunduğu vakalara da genişletilebilir. Buna multiple linear regression(çoklu doğrusal regresyon) denir. Örneğin, evin fiyatını alanı, yatak odası sayısı, bölgedeki insanların ortalama geliri, evin yaşı vb. Temelinde tahmin etmeniz gereken bir senaryo düşünün. Bu durumda, bağımlı değişken (hedef değişken) birkaç bağımsız değişkene bağlıdır. Birden çok değişkeni içeren bir regresyon modeli şu şekilde temsil edilebilir: y = b0 + m1b1 + m2b2 + m3b3 + … mnbn hQ(x) =θ0 +θ1X1 + θ2X2 + θ3X3 + …θnXn Bu, bir hiper düzlemin denklemidir. Unutmayın, iki boyutta doğrusal bir regresyon modeli düz bir çizgidir; üç boyutta olan bir düzlemdir ve üçten fazla boyutta olan bir hyperplane(hiperdüzlem)dir. Polynomal Linear RegressionKullanacağınız veri setine göre veriler lineer olarak dağılım göstermeyebilir ve doğrusal olmayan(non-linear) diye adlandırılan dağılımı gösterebilir. Lineer regresyon burada istediğimiz sonucu vermeyecektir.Non-linear olan dağılımda polinomal regresyon istediğimiz sonuca bizi yaklaştıracaktır.Polinomal regresyonda bağımsız değişken x ve bağımlı değişken y arasındaki ilişkinin n’inci derece polinom olarak modellendiği bir doğrusal regresyon biçimidir. Unutmayın burada x’ler lineer ilerlemiyor.Zaten lineer dememizin sebebi θ0,θ1,θ2,θ3… değerleridir. n’inci derece polinom denklemi y = a + b1x + b2x^2 +….+ bnx^n hQ(x) =θ0 +θ1X1 + θ2X2^2 + θ3X3^3 + …θnXn^n Gelin küçük bir örnekle lineer ve polinomal regresyon için kodlayalım. Amaç: Sıcaklık ve basınç değerleri verilen bir veri setinde istenilen sıcaklık değerinde basıncın ne olacağını tahmin edebilmektir. 12345678# Importing the libraries import numpy as np import matplotlib.pyplot as plt import pandas as pd # Importing the dataset datas = pd.read_csv('data.csv') datas .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sno Temperature Pressure 0 1 0 0.0002 1 2 20 0.0012 2 3 40 0.0060 3 4 60 0.0300 4 5 80 0.0900 5 6 100 0.2700 123# for x axis we select temperature, for y axis we select pressureX = datas.iloc[:, 1:2].values y = datas.iloc[:, 2].values 12345# Fitting Linear Regression to the dataset from sklearn.linear_model import LinearRegression lin = LinearRegression() lin.fit(X, y) 12LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) 123456789# Visualising the Linear Regression results plt.scatter(X, y, color = 'blue') plt.plot(X, lin.predict(X), color = 'red') plt.title('Linear Regression') plt.xlabel('Temperature') plt.ylabel('Pressure') plt.show() 123456789# Fitting Polynomial Regression to the dataset from sklearn.preprocessing import PolynomialFeatures poly = PolynomialFeatures(degree = 4) X_poly = poly.fit_transform(X) poly.fit(X_poly, y) lin2 = LinearRegression() lin2.fit(X_poly, y) 12LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) 123456789# Visualising the Polynomial Regression results plt.scatter(X, y, color = 'blue') plt.plot(X, lin2.predict(poly.fit_transform(X)), color = 'red') plt.title('Polynomial Regression') plt.xlabel('Temperature') plt.ylabel('Pressure') plt.show() Görselimizde görüldüğü üzere regresyon çizgimiz değerlerimize yakın bile değil peki yakın(fit) olmaması sorun teşkil eder mi? Tabi ki eder modelimize uyguladığımızda modelimiz doğru tahminde bulunmayacaktır. 12# Predicting a new result with Linear Regression print(lin.predict([[197]])) 1[0.41050733] 12# Predicting a new result with Polynomial Regression lin2.predict(poly.fit_transform([[197]])) 1array([7.18740604]) Yukarıda aynı x sıcaklık değeri için basınç tahminleri arasındaki farkı görebiliriz.Polinomal regresyon modelimiz lineer regresyon modelimize göre daha iyi tahminde bulundu diyebiliriz. Polinomal regresyonda avantajlar: Polinom, bağımlı ve bağımsız değişken arasındaki ilişkiye en iyi yaklaşımı sağlar. Polinomal regresyonda dezavantajlar: Bunlar aykırı değerlere karşı çok hassastır. Verilerdeki bir veya iki aykırı değerin varlığı, doğrusal olmayan bir analizin sonuçlarını ciddi şekilde etkileyebilir. Ek olarak, maalesef doğrusal olmayan regresyonda aykırı değerlerin tespiti için doğrusal regresyon için olanlardan daha az model doğrulama aracı vardır.","link":"/Regression/"},{"title":"GPT-3","text":"Generative Pre-trained Transformer 3 (Türkçe: Üretken Ön İşlemeli Dönüştürücü 3) kısaca GPT-3, insanların yazdığı metinlere benzer içerik üretmek için derin öğrenmeyi kullanan özbağlanımlı dil modelidir. GPT-n serisindeki üçüncü nesil dil tahmin modeli olan GPT-3, San Francisco merkezli yapay zeka araştırma laboratuvarı OpenAI tarafından geliştirilmiştir. GPT-3’ün tam sürümü, veri işleyecek 175 milyar parametreye sahiptir. Bu rakam GPT-2’nin öğrenme kapasitesinin 2 katıdır. 14 Mayıs 2020’de tanıtılan ve Temmuz 2020 itibarıyla beta aşamasında olan GPT-3, önceden öğretilmiş dil örnekleriyle doğal dil işleme (NLP) sistemini kullanmaktadır. GPT-3’ün piyasaya sürülmesinden önce, en büyük dil modeli Microsoft’un Şubat 2020’de tanıttığı ve GPT-3’ün %10’undan daha az kapasiteye sahip olan (17 milyar parametre) Turing NLG idi.Wikipedia sitesinde bu şekilde açıklanıyor. Youtube panelinde GPT-3 hakkında sorulan sorulara Google Brain’de Araştırmacı olan Lukasz Kaiser şu açıklamaları yaptı: Transformerlardan öncesini yani derin öğrenme kısmında NLP’de RNN’ler her şeyi doğru yapıyordu. Derin öğrenmenin ve NLP’nin ilk büyük dalgasıydılar. İşleri adım adım yineleyerek yapmanız gerektiğine dair süper temel fikirlere sahiptiler, bu da çok sezgisel ancak modern donanımda gerçekten yavaştır çünkü hızlandırıcılar paralel işlem için inşa edilmiştir. Dikkat fikri NLP’de çok eski bir bir yöntem olan hizalamadan (alignment) geliyor. Diyelim ki bir cümleyi çevirmeye çalışıyorsunuz elinizde ingilizce ve fransızca cümleler var hangi kelimelerin hangi kelimelere karşılık geldiğini hizalamaya çalışıyorsunuz. Dolayısıyla, bu hizalama fikrini bir sinir ağına koyarsanız, elde ettiğiniz şey dikkat mekanizmasıdır. Kelimeleri daha önce gelen kelimelerle hizalamanın farklılaştırılabilir yumuşak bir versiyonudur ve öz-ilgi, aynı metni, daha önce görünen kelimelerle aynı hizaya getirecek şekilde hizalamaktır. Bu fikir, aldığınız sonuçlar açısından iyi işliyor, ancak aynı zamanda modern derin öğrenme hızlandırıcılarında iyi bir şekilde uygularsanız şaşırtıcı derecede hızlı da çalışıyor. Sonuçları bir gün veya bir ay beklemeniz gerekmiyor bu da büyük bir fark yaratıyor. Ama diğer bir şey de hizalama(alignment), nlp’de uzun zamandır bilinen gerçekten iyi bir fikir.Paragrafın tamamını çevirmek istiyorsanız, bu bölümü çevirmeye odaklandığınızda ve her seferinde sadece bu bölüme baktığınızda çok daha kolay. Her insanın yaptığı da budur. Bunu bir sinir ağına öncelikli olarak veriyorsunuz ve bu gerçekten işe yarıyor, bu yüzden dikkatin geldiği yer burasıdır ancak şunu söylemek isterim, her şey dalgalar halinde ilerlerken, RNN’leri kullanmak çok iyi bir fikirdir. Çünkü seyrek transformatörlerle ilgili, bu ilginin insanların düşündüğünden daha çok RNN’ e benzediğini gösteren modern makaleler var ve aslında buna tekrar eden bir ağ(recurrent network) eklemek onu daha da iyi hale getiriyor. İnsanlar tekrar eden ağa geri dönerse, tekrar bir şekilde tekrarlayan ağlara bile dönüşmesi bu yüzden şaşırtıcı olmaz. En yeni teknikten daha fazlasını öğrenmek, daha önce gelen şeyleri bilmek ve bununla ilgili her şeyi öğrenmek iyidir.Herkesin internette NLP’de derin öğrenme yaptığını düşünebilirsiniz ama ben bunun tam tersini düşünüyorum. Elbette bugünlerde her şey çevrimiçi olarak gerçekleşiyor, çok fazla hareket varmış gibi geliyor çünkü nlp dünyası onlarca yıl öncesine göre çok daha büyük ama bu derin modellerin aslında dil yapabildiği şeylerin yüzeyini zar zor çizdiğimizi hissediyorum. Bu dil son derece derin bir alandır. Evet, size bir hikaye oluşturabiliriz ve okuruz, tamam mıdır? Gerçekten anlamı var mı? Bu doğru şeyler yaratır mı? Bunu bize bildiğini söyleyebilir mi? Doğrulayabilir miyiz? Önyargılar(bias) hakkında konuştuğumuzu bildiğini bize söyleyebilir mi? Aslında dil modelinin bu kadar saldırgan olup olmadığını sorabilirsiniz ve çoğu durumda size bunun olup olmadığını söyleyecektir. Ancak insan benzeri olmayan bazı hatalar yapacaktır. Nedenini anlayabilir miyiz?Sadece birkaç hafta önce piyasaya sürülen GPT-3, gradyan inişi olmadan öğrenebileceğini gösteren ilk model, bir şeyleri girdi olarak modele koyabilirsiniz ve sanki onları eğitiyormuş gibi çalışır, bu yüzden bu çok yeni ve test etmesi çok zor çünkü büyük modele ihtiyacınız var .Yarım yıl veya yıl içinde, bunu uygulamalı olarak yapmaya başlayabileceğiniz modeller olacak. Öğrenmeye başlamak için harika bir zaman. Çünkü dile giren bu şeylerin çoğunun başlangıcı. Teknolojiyi aldık ama aslında dilin derinliklerine inerken hala önümüzde çok düşündüğümüz bu uygulamaları getirecek.GPT-3 transformer modeli tüm web üzerinden eğitildi. Gelecekteki öğrenmeyi biraz beklenmedik olan yeni görevlere genelleştirir, ancak gerçekten tüm web üzerinde eğitilmiştir. Yani bir anlamda o kadar da beklenmedik değil ve arabalarda eğiteceğimiz daha küçük modelleri bile göreceksiniz, onlar da genelleştiriyorlar. Bu yüzden şimdi GPT-3 size harika cevaplar veriyor ama bu cevaplar ne işe yarıyor ve belki görevleriniz soruya uyuyor. Ancak görevinizi çözmeniz gerekir, genellikle görevinizi çözmek için modeli kullanmak ister ve onunla oynarsınız.Tamam işe yaramaz bir görevi çözmelisin deneyim kazanıp, öğrenmen gerekiyor ama daha sonra gerçek dünya görevinde bir araç kullanmalısın ve harika çeviri modellerimiz var. Google Translate sadece bu model değil tam da bunun gibi derin öğrenme modeli başlatamazsın. Biraz regex eklemelisiniz. Korkunç bir çıktı üretip üretmediğini görmek için basit bir regexin için bile, tüm eski tekniklere ön işleme(pre-processing) koymanız gerekir. Kullanıcılarınıza, müşterilerinize sonuç olarak neyi çıkardığınıza bakmanız ve bunu doğrulamanız gerekir. Bu modelin neden belirli durumlarda kötü çıktılar verdiğini ve modeli nasıl tamir edeceğinizi bilmiyorsanız düşünmeye başlamanız gerekir.Hala bilmediğimiz çok şey var, o zaman buna karşı biraz savunma yapmanız gerekiyor, belki sadece modelin gerçekten kötü olduğu ve GPT-3’ün kötü olduğu durumları tespit edin. GPT-3 diğer pek çok durumda iyidir, bu yüzden onu nasıl kullanacağınızı gerçekten öğrenmeniz gereken bir araç olduğunu öğrenmeniz gerekir. Verimli bir şekilde kullanabileceğiniz her yerde deneyim kazanın, sadece alıp uygulamak işe yarıyor mu? Hayır. Ne zaman çalıştığını, nasıl çalıştığını anlamak için çok iş var. Yıllar geçtikçe, bu şeylerin gerçekte nasıl çalıştığını daha iyi anlayacağımızı umuyoruz. Bunlar dilde biraz daha derine inmemize, ancak yine de uzun bir yol kat etmemize olanak tanıyan araçlar. Onu nerede nasıl kullanabileceğimizi öğrenmemiz gereken uzun bir yolumuz var ama bizim de ihtiyacımız olan başka şeyler olabilir ve kesinlikle bir GPT-4 olacaktır, bu yolun sonu değil, ama bu yolda büyük bir adım. Bir diğer panelist olan makine öğrenmesi ve yapay zeka alanında verdiği eğitimlerle birçok insanın hayatına dokunan Prof. Andrew NG GPT-3 ün çıkışı hakkında şunları söyledi: “İnanılmaz görünen her şey, çok çalıştığımızda ve bunları iyileştirdiğimizde, niş görünse bile doğru uygulamaları bulduğumuzda, bir gün okuduğumuz ve hayran kaldığımız bu modelin nerede olduğunu hayal edin. Kol saatinizde koşacak mıyım bilmiyorum ama teknoloji bu şekilde daha kullanılabilir hale geliyor. Şu anda NLP alanında çok sayıda zayıf sinyal görüyorum. Bunun patlayacağını ve daha yetenekli ve daha yaygın hale geleceğini düşündüğüm şeylerle yapabilirsiniz. Umarım bu araçları öğrenerek bu devrime katılabilirsiniz.” GPT-3 parlak bir obje mi? Doğru zamanda mı piyasa sürüldü? İşlerimizi elimizden alacak mı? Bu tür sorulardan ziyade kendimizi güncel tutmalı öğrenebileceğimiz herşeyi öğrenmeli, tüm yetkinlikleri kazanmalıyız. Bu yetkinlikleri bir sonraki ürünü geliştirmek için kullanmalıyız. Bu GPT4, GPT-5 yada adı her ne ise kendimizi geliştirip bu henüz yüzeyinde olduğumuz dünyanın derinlerine inmeliyiz. O dünyanın nasıl olacağını belirleyenler arasında olmalıyız.","link":"/GPT-3/"},{"title":"Feature Scaling","text":"Makine öğreniminde feature scaling (özellik ölçeklendirme), bir makine öğrenimi modeli oluşturmadan önce verilerin ön işlenmesi sırasında en kritik adımlardan biridir. Ölçeklendirme, zayıf bir makine öğrenimi modeli ile daha iyisi arasında bir fark yaratabilir. Makine öğrenimi, karışık meyve suyu yapmak gibidir. En iyi karıştırılmış suyu elde etmek istiyorsak, tüm meyveleri boyutlarına göre değil, doğru oranlarına göre karıştırmamız gerekir. Benzer şekilde, birçok makine öğrenimi algoritmasında, tüm özellikleri aynı duruma getirmek için, ölçeklendirme yapmamız gerekir, böylece tek bir önemli sayı oluşturduğumuz modeli büyüklükleri nedeniyle etkileyemez. Feature scaling işleminde en çok kullanılanlar Normalizasyon ve Standardizasyon teknikleridir.Normalizasyonda değerlerimizi iki sayı arasında, tipik olarak [0,1] veya [-1,1] arasında sınırlamak istediğimizde normalleştirme kullanılır.Standardizasyon, verileri sıfır ortalamaya ve 1 varyansına dönüştürürken, verilerimizi birimsiz hale getirir. Peki neden gereklidir? Makine öğrenimi algoritması sadece sayıyı görür. Eğer aralıkta çok büyük bir fark varsa, bir tarafta farkın binler olduğunu ve diğer tarafta farkın onlar arasında değiştiğini farzedelim. Daha yüksek aralıklı sayıların bir tür üstünlüğe sahip olduğu varsayımını yapar. Dolayısıyla bu daha önemli sayı, modeli eğitirken daha belirleyici bir rol oynamaya başlar. Makine öğrenimi algoritması sayılar üzerinde çalışır ve bu sayının neyi temsil ettiğini bilmez. 10 gramlık bir ağırlık ve 10 dolarlık bir fiyat tamamen iki farklı şeyi temsil ediyor ama makine öğrenmesi algoritması bunun farklı olduğunu anlamıyor ve model için her ikisine aynı muamelesi yapıyor. Dolayısıyla bu daha önemli sayı, modeli eğitirken daha belirleyici bir rol oynamaya başlar. Bu nedenle, herhangi bir ön önem olmaksızın her özelliği aynı temelde getirmek için Feature Scaling “özellik ölçeklendirmesi” gereklidir. İlginç bir şekilde, ağırlığı “Kg” ye çevirirsek, “Fiyat” baskın hale gelir.Özellik ölçeklemenin uygulanmasının bir başka nedeni de, sinir ağı gradyan descent gibi birkaç algoritmanın, özellik ölçeklendirmesi olunca global minimuma çok daha hızlı yakınlaşmasıdır. Verilerin arasındaki mesafeyi ölçen makine öğrenmesi algoritmaları için feature scaling çok önemlidir. Eğer ölçeklendirme yapılmazsa, yüksek değere sahip özellik mesafe ölçümünü domine edecektir.Birçok algoritmada, daha hızlı yakınsama istediğimizde ölçeklendirme, sinir ağında olduğu gibi bir zorunluluktur.Ham verilerin değer aralığı büyük ölçüde değiştiğinden, bazı makine öğrenimi algoritmalarında, nesnel işlevler normalleştirme olmadan doğru şekilde çalışmaz. Örneğin, sınıflandırıcıların çoğu iki nokta arasındaki mesafeyi mesafeye göre hesaplar. Özelliklerden biri geniş bir değer aralığına sahipse, mesafe bu belirli özelliği yönetir. Bu nedenle, tüm özelliklerin aralığı normalize edilmelidir, böylece her özellik son mesafeye yaklaşık orantılı olarak katkıda bulunur.Yukarıda belirtildiği gibi koşullar karşılanmadığında bile, ML algoritması bir ölçek beklerse veya bir saturation fenomeni meydana gelirse, tekrar özelliklerinizi yeniden ölçeklendirmeniz gerekebilir. Yine, doyurucu aktivasyon işlevlerine (örneğin sigmoid) sahip bir sinir ağı iyi bir örnektir.Özellik ölçeklendirmesinin önemli olduğu bazı algoritmalara bakalım. • K-nearest neighbors (KNN) Öklid mesafe ölçüsü ile büyük değerlere duyarlıdır ve bu nedenle tüm özelliklerin eşit olarak tartılması için ölçeklendirilmelidir. • K-Means burada Öklid mesafe ölçüsünü kullanır özellik ölçekleme önemlidir. • Principal Component Analysis(PCA) gerçekleştirilirken ölçeklendirme çok önemlidir. PCA, feature(özellikleri) maksimum varyansla elde etmeye çalışır ve varyans, yüksek büyüklükteki özellikler için yüksektir ve PCA’yı yüksek büyüklük özelliklerine doğru çarpıtır. • Gradient Descent’i ölçeklendirerek hızlandırabiliriz çünkü küçük aralıklarda hızlı ve büyük aralıklarda yavaşça iner ve değişkenler çok düzensiz olduğunda verimsiz bir şekilde optimum seviyeye iner. Normalleştirme / ölçeklendirme gerektirmeyen algoritmalar, kurallara bağlı olanlardır. Değişkenlerin herhangi bir monoton dönüşümünden etkilenmezler. Ölçeklendirme, tekdüze bir dönüşümdür. Bu kategorideki algoritmaların örnekleri, tüm tree-tabanlı algoritmalardır. Bunlar CART, Random Forests, Gradient Boosted Decision Trees. Bu algoritmalar kuralları kullanır(eşitsizlikler dizisi) ve normalleştirme gerektirmez.Linear Discriminant Analysis(LDA), Naive Bayes gibi algoritmalar bu durumu işlemek ve özelliklere göre ağırlık vermek için donatılmış tasarımlara sahiptirler.Bu algoritmalarda özellik ölçeklendirmesinin gerçekleştirilmesinin çok fazla etkisi olmayabilir. Dikkat edilmesi gereken birkaç önemli nokta: • Ortalama merkezleme kovaryans matrisini etkilemez. • Değişkenlerin ölçeklendirilmesi kovaryans matrisini etkiler. • Standardizasyon kovaryansı etkiler. Feature Scaling Yöntemleri Min-Max Scaler Standard Scaler Max Abs Scaler Robust Scaler Quantile Transformer Scaler Power Transformer Scaler Unit Vector Scaler Bu yöntemleri elimizdeki küçük veri seti ile açıklamaya başlayalım. 12345678import pandas as pdimport numpy as npimport matplotlib.pyplot as plt%matplotlib inlinedf = pd.DataFrame({'WEIGHT': [15, 18.5, 14,5,1], 'PRICE': [1,3,4,7,10]}, index = ['Pineapple','Apple','Strawberry','Watermelon',\"Fig\"])print(df) WEIGHT PRICE Pineapple 15.0 1 Apple 18.5 3 Strawberry 14.0 4 Watermelon 5.0 7 Fig 1.0 10 1)Min-Max scaler Min-max Scaler verilen aralığa göre özellikleri ölçekler. Bu tahmin aracı, her özelliği, eğitim setinde verilen aralıkta, örneğin sıfır ile bir arasında olacak şekilde tek tek ölçeklendirir ve çevirir. Bu ölçekleyici, negatif değerler varsa -1 ile 1 aralığında verileri küçültür. Aralığı [0,1] veya [0,5] veya [-1,1] gibi ayarlayabiliriz. Bu Ölçekleyici, standart sapma küçükse ve dağılım Gaussian değilse iyi sonuç verir. Min-max scaler, aykırı değerlere karşı hassastır. 12345678910111213from sklearn.preprocessing import MinMaxScalerscaler = MinMaxScaler()df1 = pd.DataFrame(scaler.fit_transform(df), index=['Pineapple','Apple','Strawberry','Watermelon','Fig'], columns= ['WEIGHT','PRICE'])ax = df.plot.scatter(x='WEIGHT', y='PRICE',color=['red','green','blue','yellow','purple'], marker = '*',s=100, label='BREFORE SCALING');df1.plot.scatter(x='WEIGHT', y='PRICE', color=['red','green','blue','yellow','purple'], marker = \"2\",s=100,label='AFTER SCALING', ax = ax,figsize=(12,6));plt.axhline(0, color='cyan',alpha=0.9)plt.axvline(0, color='cyan',alpha=0.9);plt.show() 2) Standard Scaler Standart Scaler, verilerin normal olarak her bir özelliğe dağıtıldığını varsayar ve bunları, 1’lik bir standart sapma ile dağıtım 0 civarında ortalanacak şekilde ölçeklendirir. Merkezleme ve ölçeklendirme, training setideki örnekler üzerindeki ilgili istatistikleri hesaplayarak her özellik için bağımsız olarak gerçekleşir. Veriler normal olarak dağıtılmıyorsa, bu kullanılacak en iyi ölçekleyici değildir. 1234567891011from sklearn.preprocessing import StandardScalerscaler = StandardScaler()df2 = pd.DataFrame(scaler.fit_transform(df), columns=['WEIGHT','PRICE'], index = ['Pineapple','Apple','Strawberry','Watermelon','Fig'])ax = df.plot.scatter(x='WEIGHT', y='PRICE',color=['red','green','blue','yellow','purple'], marker = '*',s=100, label='BREFORE SCALING');df2.plot.scatter(x='WEIGHT', y='PRICE', color=['red','green','blue','yellow','purple'], marker = \"d\",s=100,label='AFTER SCALING', ax = ax, figsize=(12,6));plt.axhline(0, color='cyan',alpha=0.9);plt.axvline(0, color='cyan',alpha=0.9); 3) Max Abs ScalerMax Abs Scaler her özelliği maksimum mutlak değerine göre ölçekler. Bu ölçekleyici, eğitim setindeki her bir özelliğin maksimum mutlak değeri 1.0 olacak şekilde her özelliği ayrı ayrı ölçeklendirir ve çevirir. Verileri kaydırmaz, ortalamaz ve dolayısıyla herhangi bir seyrekliği yok etmez. Yalnızca pozitif verilerde, bu ölçekleyici Min-Maks ölçekleyiciye benzer şekilde davranır ve bu nedenle önemli aykırı değerlerin varlığından da muzdariptir. 1234567891011from sklearn.preprocessing import MaxAbsScalerscaler = MaxAbsScaler()df4 = pd.DataFrame(scaler.fit_transform(df), columns=['WEIGHT','PRICE'], index = ['Pineapple','Apple','Strawberry','Watermelon','Fig'])ax = df.plot.scatter(x='WEIGHT', y='PRICE',color=['red','green','blue','yellow','purple'], marker = '*',s=100, label='BREFORE SCALING');df4.plot.scatter(x='WEIGHT', y='PRICE', color=['red','green','blue','yellow','purple'], marker = '3',s=100,label='AFTER SCALING', ax = ax, figsize=(12,6))plt.axhline(0, color='cyan',alpha=0.9)plt.axvline(0, color='cyan',alpha=0.9); 4) Robust ScalerBu ölçekleyici aykırı değerlere karşı sağlamdır. Verilerimiz çok sayıda aykırı değer içeriyorsa, verilerin ortalamasını ve standart sapmasını kullanarak ölçeklendirme iyi sonuç vermeyecektir. Bu ölçekleyici medyanı kaldırır ve verileri nicelik aralığına göre ölçeklendirir ( IQR: Çeyrekler Arası Aralık). IQR, 1. çeyrek (25.inci kuantil) ile 3. çeyrek (75.inci kuantil) arasındaki aralıktır. Bu ölçekleyicinin merkezleme ve ölçeklendirme istatistikleri yüzdelik dilimlere dayanmaktadır ve bu nedenle birkaç sayıdaki büyük marjinal aykırı değerlerden etkilenmez. Aykırı değerlerin kendilerinin dönüştürülmüş verilerde hala mevcut olduğuna unutmayın. Ayrı bir aykırı değer kırpılması isteniyorsa, doğrusal olmayan bir dönüşüm gereklidir. 1234567891011from sklearn.preprocessing import RobustScalerscaler = RobustScaler()df3 = pd.DataFrame(scaler.fit_transform(df), columns=['WEIGHT','PRICE'], index = ['Pineapple','Apple','Strawberry','Watermelon','Fig'])ax = df.plot.scatter(x='WEIGHT', y='PRICE',color=['red','green','blue','yellow','purple'], marker = '*',s=100, label='BREFORE SCALING');df3.plot.scatter(x='WEIGHT', y='PRICE', color=['red','green','blue','yellow','purple'], marker = 'v',s=100,label='AFTER SCALING', ax = ax,figsize=(12,6))plt.axhline(0, color='cyan',alpha=0.9)plt.axvline(0, color='cyan',alpha=0.9); Şimdi bir aykırı değer sunarsak ve Standart Scaler ve Robust Scaler kullanarak ölçeklendirmenin etkisini görürsek ne olacağını görelim (karo şekil aykırı değeri gösterir). 12345678910111213141516171819202122dfr = pd.DataFrame({'WEIGHT': [15, 18, 12,10,50], 'PRICE': [1,3,2,5,20]}, index = ['Apricot','Apple','Banana','Grape','Cherry'])print(dfr)from sklearn.preprocessing import StandardScalerscaler = StandardScaler()df21 = pd.DataFrame(scaler.fit_transform(dfr), columns=['WEIGHT','PRICE'], index = ['Apricot','Apple','Banana','Grape','Cherry'])ax = dfr.plot.scatter(x='WEIGHT', y='PRICE',color=['purple','green','blue','yellow','black'], marker = '*',s=80, label='BREFORE SCALING');df21.plot.scatter(x='WEIGHT', y='PRICE', color=['purple','green','blue','yellow','black'], marker = 'd',s=50,label='STANDARD', ax = ax,figsize=(12,6))from sklearn.preprocessing import RobustScalerscaler = RobustScaler()df31 = pd.DataFrame(scaler.fit_transform(dfr), columns=['WEIGHT','PRICE'], index = ['Apricot','Apple','Banana','Grape','Cherry'])df31.plot.scatter(x='WEIGHT', y='PRICE', color=['purple','green','blue','yellow','black'], marker = 'v',s=50,label='ROBUST', ax = ax,figsize=(12,6))plt.axhline(0, color='cyan',alpha=0.9)plt.axvline(0, color='cyan',alpha=0.9); WEIGHT PRICE Apricot 15 1 Apple 18 3 Banana 12 2 Grape 10 5 Cherry 50 20 5) Quantile Transformer ScalerNicelik bilgilerini kullanarak özellikleri dönüştürür. Bu yöntem, özellikleri tek tip veya normal bir dağılım izleyecek şekilde dönüştürür. Bu nedenle, belirli bir özellik için, bu dönüşüm en sık görülen değerleri yayma eğilimindedir. Aynı zamanda (marjinal) aykırı değerlerin etkisini de azaltır: bu nedenle bu, Robust bir preprocessing şemasıdır. Bir özelliğin kümülatif dağılım işlevi, orijinal değerleri yansıtmak için kullanılır. Bu dönüşümün doğrusal olmadığını ve aynı ölçekte ölçülen değişkenler arasındaki doğrusal korelasyonları bozabileceğini, ancak farklı ölçeklerde ölçülen değişkenleri daha doğrudan karşılaştırılabilir hale getirdiğini unutmayın. Bu aynı zamanda bazen Rank Scaler olarak da adlandırılır. 1234567891011from sklearn.preprocessing import QuantileTransformerscaler = QuantileTransformer()df6 = pd.DataFrame(scaler.fit_transform(df), columns=['WEIGHT','PRICE'], index = ['Pineapple','Apple','Strawberry','Watermelon','Fig'])ax = df.plot.scatter(x='WEIGHT', y='PRICE',color=['red','green','blue','yellow','purple'], marker = '*',s=100, label='BREFORE SCALING');df6.plot.scatter(x='WEIGHT', y='PRICE', color=['red','green','blue','yellow','purple'], marker = 'X',s=100,label='AFTER SCALING', ax = ax,figsize=(12,6))plt.axhline(0, color='cyan',alpha=0.9)plt.axvline(0, color='cyan',alpha=0.9); C:\\Users\\kader\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (5). n_quantiles is set to n_samples. % (self.n_quantiles, n_samples)) 6)Power Transformer ScalerParametrik, monoton dönüşümler ailesinden olan Power Transformatörü, verileri daha Gaussian benzeri hale getirmek için uygulanır. Bu yöntem, aralık boyunca eşit olmayan bir değişkenin değişkenliği (farklı varyans) veya normalliğin istendiği durumlar ile ilgili sorunları modellemek için yararlıdır. Power Transformatörü, maksimum olasılık tahmini yoluyla varyansı stabilize etmede ve çarpıklığı en aza indirmede optimum ölçeklendirme faktörünü bulur. Şu anda, PowerTransformer’ın Sklearn uygulaması Box-Cox transformu ve Yeo-Johnson transformu desteklemektedir. Varyansı sabitlemek ve çarpıklığı en aza indirmek için en uygun parametre maksimum olasılıkla tahmin edilir. Box-Cox, giriş verilerinin kesinlikle pozitif olmasını gerektirirken, Yeo-Johnson hem pozitif hem de negatif verileri destekler. 1234567891011from sklearn.preprocessing import PowerTransformerscaler = PowerTransformer(method='yeo-johnson')df5 = pd.DataFrame(scaler.fit_transform(df), columns=['WEIGHT','PRICE'], index = ['Pineapple','Apple','Strawberry','Watermelon','Fig'])ax = df.plot.scatter(x='WEIGHT', y='PRICE',color=['red','green','blue','yellow','purple'], marker = '*',s=100, label='BREFORE SCALING');df5.plot.scatter(x='WEIGHT', y='PRICE', color=['red','green','blue','yellow','purple'], marker = '&lt;',s=100,label='AFTER SCALING', ax = ax, figsize=(12,6))plt.axhline(0, color='cyan',alpha=0.9)plt.axvline(0, color='cyan',alpha=0.9); 7) Unit Vector ScalerÖlçeklendirme, bütün özellik vektörünün birim uzunluk olduğu düşünülerek yapılır. Bu genellikle her bileşeni vektörün Öklid uzunluğuna (L2 Normu) bölmek anlamına gelir. Bazı uygulamalarda (örn. histogram özellikleri), özellik vektörünün L1 normunu kullanmak daha pratik olabilir. L1 normu, oldukça açık nedenlerden dolayı L2 normundan daha sağlamdır: L2 normunun kareleri değerleri, dolayısıyla aykırı değerlerin maliyetini üssel olarak artırır; L1 normu yalnızca mutlak değeri alır, bu nedenle onları doğrusal olarak değerlendirir. Min-Maks ölçeklendirmede olduğu gibi, birim vektör tekniği [0,1] aralığında değerler üretir. Katı sınırları olan özelliklerle uğraşırken bu oldukça kullanışlıdır. Örneğin, görüntü verileriyle uğraşırken renkler yalnızca 0 ile 255 arasında değişebilir. 1234## Unit vector with L1 normdf8 =df.apply(lambda x:x/np.linalg.norm(x,1))df8 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } WEIGHT PRICE Pineapple 0.280374 0.04 Apple 0.345794 0.12 Strawberry 0.261682 0.16 Watermelon 0.093458 0.28 Fig 0.018692 0.40 1234## Unit vector with L2 normdf9 =df.apply(lambda x:x/np.linalg.norm(x,2))df9 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } WEIGHT PRICE Pineapple 0.533930 0.075593 Apple 0.658513 0.226779 Strawberry 0.498334 0.302372 Watermelon 0.177977 0.529150 Fig 0.035595 0.755929 Aşağıdaki diyagram, verilerin tüm farklı ölçekleme teknikleri için nasıl yayıldığını ve görebileceğimiz gibi, birkaç noktanın üst üste geldiğini, dolayısıyla ayrı ayrı görünmediğini göstermektedir. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162dfr = pd.DataFrame({'WEIGHT': [15, 18, 12,10,50], 'PRICE': [1,3,2,5,20]}, index = ['Apricot','Apple','Banana','Grape','Cherry'])print(dfr)from sklearn.preprocessing import MinMaxScalerscaler1 = MinMaxScaler()df11 = pd.DataFrame(scaler1.fit_transform(dfr), columns=['WEIGHT','PRICE'], index = ['Apricot','Apple','Banana','Grape','Cherry'])ax = dfr.plot.scatter(x='WEIGHT', y='PRICE',color=['purple','green','blue','yellow','red'], marker = '*',s=50, label='BREFORE SCALING');df11.plot.scatter(x='WEIGHT', y='PRICE', color=['purple','green','blue','yellow','red'], marker = '2',s=100,label='MİN-MAX SCALİNG', ax = ax,figsize=(12,6))from sklearn.preprocessing import StandardScalerscaler2 = StandardScaler()df21 = pd.DataFrame(scaler2.fit_transform(dfr), columns=['WEIGHT','PRICE'], index = ['Apricot','Apple','Banana','Grape','Cherry'])df21.plot.scatter(x='WEIGHT', y='PRICE', color=['purple','green','blue','yellow','red'], marker = 'd',s=50,label='STANDARD SCALİNG', ax = ax,figsize=(12,6))from sklearn.preprocessing import RobustScalerscaler3 = RobustScaler()df31 = pd.DataFrame(scaler3.fit_transform(dfr), columns=['WEIGHT','PRICE'], index = ['Apricot','Apple','Banana','Grape','Cherry'])df31.plot.scatter(x='WEIGHT', y='PRICE', color=['purple','green','blue','yellow','red'], marker = 'v',s=50,label='ROBUST SCALİNG', ax = ax,figsize=(12,6))from sklearn.preprocessing import MaxAbsScalerscaler4 = MaxAbsScaler()df41 = pd.DataFrame(scaler4.fit_transform(dfr), columns=['WEIGHT','PRICE'], index = ['Apricot','Apple','Banana','Grape','Cherry'])df41.plot.scatter(x='WEIGHT', y='PRICE', color=['purple','green','blue','yellow','red'], marker = '3',s=50,label='MAX ABS SCALİNG', ax = ax,figsize=(12,6))from sklearn.preprocessing import QuantileTransformerscaler5 = QuantileTransformer()df51 = pd.DataFrame(scaler5.fit_transform(df), columns=['WEIGHT','PRICE'], index = ['Apricot','Apple','Banana','Grape','Cherry'])df51.plot.scatter(x='WEIGHT', y='PRICE', color=['purple','green','blue','yellow','red'], marker = '&lt;',s=50,label='QUANTİLE TRANSFORM SCALİNG', ax = ax,figsize=(12,6))from sklearn.preprocessing import PowerTransformerscaler6 = PowerTransformer(method='yeo-johnson')df61 = pd.DataFrame(scaler6.fit_transform(df), columns=['WEIGHT','PRICE'], index = ['Apricot','Apple','Banana','Grape','Cherry'])df61.plot.scatter(x='WEIGHT', y='PRICE', color=['purple','green','blue','yellow','red'], marker = 'X',s=50,label='POWER TRANSFORM SCALİNG', ax = ax,figsize=(12,6))plt.axhline(0, color='cyan',alpha=0.9)plt.axvline(0, color='cyan',alpha=0.9); WEIGHT PRICE Apricot 15 1 Apple 18 3 Banana 12 2 Grape 10 5 Cherry 50 20 C:\\Users\\kader\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (5). n_quantiles is set to n_samples. % (self.n_quantiles, n_samples)) Feature Scaling, Makine öğrenimi pre-processing kısmında önemli bir adımdır. Derin öğrenme, daha hızlı yakınsama için feature scaling gerektirir ve bu nedenle hangi feature scaling yöntemini kullanılacağına karar vermek çok önemlidir. Çeşitli algoritmalar için ölçeklendirme yöntemlerinin birçok karşılaştırma araştırması vardır. Yine de, diğer makine öğrenimi adımlarının çoğu gibi, özellik ölçeklendirme de bir deneme yanılma sürecidir.","link":"/Featurescaling/"},{"title":"Classification","text":"Supervised Learning(denetimli öğrenme) ve Unsupervised Learning(denetimsiz öğrenme) olan en yaygın iki öğrenme türünden Supervised Learning’den Classification(Sınıflandırma) problemi konusuna bakalım. Ayrıntılara girmeden önce Regresyon Problemi ile Sınıflandırma Problemi arasındaki fark nedir? Cevabı etiket türüdür.Regresyonda sürekli sayı varken sınıflandırmada aykırı sayı vardır. Regresyon problemi için ev fiyatları(etiket) için m^2 ve fiyatlarının olduğu verisetinde değerler gerçek ve sürekli değerlerdir. Buna bir diger örnek olarak hava durumu tahminlemesi eklenebilir. Sınıflandırma problemindeki etiket ise “kategori” yi temsil etmektedir. İkili sınıf(binary class) problemi için meme kanseri teşhisini örnek alıyoruz. Meme kanseri teşhisinde en çok ilgilendiğimiz şey tümör tipi yani kötü huylu veya iyi huyludur. Kolaylık sağlamak için, basitçe kötü huylu(malignant) ve zararsız(benign) olarak sırasıyla 0 ve 1 olarak etiketledik. Ayrık sayının (0 ve 1) verilerin etiketi (tümör tipi) anlamına geldiğine dikkat edin. y∈ {0,1} 0: “Negative Class” (e.g. benign tumor) 1: “Positive Class” (e.g. malignant tumor) Sınıflandırmada örnekler: Email: Spam/ Not Spam? Online Transactions : Fraudulent (Yes/No)? Tümor : Malignant /Benign? Feature : Size(cm) Label : Tumor Type Logistic RegressionHypothesis FunctionEtiket türü Regresyon Probleminden farklı olduğundan, Sınıflandırma problemini çözmek için başka bir hipotez kullanmalıyız.Bu problemi çözmek için Lojistik Regresyonu kullanılır. **Lojistik Regresyon, gerçek sayıları olasılıklara eşleyen bir sigmoid işlevi olarak da adlandırılır, [0, 1] aralığındadır. Dolayısıyla, sigmoid fonksiyonunun değeri, verilerin bir kategoriye ne kadar kesin ait olduğu anlamına gelir. Y’nin etiketi temsil ettiğini, y = 1’in hedef etiketi ve y = 0’ın diğer etiket olduğunu unutmamalıyız. Sigmoid işlevinde her zaman hedef etiketiyle ilgileniyoruz. Çoğu durumda, olasılık eşiği olarak 0,5 alırız. Eğer h (x) ≥0.5 ise, verilerin etiket 1’e ait olduğunu, h (x) &lt;0.5 ise, verilerin etiket 0’a ait olduğunu tahmin ediyoruz. Aşağıdaki görselde Lineer ve Lojistik Regresyonun farkını daha iyi görebiliriz. Lojistik regresyondan çizgi “S” şeklini alıyor. Eğri hipotezin ( kötü huylu tümor(1) veya iyi huylu tümor(0)) doğru olma olasılığını söylüyor. Lineer Regresyonda, en uygun çizgiyi tahmin etmek için Ordinary Least Squares (OLS) yöntemini kullanıyoruz, benzer şekilde burada da lojistik eğrimizi seçmek için Maximum Likelihood tahminini kullanıyoruz. Lineer regresyonda kullandığımız hipotez formülü: hΘ(x) = β₀ + β₁X Lojistik regresyonda biraz değiştirmemiz gerekiyor. σ(Z) = σ(β₀ + β₁X) Z = β₀ + β₁X hΘ(x) = sigmoid(Z) hΘ(x) = 1/(1 + e^-(β₀ + β₁X) Decision BoundarySınıflandırıcımızın, girdileri bir tahmin fonksiyonundan geçirip 0 ile 1 arasında bir olasılık puanı döndürdüğümüzde olasılığa dayalı bir dizi çıktı veya sınıf vermesini bekliyoruz. Örneğin, 2 sınıfımız var, onları kedi ve köpek gibi alalım (1 - köpek, 0 - kedi). Temel olarak, değerleri Sınıf 1 olarak sınıflandırdığımız ve değerin eşiğin (threshold) altına düştüğü bir eşik değeri ile karar veririz ve ardından bunu Sınıf 2’de sınıflandırırız. Yukarıdaki grafikte gösterildiği gibi eşiği 0.5 olarak seçtik, eğer tahmin fonksiyonu 0.7 değerini döndürdüyse bu gözlemi Sınıf 1 (köpek) olarak sınıflandırdık. Tahminimiz 0,2 değerini döndürdüyse, gözlemi Sınıf 2 (kedi) olarak sınıflandırdık. hθ(x) = g(θ0 + θ1x1 + θ2x2) Örnek olarak;θ0 = -3θ1 = 1θ2 = 1 Yani parametre vektörümüz yukarıdaki değerlere sahip bir sütun vektörüdür. Yani,θT bir satır vektörü = [-3,1,1] Peki, ne anlama geliyor? Buradaki z, θT x olur. Eğer “y = 1” ise bunu tahmin ediyoruz. -3x0 + 1x1 + 1x2 &gt;= 0 -3 + x1 + x2 &gt;= 0 Bunu şu şekilde de yazabiliriz: Eğer (x1 + x2&gt; = 3) ise y = 1’i tahmin ediyoruz. Eğer bunu görselleştirirsek; x1 + x2 = 3 karar sınırımızı(decision boundary) grafik olarak çiziyoruz. Grafikte bu iki bölgeye sahip olduğumuz anlamına gelir. Mavi = Yanlış Pembe = Doğru Çizgi = Karar Sınırı Somut olarak, düz çizgi, tam olarak hθ (x) = 0,5 olan noktalar kümesidir. Karar sınırı, hipotezin bir özelliğidir. Herhangi bir veri olmadan hipotez ve parametrelerle sınır oluşturabileceğimiz anlamına gelir. Daha sonra verileri parametre değerlerini belirlemek için kullanırız. Eğer y=1 5 - x1 &gt; 0 5 &gt; x1 Non-Linear Decision Boundaries Doğrusal olmayan karmaşık bir veri kümesine lojistik regresyon uygulayalım. Polinom regresyonu gibi daha yüksek mertebeden terimler ekleyelim. Öyleyse sahip olduğumuz hipotezimiz şöyle olur; Θ vektörünün transpozu ile giriş vektörünü çarpıyoruz. ΘT [-1,0,0,1,1] “Y = 1” olan durumu tahmin edelim. Bu bize yarıçapı 1, 0 civarında olan bir daire verir. Bu (görece) basit hipoteze karmaşık parametreleri yerleştirerek daha karmaşık karar sınırları oluşturabileceğimiz anlamına gelir. Daha karmaşık karar sınırları? Daha yüksek dereceden polinom terimleri kullanarak daha da karmaşık karar sınırları elde edebiliriz. Cost Function (J(θ))Lineer Regresyonda cost fonksiyonu; Cost function optimizasyon hedefini temsil ediyor, yani bir maliyet fonksiyonu oluşturuyor ve minimum hatayla doğru bir model geliştirebilmemiz için bunu en aza indiriyoruz. Lojistik regresyon için cost fonksiyonu ; Sonucu bize konveks olmayan sonuç verecektir. Global minimuma ulaşmaya çalışan Gradiyen Descent için lokal optimada kalan bu sonuç büyük bir problem verecektir. −log(hθ(x)) eğer y = 1 −log(1−hθ(x)) eğer y = 0 Bu tek bir örneğin cost fonksiyonudur. İkili sınıflandırma problemleri için y her zaman 0 veya 1’dir Bu nedenle, maliyet fonksiyonunu yazmanın daha basit bir yolunu bulabiliriz.θ parametreleri için maliyet fonksiyonumuz şu şekilde tanımlanabilir: Diğer maliyet fonksiyonları varken neden bu fonksiyonu seçiyoruz? Bu cost fonksiyonu, maksimum olasılık tahmini(maximum likehood estimation) ilkesi kullanılarak istatistiklerden türetilebilir. Bunun, özelliklerin dağıtımıyla ilgili temel bir Gauss varsayımı olduğu anlamına geldiğini unutmayın. Dışbükey olması da güzel bir özelliğe sahiptir. Parametreleri sığdırmak için θ: J (θ) ‘yı en aza indiren θ parametreleri bulunur. Bu, modelimizde gelecekteki tahminler için kullanacağımız bir dizi parametremiz olduğu anlamına gelir. Ardından, x özellik kümesiyle yeni bir örnek verilirse, oluşturduğumuz θ’yı alabilir ve tahminimizi çıkarabiliriz. Lojistik regresyon’da cost fonksiyonu nasıl en aza indirilir? J (θ) ‘yi nasıl minimize edeceğimizi bulmalıyız.Gradient Descenti eskisi gibi kullanacağız.Bir öğrenme oranı (learning rate) kullanarak her parametre tekrar tekrar güncellenir. Eğer n feature olsaydı, θ vektörünüz için n + 1 sütun olurdu. Bu denklem, doğrusal regresyon kuralı ile aynıdır.Tek fark, hipotez tanımımızın değişmiş olmasıdır. Gradient descent lojistik regresyon için aynı şeyi burada yapabilir. Gradyan inişli lojistik regresyon uygularken, tüm θ değerlerini (θ0’dan θn’ye) aynı anda güncellemeliyiz Bir for döngüsü kullanabilir. Vektörize bir uygulama daha iyi olur. Lojistik regresyon için gradyan inişi için özellik ölçeklendirme(feature scaling) burada da geçerlidir. Advanced Optimization Daha önce maliyet fonksiyonunu en aza indirmek için gradyan inişine bakmıştık. Lojistik regresyon için maliyet fonksiyonunu en aza indirmek için gelişmiş kavramlara bakalım. Büyük makine öğrenimi problemleri için iyidir (ör. Çok büyük feature seti) Gradyan inişi aslında ne yapıyor? Diyelim ki maliyet fonksiyonumuz J (θ) var ve bunu en aza indirmek istiyoruz. Girdi olarak θ alabilen ve aşağıdakileri hesaplayabilen bir kod yazmalıyız. J (θ) J’ye göre J (θ) ise kısmi türev (burada j = 0 ila j = n) Bu iki şeyi yapabilen kod verildiğinde; Gradyan inişi, aşağıdaki güncellemeyi tekrar tekrar yapar. Yani her j içindeki θ sırayla güncellenir. (θ) ve türevlerini hesaplamak için kod yazılır. Sonra bu değerleri gradyan inişine konur. Alternatif olarak, maliyet(cost) fonksiyonunu en aza indirmek için Conjugate gradient BFGS (Broyden-Fletcher - Goldfarb-Shanno) L-BFGS (Limited Memory - BFGS)gradyan inişi yerine kullanabilir. Bunlar, aynı girdiyi alan ve maliyet fonksiyonunu en aza indiren daha optimize edilmiş algoritmalardır.Bunlar çok karmaşık algoritmalardır. Avantajlar Manuel olarak alfa (öğrenme oranı) seçmeye gerek yok. Bir grup alfa değerini deneyen ve iyi bir tane seçen akıllı bir iç döngüye (line search algoritması) sahiptir. Genellikle gradyan inişinden daha hızlıdır. İyi bir öğrenme oranı seçmekten fazlasını yapar. Karmaşıklıklarını anlamadan başarıyla kullanılabilir. Dezavantajlar Hata ayıklamayı daha zor hale getirebilir. Kendileri uygulanmamalıdır. Farklı kitaplıklar farklı uygulamalar kullanabilir. Performansı etkileyebilir. Multiclass classification problemsLojistik regresyonda birden fazla sınıf olduğunda one vs. all tekniği kullanılır. Multiclass - evet veya hayır(1 veya 0)’dan fazlasıdır. Üç sınıflı bir veri kümesi verildiğinde, bir öğrenme algoritmasının çalışmasını nasıl sağlayabiliriz? Tüm sınıflandırmaya karşı birini kullanıp, ikili sınıflandırmayı çok sınıflı sınıflandırma için çalışır hale getiririz. One vs. all classification Eğitim setini üç ayrı ikili sınıflandırma problemine bölebiliriz. Yeni sahte bir trainning set oluşturup Üçgenler(1) vs çarpılar ve kareler(o) hθ1(x) P(y=1 | x1; θ) Kareler(1) vs üçgen ve çarpılar (o) hθ2(x) P(y=1 | x2; θ) Çarpılar (1) vs üçgen and kareler (o) hθ3(x) P(y=1 | x3; θ) y = i olasılığını tahmin etmek için her i sınıfı için bir lojistik regresyon sınıflandırıcı hθ (i) (x) eğitilir. Yeni bir girdide, x tahmin yapmak için, hθ (i) (x) = 1 olasılığını en üst düzeye çıkaran i sınıfı seçilir.","link":"/Classification/"}],"tags":[{"name":"Model","slug":"Model","link":"/tags/Model/"},{"name":"Representation","slug":"Representation","link":"/tags/Representation/"},{"name":"CostFunction","slug":"CostFunction","link":"/tags/CostFunction/"},{"name":"Regression","slug":"Regression","link":"/tags/Regression/"},{"name":"Linear Regression","slug":"Linear-Regression","link":"/tags/Linear-Regression/"},{"name":"Polynomial Regression","slug":"Polynomial-Regression","link":"/tags/Polynomial-Regression/"},{"name":"NLP","slug":"NLP","link":"/tags/NLP/"},{"name":"GPT-3","slug":"GPT-3","link":"/tags/GPT-3/"},{"name":"OpenAI","slug":"OpenAI","link":"/tags/OpenAI/"},{"name":"Feature Scaling","slug":"Feature-Scaling","link":"/tags/Feature-Scaling/"},{"name":"Min-Max Scaler","slug":"Min-Max-Scaler","link":"/tags/Min-Max-Scaler/"},{"name":"Standard Scaler","slug":"Standard-Scaler","link":"/tags/Standard-Scaler/"},{"name":"Max Abs Scaler","slug":"Max-Abs-Scaler","link":"/tags/Max-Abs-Scaler/"},{"name":"Robust Scaler","slug":"Robust-Scaler","link":"/tags/Robust-Scaler/"},{"name":"Quantile Transformer Scaler","slug":"Quantile-Transformer-Scaler","link":"/tags/Quantile-Transformer-Scaler/"},{"name":"Power Transformer Scaler","slug":"Power-Transformer-Scaler","link":"/tags/Power-Transformer-Scaler/"},{"name":"Unit Vector Scaler","slug":"Unit-Vector-Scaler","link":"/tags/Unit-Vector-Scaler/"},{"name":"Classification","slug":"Classification","link":"/tags/Classification/"},{"name":"Logistic Regression","slug":"Logistic-Regression","link":"/tags/Logistic-Regression/"},{"name":"Decision Boundary","slug":"Decision-Boundary","link":"/tags/Decision-Boundary/"},{"name":"Binary Classification","slug":"Binary-Classification","link":"/tags/Binary-Classification/"},{"name":"Multiclass Classification","slug":"Multiclass-Classification","link":"/tags/Multiclass-Classification/"}],"categories":[{"name":"Machine Learning","slug":"Machine-Learning","link":"/categories/Machine-Learning/"},{"name":"Deep Learning","slug":"Deep-Learning","link":"/categories/Deep-Learning/"}]}