{"pages":[],"posts":[{"title":"Model Representation","text":"Makine öğrenimi algoritmasının çoğunun temel amacı bir model oluşturmaktır. Bu modelden hipotez olarak söz edebiliriz. Hipotez temel olarak girdiyi çıktıya eşler. Girdi değişkeni özelliği ve çıktı değişkeni hedefi belirtir. Öğrenmek için kullanacağımız veri kümesine eğitim seti(trainning set) denir. Amacımız, bir eğitim seti verildiğinde, h: X → Y fonksiyonunu öğrenmek, böylece h (x), y’nin karşılık gelen değeri için “iyi” bir tahmin edici model diyebiliriz. Gelin bunu bir örnekle açıklayalım. Diyelim ki ev fiyatları tahmini yapmak istiyoruz. Elimizde evlerin m2 ölçüleri ve fiyatları var. Burada dikkat etmemiz gereken girdilerimiz yani “x” , fiyatını tahmin edeceğimiz çıktı “y” olacak. Eğer biz verilerimizden fiyat tahmini yapmak istiyorsak bunun için regresyon (regression) kullancağız. Eğer yaşam alanının ( villa, arsa , apartman vs.) ne olduğunu bulmak istiyorsak bunun için sınıflandırma (classification) kullanacağız. Hedefimiz fiyat tahmini bu yüzden regresyon kullancağız. Hipotez formülü : hQ(x) =θ0+θ1X Tetalar (θ) bizim parametrelerimizdir. Katsayılarımızı düzgün seçmeliyiz çünkü verilerimiz görselleştirdiğimizde eğimi 0 olduğunda tahminimiz yani y değeri hep 0 gelecektir.NOT: Model oluşturmanın amacı parametreleri veya teta değerlerini doğru seçmektir, böylece h (x) training verilerimiz olan x’ler için ulaşmak istedğimiz y değerine yakın olur. Eğer θ1 değerimizi yani eğimi veren değer 0 olursa aşağıdaki gibi grafik elde ederiz ve istediğimiz y değerine ulaşamayız. 1234import matplotlib.pyplot as pltplt.plot([1, 2, 3, 4], [1,1,1,1])plt.ylabel('some numbers')plt.show() Şimdi örnek verimizi görselleştirerek anlatalım.Elimizde evlerin ölçüleri ve fiyatları olsun burada eğim 0 olmadığından girdiğimiz her x değerimize karşılık y değeri geliyor bu da bize regression kullanarak fiyat tahmini yapmamızı sağlıyor.Aşağıdaki örnekteki gibi küçük bir verimiz olsun. 123import pandas as pddf = pd.DataFrame({'x': [0, 0.5, 1,1.5,2,2.5,3], 'hθ(x)': [1.0,1.5,2.0,2.5,3.0,3.5,4.0]})df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x hθ(x) 0 0.0 1.0 1 0.5 1.5 2 1.0 2.0 3 1.5 2.5 4 2.0 3.0 5 2.5 3.5 6 3.0 4.0 1234plt.plot([852, 1416,1534,2104], [178,232,315,460], color='blue')plt.ylabel('Price($) in 1000s')plt.xlabel('Size in house feet^2 (x)')plt.show() Üstteki grafikte olduğu gibi kırmızı noktalarla işaretlediğimiz 1750 feet^2 olan evimizin tahmini değeri 375000 $ civarı oluyor.İşte modelimizin bize tahminde bulunmasını istediğimiz değerleri böyle örneklendirebiliriz.","link":"/ModelRepresentation/"},{"title":"Cost Function","text":"Öncelikle lineer regresyonda tahmin edilen y değeri ile gerçek y değeri arasındaki hatayı minimuma indirebilmek için teta(θ) değerleri bulmalıyız. Maliyet fonksiyonunu (cost function) minimize etmeliyiz. Maliyet fonksiyonu diye gerçek y değerleri ile tahmin edilen y değerleri arasındaki farka deriz.Maliyet fonksiyonumuz test setindeki çıktıları ne kadar iyi tahmin ettiğini ölçer.Tahmin edilen değer ile gerçek değer arasındaki fark ne kadar az ise modelimiz o kadar iyi tahminde bulunur. Amaç, maliyeti en aza indiren bir dizi ağırlık(weight) ve önyargı(bias) bulmaktır. Bunun için y’nin gerçek değeri ile y’nin tahmini değeri (tahmin) arasındaki farkı ölçen ortalama kare hatası(the mean squared error)kullanılır. Aşağıdaki regresyon çizgisinin denklemi, sadece iki parametreye sahip olan hθ (x) = θ0 + θ1x’tir: weight(θ1) ve bias(θ0) Minimising Cost functionHerhangi bir makine öğrenmesi modelinin amacı cost fuction’ı (maliyet fonksiyonu) en aza indirgemektir. Gelin, yukarıdaki görselimizi anlayalım. Kırmızı olan tepecikler random olarak seçtiğimiz teta parametrelerimizin bulunduğu yeri temsil ediyor.Hedefimiz koyu mavi ile gösterilen “global minimum” dediğimiz yere doğru adım adım ilerlemek. Şekilde görüldüğü gibi ikinci bir mavi noktamız var buraya da “local minimum” diyoruz ama bu noktaya ilerlemiyoruz.Çünkü istediğimiz şey costu minimize etmek(hatalı değerlerimizi minimuma indirgemek) local minimumda değerimiz global minimuma göre daha yüksek çıkacağından hedefimiz her zaman global minimuma gitmek olmalıdır.Peki nasıl global minimuma varacağız. Bunun için etkili bir optimizasyon algoritması olan Gradient Descent Algoritmasını kullanacağız. Gradient Descent AlgorithmGradient Descent (Degrade İniş), hesaplamayı kullanarak belirli maliyet işlevinin minimum değerine karşılık gelen parametrelerin optimal değerlerini bulmak için yinelemeli olarak çalışır. Matematiksel olarak, ‘türev’ tekniği maliyet işlevini en aza indirmek için son derece önemlidir, çünkü minimum noktayı elde etmeye yardımcı olur. Türev, matematikten gelen bir kavramdır ve belirli bir noktada fonksiyonun eğimini ifade eder. Eğimi bilmemiz gerekir, böylece bir sonraki yinelemede daha düşük bir maliyet elde etmek için katsayı değerlerini hareket ettirme yönünü (işaretini) biliriz. Her parametredeki bir fonksiyonun türevi (bizim durumumuzda, J (θ)) bize bu değişkene göre fonksiyonun hassasiyetini veya değişkeni değiştirmenin fonksiyon değerini nasıl etkilediğini söyler. Gradient descent, bu nedenle, öğrenme sürecinin modeli optimal bir parametre kombinasyonuna doğru hareket ettiren öğrenilmiş tahminlerde düzeltici güncellemeler yapmasını sağlar (θ). Cost , bir gradient descent algoritmasının her tekrarı için tüm training set kümesinde bir makine öğrenme algoritması için hesaplanır. Gradient Descent, algoritmanın bir yinelemesine bir “Batch Gradient Descent” deniyor. Bu her bir yinelemenin gradyanını hesaplamak için kullanılan bir training set kümesindeki toplam örnek sayısını belirtir. Bu yeni gradyan, maliyet fonksiyonumuzun mevcut konumumuzdaki eğimini (geçerli parametre değerleri) ve parametrelerimizi güncellemek için hareket etmemiz gereken yönü gösterir. Güncellememizin boyutu learning rate (α)(öğrenme oranı) tarafından kontrol edilmektedir. Learning rate (α) Gradient descent algoritmasında adımların boyutuna, ne kadar büyük adımlar attığımız konusunda bize ek kontrol sağlayan değere learning rate (α) denir. Büyük bir learning rate(α) sağ alt köşedeki görselde olduğu gibi, her adımda daha fazla yer atlayabiliriz, ancak tepenin eğimi sürekli değiştiği için en düşük noktayı aşma riskiyle karşı karşıyayız. Çok düşük bir learning rate(α) sağ üst köşedeki görselde olduğu gibi, negatif gradyan yönünde güvenle hareket edebiliriz, çünkü bunu çok sık yeniden hesaplıyoruz. Düşük bir learning rate(α) daha kesindir, ancak gradyanı hesaplamak zaman alıcıdır, bu nedenle en alt noktaya gelmek çok uzun zaman alacaktır. En sık kullanılan learning rate(α) değerleri: 0.001, 0.003, 0.01, 0.03, 0.1, 0.3 Şimdi Gradient descent algoritmasının üç varyantını tartışalım. Aralarındaki temel fark, her bir learning step(öğrenme adımı) için degradeleri hesaplarken kullandığımız veri miktarıdır. Aralarındaki değişim, her bir parametrenin güncellemesini gerçekleştirmek için zaman karmaşıklığına karşı degradenin doğruluğudur (learning step). Stochastic Gradient Descent (SGD)Batch Gradient Descent ile ilgili temel sorun, her adımda degradeleri hesaplamak için tüm eğitim setini kullanmasıdır, bu da eğitim seti büyük olduğunda çok yavaş olmasını sağlar. Stochastic Gradient Descent her adımda belirlenen eğitimde rastgele bir örnek seçer ve degradeleri yalnızca bu tek örneğe göre hesaplar. Algoritmayı çok daha hızlı hale getirir. Öte yandan, stokastik doğası nedeniyle, bu algoritma Batch Gradient Descent’ten çok daha az düzenlidir: minimum seviyeye ulaşıncaya kadar hafifçe azaltmak yerine, maliyet fonksiyonu yukarı ve aşağı sıçrar ve sadece ortalama olarak azalır. Zamanla minimum seviyeye çok yakın olacak, ancak oraya vardığında geri dönmeyecek, asla yerleşmeyecek. Dolayısıyla algoritma durduğunda, son parametre değerleri iyidir, ancak optimal değildir. Cost function çok düzensiz olduğunda, bu aslında algoritmanın local minimum dışına atlamasına yardımcı olabilir, bu nedenle Stochastic Gradient Descent, Batch Gradient Descent’ten daha fazla global minimum bulma şansına sahiptir. Bu nedenle, rasgelelik local optima’dan kaçmak için iyidir, diğer yandan kötüdür, çünkü algoritmanın asla minimumda yerleşemeyeceği anlamına gelir. Bu ikilemin bir çözümü learning rate(α) kademeli olarak azaltmaktır. Adımlar büyük başlar (hızlı ilerleme kaydetmeye ve yerel minimadan kaçmaya yardımcı olur), daha sonra gittikçe küçülür ve algoritmanın küresel minimumda yerleşmesine izin verir. Her yinelemede öğrenme hızını belirleyen işlev öğrenme çizelgesi olarak adlandırılır. Öğrenme oranı çok yavaş bir şekilde azalırsa, minimuma çok uzun bir süre sonra varabilir ve eğitimi çok erken durdurursanız, en uygun olmayan bir çözüm elde edebilirsiniz. Öğrenme oranı çok hızlı bir şekilde azalırsa, yerel bir minimumda takılabilir veya hatta en sonunda yarıya kadar donmuş olabilirsiniz. Öğrenme oranı çok yavaş bir şekilde azalırsa, minimum süre boyunca uzun süre atlayabilir ve eğitimi çok erken durdurursanız, en uygun olmayan bir çözüm elde edebilirsiniz. Stochastic Gradient Descent kullanıldığında, parametrelerin ortalama olarak global minimum değere doğru çekilmesini sağlamak için training set bağımsız ve aynı şekilde dağıtılmalıdır. Bunu sağlamanın basit bir yolu, eğitim sırasında örnekleri karıştırmaktır. Bunu yapmazsanız, örneğin örnekler etikete göre sıralanırsa, SGD bir etiket için, ardından bir sonraki öğe için optimizasyon yaparak başlayacaktır ve global minimum değere yakın yerleşmeyecektir. Mini-Batch Gradient DescentHer adımda, gradientleri tüm training sete (Batch GD’de olduğu gibi) veya yalnızca bir örneğe (Stochastic GD’de olduğu gibi) dayalı olarak hesaplamak yerine, Mini-Batch GD, gradientleri mini-batches adı verilen küçük rasgele örnek kümelerinde hesaplar. Mini-Batch GD’nin Stochastic GD’ye göre ana avantajı, özellikle GPU’ları kullanırken matris işlemlerinin donanım optimizasyonundan bir performans artışı elde edebilmenizdir. Algoritmanın parametre alanındaki ilerlemesi, özellikle oldukça büyük Mini-Batch’lerde SGD’den daha az düzensizdir. Sonuç olarak, Mini-Batch GD, SGD’den minimum seviyeye biraz daha yakın yürüyecektir. Ancak, diğer taraftan, yerel minimadan kaçmak daha zor olabilir. Hepsi minimum seviyeye yakın, ancak Batch GD’nin yolu aslında minimumda dururken, hem Stochastic GD hem de Mini-Batch GD dolaşmaya devam ediyor. Ancak, Batch GD’nin her adımı atması çok zaman aldığını ve iyi bir öğrenme programı kullandıysanız Stochastic GD ve Mini-Batch GD’nin de minimum seviyeye ulaşacağını unutmayın.","link":"/CostFunction-GradientDescent/"},{"title":"Linear and Polynomial Regression","text":"İki tür gözetimli(supervised) makine öğrenme algoritması vardır: Regresyon ve sınıflandırma.Örneğin, bir evin fiyatını dolar olarak tahmin etmek bir regression problemidir, bir tümörün kötü veya iyi huylu olup olmadığını tahmin etmek bir sınıflandırma problemidir. Bu yazıda , Python için en popüler makine öğrenimi kütüphanelerinden biri olan Scikit-Learn kullanarak doğrusal regresyonun ne olduğunu ve hem iki değişken hem de çoklu değişken için nasıl uygulanabileceğini kısaca inceleyeceğiz. Cebirde “doğrusallık” terimi, iki veya daha fazla değişken arasındaki doğrusal bir ilişkiyi ifade eder. Bu ilişkiyi iki boyutlu bir alanda (iki değişken arasında) çizersek, düz bir çizgi elde ederiz. Doğrusal regresyon, verilen bağımsız değişkeni (x) temel alarak bağımlı bir değişken değerini (y) tahmin etme görevini yerine getirir. Dolayısıyla, bu regresyon tekniği x (girdi) ve y (çıktı) arasında doğrusal bir ilişki bulur. Bu nedenle, adı Linear Regression(Doğrusal Regresyon) dur. Bağımsız değişkeni (x) x eksenine ve bağımlı değişkeni (y) y eksenine çizersek, doğrusal regresyon bize aşağıdaki şekilde gösterildiği gibi veri noktalarına en iyi uyan düz bir çizgi verir. Yukarıdaki çizginin denklemi: Y = mx + b Burada b kesişme noktası ve m doğrunun eğimidir. Temel olarak, lineer regresyon algoritması bize kesişme ve eğim için en uygun değeri verir (iki boyutta). Veri özellikleri oldukları ve değiştirilemedikleri için y ve x değişkenleri aynı kalır. Kontrol edebileceğimiz değerler kesişme noktası (b) ve eğimdir (m). Kesişim ve eğim değerlerine bağlı olarak birden fazla düz çizgi olabilir. Tek değişkeni olan bir regresyon modeli şu şekilde temsil edilebilir: y = b0 + m1b1 hQ(x) =θ0 + θ1X Multiple Linear RegressionTemel olarak doğrusal regresyon algoritmasının yaptığı şey, veri noktalarına birden çok satır sığdırması ve en az hatayla sonuçlanan çizgiyi döndürmesidir. Aynı kavram ikiden fazla değişkenin bulunduğu vakalara da genişletilebilir. Buna multiple linear regression(çoklu doğrusal regresyon) denir. Örneğin, evin fiyatını alanı, yatak odası sayısı, bölgedeki insanların ortalama geliri, evin yaşı vb. Temelinde tahmin etmeniz gereken bir senaryo düşünün. Bu durumda, bağımlı değişken (hedef değişken) birkaç bağımsız değişkene bağlıdır. Birden çok değişkeni içeren bir regresyon modeli şu şekilde temsil edilebilir: y = b0 + m1b1 + m2b2 + m3b3 + … mnbn hQ(x) =θ0 +θ1X1 + θ2X2 + θ3X3 + …θnXn Bu, bir hiper düzlemin denklemidir. Unutmayın, iki boyutta doğrusal bir regresyon modeli düz bir çizgidir; üç boyutta olan bir düzlemdir ve üçten fazla boyutta olan bir hyperplane(hiperdüzlem)dir. Polynomal Linear RegressionKullanacağınız veri setine göre veriler lineer olarak dağılım göstermeyebilir ve doğrusal olmayan(non-linear) diye adlandırılan dağılımı gösterebilir. Lineer regresyon burada istediğimiz sonucu vermeyecektir.Non-linear olan dağılımda polinomal regresyon istediğimiz sonuca bizi yaklaştıracaktır.Polinomal regresyonda bağımsız değişken x ve bağımlı değişken y arasındaki ilişkinin n’inci derece polinom olarak modellendiği bir doğrusal regresyon biçimidir. Unutmayın burada x’ler lineer ilerlemiyor.Zaten lineer dememizin sebebi θ0,θ1,θ2,θ3… değerleridir. n’inci derece polinom denklemi y = a + b1x + b2x^2 +….+ bnx^n hQ(x) =θ0 +θ1X1 + θ2X2^2 + θ3X3^3 + …θnXn^n Gelin küçük bir örnekle lineer ve polinomal regresyon için kodlayalım. Amaç: Sıcaklık ve basınç değerleri verilen bir veri setinde istenilen sıcaklık değerinde basıncın ne olacağını tahmin edebilmektir. 12345678# Importing the libraries import numpy as np import matplotlib.pyplot as plt import pandas as pd # Importing the dataset datas = pd.read_csv('data.csv') datas .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sno Temperature Pressure 0 1 0 0.0002 1 2 20 0.0012 2 3 40 0.0060 3 4 60 0.0300 4 5 80 0.0900 5 6 100 0.2700 123# for x axis we select temperature, for y axis we select pressureX = datas.iloc[:, 1:2].values y = datas.iloc[:, 2].values 12345# Fitting Linear Regression to the dataset from sklearn.linear_model import LinearRegression lin = LinearRegression() lin.fit(X, y) 12LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) 123456789# Visualising the Linear Regression results plt.scatter(X, y, color = 'blue') plt.plot(X, lin.predict(X), color = 'red') plt.title('Linear Regression') plt.xlabel('Temperature') plt.ylabel('Pressure') plt.show() 123456789# Fitting Polynomial Regression to the dataset from sklearn.preprocessing import PolynomialFeatures poly = PolynomialFeatures(degree = 4) X_poly = poly.fit_transform(X) poly.fit(X_poly, y) lin2 = LinearRegression() lin2.fit(X_poly, y) 12LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) 123456789# Visualising the Polynomial Regression results plt.scatter(X, y, color = 'blue') plt.plot(X, lin2.predict(poly.fit_transform(X)), color = 'red') plt.title('Polynomial Regression') plt.xlabel('Temperature') plt.ylabel('Pressure') plt.show() Görselimizde görüldüğü üzere regresyon çizgimiz değerlerimize yakın bile değil peki yakın(fit) olmaması sorun teşkil eder mi? Tabi ki eder modelimize uyguladığımızda modelimiz doğru tahminde bulunmayacaktır. 12# Predicting a new result with Linear Regression print(lin.predict([[197]])) 1[0.41050733] 12# Predicting a new result with Polynomial Regression lin2.predict(poly.fit_transform([[197]])) 1array([7.18740604]) Yukarıda aynı x sıcaklık değeri için basınç tahminleri arasındaki farkı görebiliriz.Polinomal regresyon modelimiz lineer regresyon modelimize göre daha iyi tahminde bulundu diyebiliriz. Polinomal regresyonda avantajlar: Polinom, bağımlı ve bağımsız değişken arasındaki ilişkiye en iyi yaklaşımı sağlar. Polinomal regresyonda dezavantajlar: Bunlar aykırı değerlere karşı çok hassastır. Verilerdeki bir veya iki aykırı değerin varlığı, doğrusal olmayan bir analizin sonuçlarını ciddi şekilde etkileyebilir. Ek olarak, maalesef doğrusal olmayan regresyonda aykırı değerlerin tespiti için doğrusal regresyon için olanlardan daha az model doğrulama aracı vardır.","link":"/Regression/"},{"title":"GPT-3","text":"Generative Pre-trained Transformer 3 (Türkçe: Üretken Ön İşlemeli Dönüştürücü 3) kısaca GPT-3, insanların yazdığı metinlere benzer içerik üretmek için derin öğrenmeyi kullanan özbağlanımlı dil modelidir. GPT-n serisindeki üçüncü nesil dil tahmin modeli olan GPT-3, San Francisco merkezli yapay zeka araştırma laboratuvarı OpenAI tarafından geliştirilmiştir. GPT-3’ün tam sürümü, veri işleyecek 175 milyar parametreye sahiptir. Bu rakam GPT-2’nin öğrenme kapasitesinin 2 katıdır. 14 Mayıs 2020’de tanıtılan ve Temmuz 2020 itibarıyla beta aşamasında olan GPT-3, önceden öğretilmiş dil örnekleriyle doğal dil işleme (NLP) sistemini kullanmaktadır. GPT-3’ün piyasaya sürülmesinden önce, en büyük dil modeli Microsoft’un Şubat 2020’de tanıttığı ve GPT-3’ün %10’undan daha az kapasiteye sahip olan (17 milyar parametre) Turing NLG idi.Wikipedia sitesinde bu şekilde açıklanıyor. Youtube panelinde GPT-3 hakkında sorulan sorulara Google Brain’de Araştırmacı olan Lukasz Kaiser şu açıklamaları yaptı: Transformerlardan öncesini yani derin öğrenme kısmında NLP’de RNN’ler her şeyi doğru yapıyordu. Derin öğrenmenin ve NLP’nin ilk büyük dalgasıydılar. İşleri adım adım yineleyerek yapmanız gerektiğine dair süper temel fikirlere sahiptiler, bu da çok sezgisel ancak modern donanımda gerçekten yavaştır çünkü hızlandırıcılar paralel işlem için inşa edilmiştir. Dikkat fikri NLP’de çok eski bir bir yöntem olan hizalamadan (alignment) geliyor. Diyelim ki bir cümleyi çevirmeye çalışıyorsunuz elinizde ingilizce ve fransızca cümleler var hangi kelimelerin hangi kelimelere karşılık geldiğini hizalamaya çalışıyorsunuz. Dolayısıyla, bu hizalama fikrini bir sinir ağına koyarsanız, elde ettiğiniz şey dikkat mekanizmasıdır. Kelimeleri daha önce gelen kelimelerle hizalamanın farklılaştırılabilir yumuşak bir versiyonudur ve öz-ilgi, aynı metni, daha önce görünen kelimelerle aynı hizaya getirecek şekilde hizalamaktır. Bu fikir, aldığınız sonuçlar açısından iyi işliyor, ancak aynı zamanda modern derin öğrenme hızlandırıcılarında iyi bir şekilde uygularsanız şaşırtıcı derecede hızlı da çalışıyor. Sonuçları bir gün veya bir ay beklemeniz gerekmiyor bu da büyük bir fark yaratıyor. Ama diğer bir şey de hizalama(alignment), nlp’de uzun zamandır bilinen gerçekten iyi bir fikir.Paragrafın tamamını çevirmek istiyorsanız, bu bölümü çevirmeye odaklandığınızda ve her seferinde sadece bu bölüme baktığınızda çok daha kolay. Her insanın yaptığı da budur. Bunu bir sinir ağına öncelikli olarak veriyorsunuz ve bu gerçekten işe yarıyor, bu yüzden dikkatin geldiği yer burasıdır ancak şunu söylemek isterim, her şey dalgalar halinde ilerlerken, RNN’leri kullanmak çok iyi bir fikirdir. Çünkü seyrek transformatörlerle ilgili, bu ilginin insanların düşündüğünden daha çok RNN’ e benzediğini gösteren modern makaleler var ve aslında buna tekrar eden bir ağ(recurrent network) eklemek onu daha da iyi hale getiriyor. İnsanlar tekrar eden ağa geri dönerse, tekrar bir şekilde tekrarlayan ağlara bile dönüşmesi bu yüzden şaşırtıcı olmaz. En yeni teknikten daha fazlasını öğrenmek, daha önce gelen şeyleri bilmek ve bununla ilgili her şeyi öğrenmek iyidir.Herkesin internette NLP’de derin öğrenme yaptığını düşünebilirsiniz ama ben bunun tam tersini düşünüyorum. Elbette bugünlerde her şey çevrimiçi olarak gerçekleşiyor, çok fazla hareket varmış gibi geliyor çünkü nlp dünyası onlarca yıl öncesine göre çok daha büyük ama bu derin modellerin aslında dil yapabildiği şeylerin yüzeyini zar zor çizdiğimizi hissediyorum. Bu dil son derece derin bir alandır. Evet, size bir hikaye oluşturabiliriz ve okuruz, tamam mıdır? Gerçekten anlamı var mı? Bu doğru şeyler yaratır mı? Bunu bize bildiğini söyleyebilir mi? Doğrulayabilir miyiz? Önyargılar(bias) hakkında konuştuğumuzu bildiğini bize söyleyebilir mi? Aslında dil modelinin bu kadar saldırgan olup olmadığını sorabilirsiniz ve çoğu durumda size bunun olup olmadığını söyleyecektir. Ancak insan benzeri olmayan bazı hatalar yapacaktır. Nedenini anlayabilir miyiz?Sadece birkaç hafta önce piyasaya sürülen GPT-3, gradyan inişi olmadan öğrenebileceğini gösteren ilk model, bir şeyleri girdi olarak modele koyabilirsiniz ve sanki onları eğitiyormuş gibi çalışır, bu yüzden bu çok yeni ve test etmesi çok zor çünkü büyük modele ihtiyacınız var .Yarım yıl veya yıl içinde, bunu uygulamalı olarak yapmaya başlayabileceğiniz modeller olacak. Öğrenmeye başlamak için harika bir zaman. Çünkü dile giren bu şeylerin çoğunun başlangıcı. Teknolojiyi aldık ama aslında dilin derinliklerine inerken hala önümüzde çok düşündüğümüz bu uygulamaları getirecek.GPT-3 transformer modeli tüm web üzerinden eğitildi. Gelecekteki öğrenmeyi biraz beklenmedik olan yeni görevlere genelleştirir, ancak gerçekten tüm web üzerinde eğitilmiştir. Yani bir anlamda o kadar da beklenmedik değil ve arabalarda eğiteceğimiz daha küçük modelleri bile göreceksiniz, onlar da genelleştiriyorlar. Bu yüzden şimdi GPT-3 size harika cevaplar veriyor ama bu cevaplar ne işe yarıyor ve belki görevleriniz soruya uyuyor. Ancak görevinizi çözmeniz gerekir, genellikle görevinizi çözmek için modeli kullanmak ister ve onunla oynarsınız.Tamam işe yaramaz bir görevi çözmelisin deneyim kazanıp, öğrenmen gerekiyor ama daha sonra gerçek dünya görevinde bir araç kullanmalısın ve harika çeviri modellerimiz var. Google Translate sadece bu model değil tam da bunun gibi derin öğrenme modeli başlatamazsın. Biraz regex eklemelisiniz. Korkunç bir çıktı üretip üretmediğini görmek için basit bir regexin için bile, tüm eski tekniklere ön işleme(pre-processing) koymanız gerekir. Kullanıcılarınıza, müşterilerinize sonuç olarak neyi çıkardığınıza bakmanız ve bunu doğrulamanız gerekir. Bu modelin neden belirli durumlarda kötü çıktılar verdiğini ve modeli nasıl tamir edeceğinizi bilmiyorsanız düşünmeye başlamanız gerekir.Hala bilmediğimiz çok şey var, o zaman buna karşı biraz savunma yapmanız gerekiyor, belki sadece modelin gerçekten kötü olduğu ve GPT-3’ün kötü olduğu durumları tespit edin. GPT-3 diğer pek çok durumda iyidir, bu yüzden onu nasıl kullanacağınızı gerçekten öğrenmeniz gereken bir araç olduğunu öğrenmeniz gerekir. Verimli bir şekilde kullanabileceğiniz her yerde deneyim kazanın, sadece alıp uygulamak işe yarıyor mu? Hayır. Ne zaman çalıştığını, nasıl çalıştığını anlamak için çok iş var. Yıllar geçtikçe, bu şeylerin gerçekte nasıl çalıştığını daha iyi anlayacağımızı umuyoruz. Bunlar dilde biraz daha derine inmemize, ancak yine de uzun bir yol kat etmemize olanak tanıyan araçlar. Onu nerede nasıl kullanabileceğimizi öğrenmemiz gereken uzun bir yolumuz var ama bizim de ihtiyacımız olan başka şeyler olabilir ve kesinlikle bir GPT-4 olacaktır, bu yolun sonu değil, ama bu yolda büyük bir adım. Bir diğer panelist olan makine öğrenmesi ve yapay zeka alanında verdiği eğitimlerle birçok insanın hayatına dokunan Prof. Andrew NG GPT-3 ün çıkışı hakkında şunları söyledi: “İnanılmaz görünen her şey, çok çalıştığımızda ve bunları iyileştirdiğimizde, niş görünse bile doğru uygulamaları bulduğumuzda, bir gün okuduğumuz ve hayran kaldığımız bu modelin nerede olduğunu hayal edin. Kol saatinizde koşacak mıyım bilmiyorum ama teknoloji bu şekilde daha kullanılabilir hale geliyor. Şu anda NLP alanında çok sayıda zayıf sinyal görüyorum. Bunun patlayacağını ve daha yetenekli ve daha yaygın hale geleceğini düşündüğüm şeylerle yapabilirsiniz. Umarım bu araçları öğrenerek bu devrime katılabilirsiniz.” GPT-3 parlak bir obje mi? Doğru zamanda mı piyasa sürüldü? İşlerimizi elimizden alacak mı? Bu tür sorulardan ziyade kendimizi güncel tutmalı öğrenebileceğimiz herşeyi öğrenmeli, tüm yetkinlikleri kazanmalıyız. Bu yetkinlikleri bir sonraki ürünü geliştirmek için kullanmalıyız. Bu GPT4, GPT-5 yada adı her ne ise kendimizi geliştirip bu henüz yüzeyinde olduğumuz dünyanın derinlerine inmeliyiz. O dünyanın nasıl olacağını belirleyenler arasında olmalıyız.","link":"/GPT-3/"},{"title":"Feature Scaling","text":"Makine öğreniminde feature scaling (özellik ölçeklendirme), bir makine öğrenimi modeli oluşturmadan önce verilerin ön işlenmesi sırasında en kritik adımlardan biridir. Ölçeklendirme, zayıf bir makine öğrenimi modeli ile daha iyisi arasında bir fark yaratabilir. Makine öğrenimi, karışık meyve suyu yapmak gibidir. En iyi karıştırılmış suyu elde etmek istiyorsak, tüm meyveleri boyutlarına göre değil, doğru oranlarına göre karıştırmamız gerekir. Benzer şekilde, birçok makine öğrenimi algoritmasında, tüm özellikleri aynı duruma getirmek için, ölçeklendirme yapmamız gerekir, böylece tek bir önemli sayı oluşturduğumuz modeli büyüklükleri nedeniyle etkileyemez. Feature scaling işleminde en çok kullanılanlar Normalizasyon ve Standardizasyon teknikleridir.Normalizasyonda değerlerimizi iki sayı arasında, tipik olarak [0,1] veya [-1,1] arasında sınırlamak istediğimizde normalleştirme kullanılır.Standardizasyon, verileri sıfır ortalamaya ve 1 varyansına dönüştürürken, verilerimizi birimsiz hale getirir. Peki neden gereklidir? Makine öğrenimi algoritması sadece sayıyı görür. Eğer aralıkta çok büyük bir fark varsa, bir tarafta farkın binler olduğunu ve diğer tarafta farkın onlar arasında değiştiğini farzedelim. Daha yüksek aralıklı sayıların bir tür üstünlüğe sahip olduğu varsayımını yapar. Dolayısıyla bu daha önemli sayı, modeli eğitirken daha belirleyici bir rol oynamaya başlar. Makine öğrenimi algoritması sayılar üzerinde çalışır ve bu sayının neyi temsil ettiğini bilmez. 10 gramlık bir ağırlık ve 10 dolarlık bir fiyat tamamen iki farklı şeyi temsil ediyor ama makine öğrenmesi algoritması bunun farklı olduğunu anlamıyor ve model için her ikisine aynı muamelesi yapıyor. Dolayısıyla bu daha önemli sayı, modeli eğitirken daha belirleyici bir rol oynamaya başlar. Bu nedenle, herhangi bir ön önem olmaksızın her özelliği aynı temelde getirmek için Feature Scaling “özellik ölçeklendirmesi” gereklidir. İlginç bir şekilde, ağırlığı “Kg” ye çevirirsek, “Fiyat” baskın hale gelir.Özellik ölçeklemenin uygulanmasının bir başka nedeni de, sinir ağı gradyan descent gibi birkaç algoritmanın, özellik ölçeklendirmesi olunca global minimuma çok daha hızlı yakınlaşmasıdır. Verilerin arasındaki mesafeyi ölçen makine öğrenmesi algoritmaları için feature scaling çok önemlidir. Eğer ölçeklendirme yapılmazsa, yüksek değere sahip özellik mesafe ölçümünü domine edecektir.Birçok algoritmada, daha hızlı yakınsama istediğimizde ölçeklendirme, sinir ağında olduğu gibi bir zorunluluktur.Ham verilerin değer aralığı büyük ölçüde değiştiğinden, bazı makine öğrenimi algoritmalarında, nesnel işlevler normalleştirme olmadan doğru şekilde çalışmaz. Örneğin, sınıflandırıcıların çoğu iki nokta arasındaki mesafeyi mesafeye göre hesaplar. Özelliklerden biri geniş bir değer aralığına sahipse, mesafe bu belirli özelliği yönetir. Bu nedenle, tüm özelliklerin aralığı normalize edilmelidir, böylece her özellik son mesafeye yaklaşık orantılı olarak katkıda bulunur.Yukarıda belirtildiği gibi koşullar karşılanmadığında bile, ML algoritması bir ölçek beklerse veya bir saturation fenomeni meydana gelirse, tekrar özelliklerinizi yeniden ölçeklendirmeniz gerekebilir. Yine, doyurucu aktivasyon işlevlerine (örneğin sigmoid) sahip bir sinir ağı iyi bir örnektir.Özellik ölçeklendirmesinin önemli olduğu bazı algoritmalara bakalım. • K-nearest neighbors (KNN) Öklid mesafe ölçüsü ile büyük değerlere duyarlıdır ve bu nedenle tüm özelliklerin eşit olarak tartılması için ölçeklendirilmelidir. • K-Means burada Öklid mesafe ölçüsünü kullanır özellik ölçekleme önemlidir. • Principal Component Analysis(PCA) gerçekleştirilirken ölçeklendirme çok önemlidir. PCA, feature(özellikleri) maksimum varyansla elde etmeye çalışır ve varyans, yüksek büyüklükteki özellikler için yüksektir ve PCA’yı yüksek büyüklük özelliklerine doğru çarpıtır. • Gradient Descent’i ölçeklendirerek hızlandırabiliriz çünkü küçük aralıklarda hızlı ve büyük aralıklarda yavaşça iner ve değişkenler çok düzensiz olduğunda verimsiz bir şekilde optimum seviyeye iner. Normalleştirme / ölçeklendirme gerektirmeyen algoritmalar, kurallara bağlı olanlardır. Değişkenlerin herhangi bir monoton dönüşümünden etkilenmezler. Ölçeklendirme, tekdüze bir dönüşümdür. Bu kategorideki algoritmaların örnekleri, tüm tree-tabanlı algoritmalardır. Bunlar CART, Random Forests, Gradient Boosted Decision Trees. Bu algoritmalar kuralları kullanır(eşitsizlikler dizisi) ve normalleştirme gerektirmez.Linear Discriminant Analysis(LDA), Naive Bayes gibi algoritmalar bu durumu işlemek ve özelliklere göre ağırlık vermek için donatılmış tasarımlara sahiptirler.Bu algoritmalarda özellik ölçeklendirmesinin gerçekleştirilmesinin çok fazla etkisi olmayabilir. Dikkat edilmesi gereken birkaç önemli nokta: • Ortalama merkezleme kovaryans matrisini etkilemez. • Değişkenlerin ölçeklendirilmesi kovaryans matrisini etkiler. • Standardizasyon kovaryansı etkiler. Feature Scaling Yöntemleri Min-Max Scaler Standard Scaler Max Abs Scaler Robust Scaler Quantile Transformer Scaler Power Transformer Scaler Unit Vector Scaler Bu yöntemleri elimizdeki küçük veri seti ile açıklamaya başlayalım. 12345678import pandas as pdimport numpy as npimport matplotlib.pyplot as plt%matplotlib inlinedf = pd.DataFrame({'WEIGHT': [15, 18.5, 14,5,1], 'PRICE': [1,3,4,7,10]}, index = ['Pineapple','Apple','Strawberry','Watermelon',\"Fig\"])print(df) WEIGHT PRICE Pineapple 15.0 1 Apple 18.5 3 Strawberry 14.0 4 Watermelon 5.0 7 Fig 1.0 10 1)Min-Max scaler Min-max Scaler verilen aralığa göre özellikleri ölçekler. Bu tahmin aracı, her özelliği, eğitim setinde verilen aralıkta, örneğin sıfır ile bir arasında olacak şekilde tek tek ölçeklendirir ve çevirir. Bu ölçekleyici, negatif değerler varsa -1 ile 1 aralığında verileri küçültür. Aralığı [0,1] veya [0,5] veya [-1,1] gibi ayarlayabiliriz. Bu Ölçekleyici, standart sapma küçükse ve dağılım Gaussian değilse iyi sonuç verir. Min-max scaler, aykırı değerlere karşı hassastır. 12345678910111213from sklearn.preprocessing import MinMaxScalerscaler = MinMaxScaler()df1 = pd.DataFrame(scaler.fit_transform(df), index=['Pineapple','Apple','Strawberry','Watermelon','Fig'], columns= ['WEIGHT','PRICE'])ax = df.plot.scatter(x='WEIGHT', y='PRICE',color=['red','green','blue','yellow','purple'], marker = '*',s=100, label='BREFORE SCALING');df1.plot.scatter(x='WEIGHT', y='PRICE', color=['red','green','blue','yellow','purple'], marker = \"2\",s=100,label='AFTER SCALING', ax = ax,figsize=(12,6));plt.axhline(0, color='cyan',alpha=0.9)plt.axvline(0, color='cyan',alpha=0.9);plt.show() 2) Standard Scaler Standart Scaler, verilerin normal olarak her bir özelliğe dağıtıldığını varsayar ve bunları, 1’lik bir standart sapma ile dağıtım 0 civarında ortalanacak şekilde ölçeklendirir. Merkezleme ve ölçeklendirme, training setideki örnekler üzerindeki ilgili istatistikleri hesaplayarak her özellik için bağımsız olarak gerçekleşir. Veriler normal olarak dağıtılmıyorsa, bu kullanılacak en iyi ölçekleyici değildir. 1234567891011from sklearn.preprocessing import StandardScalerscaler = StandardScaler()df2 = pd.DataFrame(scaler.fit_transform(df), columns=['WEIGHT','PRICE'], index = ['Pineapple','Apple','Strawberry','Watermelon','Fig'])ax = df.plot.scatter(x='WEIGHT', y='PRICE',color=['red','green','blue','yellow','purple'], marker = '*',s=100, label='BREFORE SCALING');df2.plot.scatter(x='WEIGHT', y='PRICE', color=['red','green','blue','yellow','purple'], marker = \"d\",s=100,label='AFTER SCALING', ax = ax, figsize=(12,6));plt.axhline(0, color='cyan',alpha=0.9);plt.axvline(0, color='cyan',alpha=0.9); 3) Max Abs ScalerMax Abs Scaler her özelliği maksimum mutlak değerine göre ölçekler. Bu ölçekleyici, eğitim setindeki her bir özelliğin maksimum mutlak değeri 1.0 olacak şekilde her özelliği ayrı ayrı ölçeklendirir ve çevirir. Verileri kaydırmaz, ortalamaz ve dolayısıyla herhangi bir seyrekliği yok etmez. Yalnızca pozitif verilerde, bu ölçekleyici Min-Maks ölçekleyiciye benzer şekilde davranır ve bu nedenle önemli aykırı değerlerin varlığından da muzdariptir. 1234567891011from sklearn.preprocessing import MaxAbsScalerscaler = MaxAbsScaler()df4 = pd.DataFrame(scaler.fit_transform(df), columns=['WEIGHT','PRICE'], index = ['Pineapple','Apple','Strawberry','Watermelon','Fig'])ax = df.plot.scatter(x='WEIGHT', y='PRICE',color=['red','green','blue','yellow','purple'], marker = '*',s=100, label='BREFORE SCALING');df4.plot.scatter(x='WEIGHT', y='PRICE', color=['red','green','blue','yellow','purple'], marker = '3',s=100,label='AFTER SCALING', ax = ax, figsize=(12,6))plt.axhline(0, color='cyan',alpha=0.9)plt.axvline(0, color='cyan',alpha=0.9); 4) Robust ScalerBu ölçekleyici aykırı değerlere karşı sağlamdır. Verilerimiz çok sayıda aykırı değer içeriyorsa, verilerin ortalamasını ve standart sapmasını kullanarak ölçeklendirme iyi sonuç vermeyecektir. Bu ölçekleyici medyanı kaldırır ve verileri nicelik aralığına göre ölçeklendirir ( IQR: Çeyrekler Arası Aralık). IQR, 1. çeyrek (25.inci kuantil) ile 3. çeyrek (75.inci kuantil) arasındaki aralıktır. Bu ölçekleyicinin merkezleme ve ölçeklendirme istatistikleri yüzdelik dilimlere dayanmaktadır ve bu nedenle birkaç sayıdaki büyük marjinal aykırı değerlerden etkilenmez. Aykırı değerlerin kendilerinin dönüştürülmüş verilerde hala mevcut olduğuna unutmayın. Ayrı bir aykırı değer kırpılması isteniyorsa, doğrusal olmayan bir dönüşüm gereklidir. 1234567891011from sklearn.preprocessing import RobustScalerscaler = RobustScaler()df3 = pd.DataFrame(scaler.fit_transform(df), columns=['WEIGHT','PRICE'], index = ['Pineapple','Apple','Strawberry','Watermelon','Fig'])ax = df.plot.scatter(x='WEIGHT', y='PRICE',color=['red','green','blue','yellow','purple'], marker = '*',s=100, label='BREFORE SCALING');df3.plot.scatter(x='WEIGHT', y='PRICE', color=['red','green','blue','yellow','purple'], marker = 'v',s=100,label='AFTER SCALING', ax = ax,figsize=(12,6))plt.axhline(0, color='cyan',alpha=0.9)plt.axvline(0, color='cyan',alpha=0.9); Şimdi bir aykırı değer sunarsak ve Standart Scaler ve Robust Scaler kullanarak ölçeklendirmenin etkisini görürsek ne olacağını görelim (karo şekil aykırı değeri gösterir). 12345678910111213141516171819202122dfr = pd.DataFrame({'WEIGHT': [15, 18, 12,10,50], 'PRICE': [1,3,2,5,20]}, index = ['Apricot','Apple','Banana','Grape','Cherry'])print(dfr)from sklearn.preprocessing import StandardScalerscaler = StandardScaler()df21 = pd.DataFrame(scaler.fit_transform(dfr), columns=['WEIGHT','PRICE'], index = ['Apricot','Apple','Banana','Grape','Cherry'])ax = dfr.plot.scatter(x='WEIGHT', y='PRICE',color=['purple','green','blue','yellow','black'], marker = '*',s=80, label='BREFORE SCALING');df21.plot.scatter(x='WEIGHT', y='PRICE', color=['purple','green','blue','yellow','black'], marker = 'd',s=50,label='STANDARD', ax = ax,figsize=(12,6))from sklearn.preprocessing import RobustScalerscaler = RobustScaler()df31 = pd.DataFrame(scaler.fit_transform(dfr), columns=['WEIGHT','PRICE'], index = ['Apricot','Apple','Banana','Grape','Cherry'])df31.plot.scatter(x='WEIGHT', y='PRICE', color=['purple','green','blue','yellow','black'], marker = 'v',s=50,label='ROBUST', ax = ax,figsize=(12,6))plt.axhline(0, color='cyan',alpha=0.9)plt.axvline(0, color='cyan',alpha=0.9); WEIGHT PRICE Apricot 15 1 Apple 18 3 Banana 12 2 Grape 10 5 Cherry 50 20 5) Quantile Transformer ScalerNicelik bilgilerini kullanarak özellikleri dönüştürür. Bu yöntem, özellikleri tek tip veya normal bir dağılım izleyecek şekilde dönüştürür. Bu nedenle, belirli bir özellik için, bu dönüşüm en sık görülen değerleri yayma eğilimindedir. Aynı zamanda (marjinal) aykırı değerlerin etkisini de azaltır: bu nedenle bu, Robust bir preprocessing şemasıdır. Bir özelliğin kümülatif dağılım işlevi, orijinal değerleri yansıtmak için kullanılır. Bu dönüşümün doğrusal olmadığını ve aynı ölçekte ölçülen değişkenler arasındaki doğrusal korelasyonları bozabileceğini, ancak farklı ölçeklerde ölçülen değişkenleri daha doğrudan karşılaştırılabilir hale getirdiğini unutmayın. Bu aynı zamanda bazen Rank Scaler olarak da adlandırılır. 1234567891011from sklearn.preprocessing import QuantileTransformerscaler = QuantileTransformer()df6 = pd.DataFrame(scaler.fit_transform(df), columns=['WEIGHT','PRICE'], index = ['Pineapple','Apple','Strawberry','Watermelon','Fig'])ax = df.plot.scatter(x='WEIGHT', y='PRICE',color=['red','green','blue','yellow','purple'], marker = '*',s=100, label='BREFORE SCALING');df6.plot.scatter(x='WEIGHT', y='PRICE', color=['red','green','blue','yellow','purple'], marker = 'X',s=100,label='AFTER SCALING', ax = ax,figsize=(12,6))plt.axhline(0, color='cyan',alpha=0.9)plt.axvline(0, color='cyan',alpha=0.9); C:\\Users\\kader\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (5). n_quantiles is set to n_samples. % (self.n_quantiles, n_samples)) 6)Power Transformer ScalerParametrik, monoton dönüşümler ailesinden olan Power Transformatörü, verileri daha Gaussian benzeri hale getirmek için uygulanır. Bu yöntem, aralık boyunca eşit olmayan bir değişkenin değişkenliği (farklı varyans) veya normalliğin istendiği durumlar ile ilgili sorunları modellemek için yararlıdır. Power Transformatörü, maksimum olasılık tahmini yoluyla varyansı stabilize etmede ve çarpıklığı en aza indirmede optimum ölçeklendirme faktörünü bulur. Şu anda, PowerTransformer’ın Sklearn uygulaması Box-Cox transformu ve Yeo-Johnson transformu desteklemektedir. Varyansı sabitlemek ve çarpıklığı en aza indirmek için en uygun parametre maksimum olasılıkla tahmin edilir. Box-Cox, giriş verilerinin kesinlikle pozitif olmasını gerektirirken, Yeo-Johnson hem pozitif hem de negatif verileri destekler. 1234567891011from sklearn.preprocessing import PowerTransformerscaler = PowerTransformer(method='yeo-johnson')df5 = pd.DataFrame(scaler.fit_transform(df), columns=['WEIGHT','PRICE'], index = ['Pineapple','Apple','Strawberry','Watermelon','Fig'])ax = df.plot.scatter(x='WEIGHT', y='PRICE',color=['red','green','blue','yellow','purple'], marker = '*',s=100, label='BREFORE SCALING');df5.plot.scatter(x='WEIGHT', y='PRICE', color=['red','green','blue','yellow','purple'], marker = '&lt;',s=100,label='AFTER SCALING', ax = ax, figsize=(12,6))plt.axhline(0, color='cyan',alpha=0.9)plt.axvline(0, color='cyan',alpha=0.9); 7) Unit Vector ScalerÖlçeklendirme, bütün özellik vektörünün birim uzunluk olduğu düşünülerek yapılır. Bu genellikle her bileşeni vektörün Öklid uzunluğuna (L2 Normu) bölmek anlamına gelir. Bazı uygulamalarda (örn. histogram özellikleri), özellik vektörünün L1 normunu kullanmak daha pratik olabilir. L1 normu, oldukça açık nedenlerden dolayı L2 normundan daha sağlamdır: L2 normunun kareleri değerleri, dolayısıyla aykırı değerlerin maliyetini üssel olarak artırır; L1 normu yalnızca mutlak değeri alır, bu nedenle onları doğrusal olarak değerlendirir. Min-Maks ölçeklendirmede olduğu gibi, birim vektör tekniği [0,1] aralığında değerler üretir. Katı sınırları olan özelliklerle uğraşırken bu oldukça kullanışlıdır. Örneğin, görüntü verileriyle uğraşırken renkler yalnızca 0 ile 255 arasında değişebilir. 1234## Unit vector with L1 normdf8 =df.apply(lambda x:x/np.linalg.norm(x,1))df8 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } WEIGHT PRICE Pineapple 0.280374 0.04 Apple 0.345794 0.12 Strawberry 0.261682 0.16 Watermelon 0.093458 0.28 Fig 0.018692 0.40 1234## Unit vector with L2 normdf9 =df.apply(lambda x:x/np.linalg.norm(x,2))df9 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } WEIGHT PRICE Pineapple 0.533930 0.075593 Apple 0.658513 0.226779 Strawberry 0.498334 0.302372 Watermelon 0.177977 0.529150 Fig 0.035595 0.755929 Aşağıdaki diyagram, verilerin tüm farklı ölçekleme teknikleri için nasıl yayıldığını ve görebileceğimiz gibi, birkaç noktanın üst üste geldiğini, dolayısıyla ayrı ayrı görünmediğini göstermektedir. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162dfr = pd.DataFrame({'WEIGHT': [15, 18, 12,10,50], 'PRICE': [1,3,2,5,20]}, index = ['Apricot','Apple','Banana','Grape','Cherry'])print(dfr)from sklearn.preprocessing import MinMaxScalerscaler1 = MinMaxScaler()df11 = pd.DataFrame(scaler1.fit_transform(dfr), columns=['WEIGHT','PRICE'], index = ['Apricot','Apple','Banana','Grape','Cherry'])ax = dfr.plot.scatter(x='WEIGHT', y='PRICE',color=['purple','green','blue','yellow','red'], marker = '*',s=50, label='BREFORE SCALING');df11.plot.scatter(x='WEIGHT', y='PRICE', color=['purple','green','blue','yellow','red'], marker = '2',s=100,label='MİN-MAX SCALİNG', ax = ax,figsize=(12,6))from sklearn.preprocessing import StandardScalerscaler2 = StandardScaler()df21 = pd.DataFrame(scaler2.fit_transform(dfr), columns=['WEIGHT','PRICE'], index = ['Apricot','Apple','Banana','Grape','Cherry'])df21.plot.scatter(x='WEIGHT', y='PRICE', color=['purple','green','blue','yellow','red'], marker = 'd',s=50,label='STANDARD SCALİNG', ax = ax,figsize=(12,6))from sklearn.preprocessing import RobustScalerscaler3 = RobustScaler()df31 = pd.DataFrame(scaler3.fit_transform(dfr), columns=['WEIGHT','PRICE'], index = ['Apricot','Apple','Banana','Grape','Cherry'])df31.plot.scatter(x='WEIGHT', y='PRICE', color=['purple','green','blue','yellow','red'], marker = 'v',s=50,label='ROBUST SCALİNG', ax = ax,figsize=(12,6))from sklearn.preprocessing import MaxAbsScalerscaler4 = MaxAbsScaler()df41 = pd.DataFrame(scaler4.fit_transform(dfr), columns=['WEIGHT','PRICE'], index = ['Apricot','Apple','Banana','Grape','Cherry'])df41.plot.scatter(x='WEIGHT', y='PRICE', color=['purple','green','blue','yellow','red'], marker = '3',s=50,label='MAX ABS SCALİNG', ax = ax,figsize=(12,6))from sklearn.preprocessing import QuantileTransformerscaler5 = QuantileTransformer()df51 = pd.DataFrame(scaler5.fit_transform(df), columns=['WEIGHT','PRICE'], index = ['Apricot','Apple','Banana','Grape','Cherry'])df51.plot.scatter(x='WEIGHT', y='PRICE', color=['purple','green','blue','yellow','red'], marker = '&lt;',s=50,label='QUANTİLE TRANSFORM SCALİNG', ax = ax,figsize=(12,6))from sklearn.preprocessing import PowerTransformerscaler6 = PowerTransformer(method='yeo-johnson')df61 = pd.DataFrame(scaler6.fit_transform(df), columns=['WEIGHT','PRICE'], index = ['Apricot','Apple','Banana','Grape','Cherry'])df61.plot.scatter(x='WEIGHT', y='PRICE', color=['purple','green','blue','yellow','red'], marker = 'X',s=50,label='POWER TRANSFORM SCALİNG', ax = ax,figsize=(12,6))plt.axhline(0, color='cyan',alpha=0.9)plt.axvline(0, color='cyan',alpha=0.9); WEIGHT PRICE Apricot 15 1 Apple 18 3 Banana 12 2 Grape 10 5 Cherry 50 20 C:\\Users\\kader\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (5). n_quantiles is set to n_samples. % (self.n_quantiles, n_samples)) Feature Scaling, Makine öğrenimi pre-processing kısmında önemli bir adımdır. Derin öğrenme, daha hızlı yakınsama için feature scaling gerektirir ve bu nedenle hangi feature scaling yöntemini kullanılacağına karar vermek çok önemlidir. Çeşitli algoritmalar için ölçeklendirme yöntemlerinin birçok karşılaştırma araştırması vardır. Yine de, diğer makine öğrenimi adımlarının çoğu gibi, özellik ölçeklendirme de bir deneme yanılma sürecidir.","link":"/Featurescaling/"},{"title":"Classification","text":"Supervised Learning(denetimli öğrenme) ve Unsupervised Learning(denetimsiz öğrenme) olan en yaygın iki öğrenme türünden Supervised Learning’den Classification(Sınıflandırma) problemi konusuna bakalım. Ayrıntılara girmeden önce Regresyon Problemi ile Sınıflandırma Problemi arasındaki fark nedir? Cevabı etiket türüdür.Regresyonda sürekli sayı varken sınıflandırmada aykırı sayı vardır. Regresyon problemi için ev fiyatları(etiket) için m^2 ve fiyatlarının olduğu verisetinde değerler gerçek ve sürekli değerlerdir. Buna bir diger örnek olarak hava durumu tahminlemesi eklenebilir. Sınıflandırma problemindeki etiket ise “kategori” yi temsil etmektedir. İkili sınıf(binary class) problemi için meme kanseri teşhisini örnek alıyoruz. Meme kanseri teşhisinde en çok ilgilendiğimiz şey tümör tipi yani kötü huylu veya iyi huyludur. Kolaylık sağlamak için, basitçe kötü huylu(malignant) ve zararsız(benign) olarak sırasıyla 0 ve 1 olarak etiketledik. Ayrık sayının (0 ve 1) verilerin etiketi (tümör tipi) anlamına geldiğine dikkat edin. y∈ {0,1} 0: “Negative Class” (e.g. benign tumor) 1: “Positive Class” (e.g. malignant tumor) Sınıflandırmada örnekler: Email: Spam/ Not Spam? Online Transactions : Fraudulent (Yes/No)? Tümor : Malignant /Benign? Feature : Size(cm) Label : Tumor Type Logistic RegressionHypothesis FunctionEtiket türü Regresyon Probleminden farklı olduğundan, Sınıflandırma problemini çözmek için başka bir hipotez kullanmalıyız.Bu problemi çözmek için Lojistik Regresyonu kullanılır. **Lojistik Regresyon, gerçek sayıları olasılıklara eşleyen bir sigmoid işlevi olarak da adlandırılır, [0, 1] aralığındadır. Dolayısıyla, sigmoid fonksiyonunun değeri, verilerin bir kategoriye ne kadar kesin ait olduğu anlamına gelir. Y’nin etiketi temsil ettiğini, y = 1’in hedef etiketi ve y = 0’ın diğer etiket olduğunu unutmamalıyız. Sigmoid işlevinde her zaman hedef etiketiyle ilgileniyoruz. Çoğu durumda, olasılık eşiği olarak 0,5 alırız. Eğer h (x) ≥0.5 ise, verilerin etiket 1’e ait olduğunu, h (x) &lt;0.5 ise, verilerin etiket 0’a ait olduğunu tahmin ediyoruz. Aşağıdaki görselde Lineer ve Lojistik Regresyonun farkını daha iyi görebiliriz. Lojistik regresyondan çizgi “S” şeklini alıyor. Eğri hipotezin ( kötü huylu tümor(1) veya iyi huylu tümor(0)) doğru olma olasılığını söylüyor. Lineer Regresyonda, en uygun çizgiyi tahmin etmek için Ordinary Least Squares (OLS) yöntemini kullanıyoruz, benzer şekilde burada da lojistik eğrimizi seçmek için Maximum Likelihood tahminini kullanıyoruz. Lineer regresyonda kullandığımız hipotez formülü: hΘ(x) = β₀ + β₁X Lojistik regresyonda biraz değiştirmemiz gerekiyor. σ(Z) = σ(β₀ + β₁X) Z = β₀ + β₁X hΘ(x) = sigmoid(Z) hΘ(x) = 1/(1 + e^-(β₀ + β₁X) Decision BoundarySınıflandırıcımızın, girdileri bir tahmin fonksiyonundan geçirip 0 ile 1 arasında bir olasılık puanı döndürdüğümüzde olasılığa dayalı bir dizi çıktı veya sınıf vermesini bekliyoruz. Örneğin, 2 sınıfımız var, onları kedi ve köpek gibi alalım (1 - köpek, 0 - kedi). Temel olarak, değerleri Sınıf 1 olarak sınıflandırdığımız ve değerin eşiğin (threshold) altına düştüğü bir eşik değeri ile karar veririz ve ardından bunu Sınıf 2’de sınıflandırırız. Yukarıdaki grafikte gösterildiği gibi eşiği 0.5 olarak seçtik, eğer tahmin fonksiyonu 0.7 değerini döndürdüyse bu gözlemi Sınıf 1 (köpek) olarak sınıflandırdık. Tahminimiz 0,2 değerini döndürdüyse, gözlemi Sınıf 2 (kedi) olarak sınıflandırdık. hθ(x) = g(θ0 + θ1x1 + θ2x2) Örnek olarak;θ0 = -3θ1 = 1θ2 = 1 Yani parametre vektörümüz yukarıdaki değerlere sahip bir sütun vektörüdür. Yani,θT bir satır vektörü = [-3,1,1] Peki, ne anlama geliyor? Buradaki z, θT x olur. Eğer “y = 1” ise bunu tahmin ediyoruz. -3x0 + 1x1 + 1x2 &gt;= 0 -3 + x1 + x2 &gt;= 0 Bunu şu şekilde de yazabiliriz: Eğer (x1 + x2&gt; = 3) ise y = 1’i tahmin ediyoruz. Eğer bunu görselleştirirsek; x1 + x2 = 3 karar sınırımızı(decision boundary) grafik olarak çiziyoruz. Grafikte bu iki bölgeye sahip olduğumuz anlamına gelir. Mavi = Yanlış Pembe = Doğru Çizgi = Karar Sınırı Somut olarak, düz çizgi, tam olarak hθ (x) = 0,5 olan noktalar kümesidir. Karar sınırı, hipotezin bir özelliğidir. Herhangi bir veri olmadan hipotez ve parametrelerle sınır oluşturabileceğimiz anlamına gelir. Daha sonra verileri parametre değerlerini belirlemek için kullanırız. Eğer y=1 5 - x1 &gt; 0 5 &gt; x1 Non-Linear Decision Boundaries Doğrusal olmayan karmaşık bir veri kümesine lojistik regresyon uygulayalım. Polinom regresyonu gibi daha yüksek mertebeden terimler ekleyelim. Öyleyse sahip olduğumuz hipotezimiz şöyle olur; Θ vektörünün transpozu ile giriş vektörünü çarpıyoruz. ΘT [-1,0,0,1,1] “Y = 1” olan durumu tahmin edelim. Bu bize yarıçapı 1, 0 civarında olan bir daire verir. Bu (görece) basit hipoteze karmaşık parametreleri yerleştirerek daha karmaşık karar sınırları oluşturabileceğimiz anlamına gelir. Daha karmaşık karar sınırları? Daha yüksek dereceden polinom terimleri kullanarak daha da karmaşık karar sınırları elde edebiliriz. Cost Function (J(θ))Lineer Regresyonda cost fonksiyonu; Cost function optimizasyon hedefini temsil ediyor, yani bir maliyet fonksiyonu oluşturuyor ve minimum hatayla doğru bir model geliştirebilmemiz için bunu en aza indiriyoruz. Lojistik regresyon için cost fonksiyonu ; Sonucu bize konveks olmayan sonuç verecektir. Global minimuma ulaşmaya çalışan Gradiyen Descent için lokal optimada kalan bu sonuç büyük bir problem verecektir. −log(hθ(x)) eğer y = 1 −log(1−hθ(x)) eğer y = 0 Bu tek bir örneğin cost fonksiyonudur. İkili sınıflandırma problemleri için y her zaman 0 veya 1’dir Bu nedenle, maliyet fonksiyonunu yazmanın daha basit bir yolunu bulabiliriz.θ parametreleri için maliyet fonksiyonumuz şu şekilde tanımlanabilir: Diğer maliyet fonksiyonları varken neden bu fonksiyonu seçiyoruz? Bu cost fonksiyonu, maksimum olasılık tahmini(maximum likehood estimation) ilkesi kullanılarak istatistiklerden türetilebilir. Bunun, özelliklerin dağıtımıyla ilgili temel bir Gauss varsayımı olduğu anlamına geldiğini unutmayın. Dışbükey olması da güzel bir özelliğe sahiptir. Parametreleri sığdırmak için θ: J (θ) ‘yı en aza indiren θ parametreleri bulunur. Bu, modelimizde gelecekteki tahminler için kullanacağımız bir dizi parametremiz olduğu anlamına gelir. Ardından, x özellik kümesiyle yeni bir örnek verilirse, oluşturduğumuz θ’yı alabilir ve tahminimizi çıkarabiliriz. Lojistik regresyon’da cost fonksiyonu nasıl en aza indirilir? J (θ) ‘yi nasıl minimize edeceğimizi bulmalıyız.Gradient Descenti eskisi gibi kullanacağız.Bir öğrenme oranı (learning rate) kullanarak her parametre tekrar tekrar güncellenir. Eğer n feature olsaydı, θ vektörünüz için n + 1 sütun olurdu. Bu denklem, doğrusal regresyon kuralı ile aynıdır.Tek fark, hipotez tanımımızın değişmiş olmasıdır. Gradient descent lojistik regresyon için aynı şeyi burada yapabilir. Gradyan inişli lojistik regresyon uygularken, tüm θ değerlerini (θ0’dan θn’ye) aynı anda güncellemeliyiz Bir for döngüsü kullanabilir. Vektörize bir uygulama daha iyi olur. Lojistik regresyon için gradyan inişi için özellik ölçeklendirme(feature scaling) burada da geçerlidir. Advanced Optimization Daha önce maliyet fonksiyonunu en aza indirmek için gradyan inişine bakmıştık. Lojistik regresyon için maliyet fonksiyonunu en aza indirmek için gelişmiş kavramlara bakalım. Büyük makine öğrenimi problemleri için iyidir (ör. Çok büyük feature seti) Gradyan inişi aslında ne yapıyor? Diyelim ki maliyet fonksiyonumuz J (θ) var ve bunu en aza indirmek istiyoruz. Girdi olarak θ alabilen ve aşağıdakileri hesaplayabilen bir kod yazmalıyız. J (θ) J’ye göre J (θ) ise kısmi türev (burada j = 0 ila j = n) Bu iki şeyi yapabilen kod verildiğinde; Gradyan inişi, aşağıdaki güncellemeyi tekrar tekrar yapar. Yani her j içindeki θ sırayla güncellenir. (θ) ve türevlerini hesaplamak için kod yazılır. Sonra bu değerleri gradyan inişine konur. Alternatif olarak, maliyet(cost) fonksiyonunu en aza indirmek için Conjugate gradient BFGS (Broyden-Fletcher - Goldfarb-Shanno) L-BFGS (Limited Memory - BFGS)gradyan inişi yerine kullanabilir. Bunlar, aynı girdiyi alan ve maliyet fonksiyonunu en aza indiren daha optimize edilmiş algoritmalardır.Bunlar çok karmaşık algoritmalardır. Avantajlar Manuel olarak alfa (öğrenme oranı) seçmeye gerek yok. Bir grup alfa değerini deneyen ve iyi bir tane seçen akıllı bir iç döngüye (line search algoritması) sahiptir. Genellikle gradyan inişinden daha hızlıdır. İyi bir öğrenme oranı seçmekten fazlasını yapar. Karmaşıklıklarını anlamadan başarıyla kullanılabilir. Dezavantajlar Hata ayıklamayı daha zor hale getirebilir. Kendileri uygulanmamalıdır. Farklı kitaplıklar farklı uygulamalar kullanabilir. Performansı etkileyebilir. Multiclass classification problemsLojistik regresyonda birden fazla sınıf olduğunda one vs. all tekniği kullanılır. Multiclass - evet veya hayır(1 veya 0)’dan fazlasıdır. Üç sınıflı bir veri kümesi verildiğinde, bir öğrenme algoritmasının çalışmasını nasıl sağlayabiliriz? Tüm sınıflandırmaya karşı birini kullanıp, ikili sınıflandırmayı çok sınıflı sınıflandırma için çalışır hale getiririz. One vs. all classification Eğitim setini üç ayrı ikili sınıflandırma problemine bölebiliriz. Yeni sahte bir trainning set oluşturup Üçgenler(1) vs çarpılar ve kareler(o) hθ1(x) P(y=1 | x1; θ) Kareler(1) vs üçgen ve çarpılar (o) hθ2(x) P(y=1 | x2; θ) Çarpılar (1) vs üçgen and kareler (o) hθ3(x) P(y=1 | x3; θ) y = i olasılığını tahmin etmek için her i sınıfı için bir lojistik regresyon sınıflandırıcı hθ (i) (x) eğitilir. Yeni bir girdide, x tahmin yapmak için, hθ (i) (x) = 1 olasılığını en üst düzeye çıkaran i sınıfı seçilir.","link":"/Classification/"},{"title":"Artificial Neural Networks","text":"Yapay Sinir Ağları, günümüzün en popüler makine öğrenimi algoritmalarıdır. Bu sinir ağlarının icadı 1970’lerde gerçekleşti, ancak şu anda neredeyse her yerde bulundukları için hesaplama gücündeki son artış nedeniyle büyük popülerlik elde ettiler. Kullandığınız her uygulamada, sinir ağları güçlü bir arayüzle bağlanmanızı sağlar. İlk nörobilgisayarın mucidi Dr. Robert Hecht-Nielsen bir sinir ağını şu şekilde tanımlar: “… bilgileri harici girdilere dinamik durum tepkileri ile işleyen, basit, birbiriyle son derece bağlantılı işleme öğelerinden oluşan bir bilgi işlem sistemi.” Basic Structure of Artificial Neural Networks (ANNs)ANN fikri, insan beyninin doğru bağlantıları yaparak çalışmasının, canlı nöron ve dendrit olarak silikon ve teller kullanılarak taklit edilebileceği inancına dayanmaktadır. İnsan beyni, nöron adı verilen 86 milyar sinir hücresinden oluşur. Aksonlar tarafından diğer bin hücreye bağlanırlar. Dış çevreden gelen uyarılar veya duyu organlarından gelen girdiler dendritler tarafından kabul edilir. Bu girdiler, sinir ağında hızla dolaşan elektrik uyarıları yaratır. Bir nöron daha sonra mesajı başka bir nörona gönderebilir veya iletiyi iletmez.ANN’ler, insan beyninin biyolojik nöronlarını taklit eden çoklu düğümlerden oluşur. Nöronlar bağlantılarla bağlıdır ve birbirleriyle etkileşime girerler. Düğümler giriş verilerini alabilir ve veriler üzerinde basit işlemler gerçekleştirebilir. Bu işlemlerin sonucu diğer nöronlara aktarılır. Her düğümdeki çıktıya aktivasyon veya düğüm değeri denir. Her bağlantı ağırlık ile ilişkilidir. ANN’ler, ağırlık değerlerini değiştirerek gerçekleşen öğrenme yeteneğine sahiptir. Aşağıdaki şekilde basit bir ANN gösterilmektedir. Yapay Sinir Ağları, insan beyninden sonra modellenen özel bir makine öğrenme algoritması türüdür. Yani tıpkı sinir sistemimizdeki nöronların geçmiş verilerden nasıl öğrenebildikleri gibi ANNs de verilerden öğrenip tahminler veya sınıflandırmalar şeklinde yanıtlar verebilir. Görüntü tanıma, konuşma tanıma, makine çevirisi ve tıbbi teşhis gibi çeşitli görevler bu yapay sinir ağlarını kullanır. ANNs’lerin önemli bir avantajı, örnek veri setlerinden öğrenmesidir. ANNs’lerin en yaygın kullanımı, rastgele fonksiyon yaklaşımıdır. Bu tür araçlarla, dağıtımı tanımlayan çözümlere ulaşmak için uygun maliyetli bir yöntem elde edilebilir. ANNs ayrıca çıktı sonucunu sağlamak için tüm veri kümesinden ziyade örnek verileri alabilir. ANNS ile, gelişmiş tahmin yetenekleri sayesinde mevcut veri analizi teknikleri geliştirilebilir. Yapay Sinir Ağlarının işleyişi, sinir sistemimizde nöronların çalışma şekline benzer. Sinir Ağları, Warren S McCulloch ve Walter Pitts’in bu terimi icat ettiği 1970’lerin başlarına kadar uzanıyor. ANN’lerın işleyişini anlamak için önce nasıl yapılandırıldığını anlayalım. Bir sinir ağında üç temel katman vardır. Input LayersGiriş katmanı(input layer), giriş bilgilerini çeşitli metinler, sayılar, ses dosyaları, görüntü pikselleri vb. biçiminde alan bir ANN’nın ilk katmanıdır. Hidden LayersANN modelinin ortasında gizli katmanlar(hidden layer) bulunur. Algılayıcı veya birden çok gizli katman durumunda olduğu gibi tek bir gizli katman olabilir. Bu gizli katmanlar, giriş verileri üzerinde çeşitli matematiksel hesaplamalar gerçekleştirir ve parçası olan kalıpları tanır. Output LayerÇıktı katmanında(output layer), orta katman tarafından yapılan titiz hesaplamalarla elde ettiğimiz sonucu elde ederiz. Bir sinir ağında, modelin performansını etkileyen çok sayıda parametre ve hiperparametre vardır. ANNs çıktıları çoğunlukla bu parametrelere bağlıdır. Bu parametrelerden bazıları weight, bias, learning rate, batch size vb .’dir. ANNS’deki her düğümün bir ağırlığı(weight) vardır. Ağdaki her düğümün kendisine atanmış bazı ağırlıkları vardır. Girişlerin ve sapmanın ağırlıklı toplamını hesaplamak için bir transfer fonksiyonu kullanılır. Transfer fonksiyonu toplamı hesapladıktan sonra, aktivasyon fonksiyonu sonucu alır. Alınan çıktıya bağlı olarak, etkinleştirme işlevleri düğümden uygun sonucu ateşler. Örneğin, alınan çıktı 0.5’in üzerindeyse, aktivasyon işlevi 1’i ateşler, aksi takdirde 0 kalır. Yapay Sinir Ağlarında kullanılan popüler aktivasyon işlevlerinden bazıları Sigmoid, RELU, Softmax, tanh vb. Düğümün ateşlediği değere bağlı olarak, son çıktıyı elde ederiz. Ardından, hata işlevlerini kullanarak, tahmin edilen çıktı ile ortaya çıkan çıktı arasındaki tutarsızlıklarını hesaplıyoruz ve geri yayılım(back propagation) olarak bilinen bir işlemle sinir ağının ağırlıklarını ayarlıyoruz. ANNs, Derin Öğrenme olarak bilinen Makine Öğreniminde yeni ortaya çıkan bir alanın parçasıdır. Back Propagation in Artificial Neural NetworksBir sinir ağını eğitmek için, ona girdi-çıktı eşleme örnekleri veriyoruz. Son olarak, sinir ağı eğitimi tamamladığında, bu haritalamaları sağlamadığımız sinir ağını test ediyoruz. Sinir ağı çıktıyı tahmin eder ve çeşitli hata fonksiyonlarını kullanarak çıktının ne kadar doğru olduğunu değerlendiririz.Sonuca göre model zincir kuralı üzerinden gradyan inişini takiben ağı optimize etmek için sinir ağlarının ağırlıklarını ayarlar. Types of Artificial Neural Networksİki önemli Yapay Sinir Ağı türü vardır: FeedForward Neural Network FeedBack Neural Network FeedForward Neural Networksİleri beslemeli(FeedForward) ANN’lerde, bilgi akışı yalnızca bir yönde gerçekleşir. Yani, bilgi akışı girdi katmanından gizli katmana ve son olarak çıktıya doğrudur. Bu sinir ağında hiçbir geri bildirim döngüsü yoktur. Bu tür sinir ağları çoğunlukla sınıflandırma, görüntü tanıma vb. durumlar için denetimli öğrenmede(supervised learning) kullanılır. Bunları, verilerin doğası gereği sıralı olmadığı durumlarda kullanırız. FeedBack Neural NetworkGeri besleme(FeedBack) ANN’lerde, geribildirim döngüleri bunun bir parçasıdır. Bu tür sinir ağları, Yinelenen Sinir Ağları(Recurrent Neural Networks(RNN) durumunda olduğu gibi, esas olarak bellek tutma içindir. Bu tür ağlar, verilerin sıralı veya zamana bağlı olduğu alanlar için en uygun olanıdır. Machine Learning in ANNsANNs’ler öğrenme yeteneğine sahiptir ve eğitilmeleri gerekir. Birkaç öğrenme stratejisi var. Supervised Learning - ANNs’lerin kendisinden daha bilgili olan bir öğretmeni içerir. Örneğin, öğretmen, öğretmenin cevapları zaten bildiği bazı örnek veriler ile verileri besler. Örneğin, örüntü tanıma(pattern recognizing). ANN, tanıma yaparken tahminlerle gelir. Sonra öğretmen ANN’ye cevapları sağlar. Ağ daha sonra tahminlerini öğretmenin “doğru” yanıtlarıyla karşılaştırır ve hatalara göre ayarlamalar yapar. Unsupervised Learning Bilinen yanıtlarla örnek veri kümesi olmadığında gereklidir. Örneğin, gizli bir örüntü aramak için kullanılır. Bu durumda, kümeleme, yani bir dizi öğeyi bilinmeyen bir modele göre, mevcut veri kümelerine dayalı olarak gruplara ayırma gerçekleştirilir. Reinforcement Learning Bu strateji gözlem üzerine inşa edilmiştir. ANN, çevresini gözlemleyerek bir karar verir. Gözlem olumsuz ise ağ, bir dahaki sefere farklı bir gerekli kararı verebilmek için ağırlıklarını ayarlar. Back Propagation AlgorithmEğitim veya öğrenme algoritmasıdır. Verilen örneklerden öğrenir. Algoritmaya ağın ne yapmasını istediğinize dair bir örnek gönderirseniz, ağın ağırlıklarını değiştirir, böylece eğitimin bitiminde belirli bir girdi için istenen çıktıyı üretebilir. Back Propagation ağları basit Pattern Recognition ve Mapping Tasks için idealdir. Bayes NetworksBu tür sinir ağları, olasılığı hesaplamak için Bayesian Çıkarımını kullanan olasılıklı bir grafik modele sahiptir. Bu tür Bayes Ağları, Belief Ağları olarak da bilinir. Bu Bayes Ağlarında, bu tür rastgele değişkenler arasında bulunan olasılık bağımlılıkları temsil eden düğümleri birbirine bağlayan kenarlar vardır. Etkinin yönü öyledir ki, bir düğüm diğerini etkiliyorsa, o zaman aynı etki çizgisine düşerler. Her düğümle ilişkili olasılık, ilişkinin gücünü belirler. İlişkiye dayalı olarak, grafikteki rastgele değişkenlerden çeşitli faktörlerin yardımıyla çıkarım yapılabilir. Bu ağların uyması gereken tek kısıtlama, yönlendirilmiş yaylar üzerinden düğüme geri dönememesidir. Bu nedenle, Bayes Ağları Directed Acyclic Graphs (DAGs) olarak anılır. Bu Bayes Ağları, çok değerli değişkenleri idare edebilir ve iki boyuttan oluşur. Range of Prepositions Her preposition’nın atanmış olma olasılığı. Sonlu kümenin her değişkeni X = {x1, x2… xn} ile gösterilecek ve her X değişkeni, Değer {x1} olacak şekilde sonlu kümede bulunan değerlerden alacak şekilde sonlu bir rastgele değişkenler kümesi olduğunu varsayalım. Xi değişkeninden Xj değişkenine yönlendirilmiş bir bağlantı varsa, Xi, Xj’nin bu değişkenler arasındaki doğrudan bağımlılıkları gösteren ebeveyni olacaktır. Bayesian Networks’ün yardımıyla, önceki bilgilerle birlikte gözlemlenen veriler birleştirilebilir. Bayes Ağları temel olarak nedensel ilişkileri öğrenmek ve ayrıca alan bilgisini anlayıp gelecekteki olayı tahmin etmek için kullanılır. Bu, eksik veri durumunda bile gerçekleşir. Sinir Ağlarının Avantajları ve DezavantajlarıMakine Öğrenimi için Yapay Sinir Ağının birkaç avantajını ve dezavantajını görelim: Sinir ağları, doğrusal ve doğrusal olmayan verilerle iyi performans gösterir, ancak sinir ağlarının, özellikle robotikte yaygın bir eleştirisi, gerçek dünya operasyonları için çok çeşitli eğitim gerektirmeleridir. Bunun nedeni, herhangi bir öğrenen makinenin yeni vakalara genellemesine izin veren temel yapıyı yakalamak için yeterli temsili örneklere ihtiyaç duymasıdır. Sinir ağları, bir veya birkaç birim ağa yanıt vermede başarısız olsa bile çalışır, ancak büyük ve etkili yazılım sinir ağları uygulamak için, çok sayıda işleme ve depolama kaynağının işlenmesi gerekir. Beyin, bir nöron grafiği aracılığıyla sinyalleri işleme görevine göre uyarlanmış donanıma sahipken, Von Neumann teknolojisinde en basitleştirilmiş bir formu simüle etmek bile bir sinir ağı tasarımcısını bağlantıları için milyonlarca veritabanı satırını doldurmaya zorlayabilir - bu da çok miktarda tüketebilir bilgisayar belleği ve sabit disk alanı. Sinir ağı, analiz edilen verilerden öğrenir ve yeniden programlamaya ihtiyaç duymaz ancak bunlara kara kutu(black box) modelleri denir ve bu modellerin gerçekte ne yaptığına dair çok az fikir verir. Kullanıcının sadece girdiyi beslemesi ve eğitmesini izlemesi ve çıktıyı beklemesi gerekir.","link":"/ANN/"},{"title":"Debugging Learning Algorithm","text":"Makine öğrenimi modelimizi verilere uydurduktan sonra ne yapmalıyız? Açıkçası, onu değerlendirmemiz ve çalışıp çalışmadığını anlamamız ve özellikle son durumda, iyileştirmek için bazı değişiklikler yapmamız gerekiyor. Makine öğrenimi eğitimi sırasında daha iyi veri yakalama, gerçek zamanlı izleme ve zamanında müdahale ile zamandan ve maliyetlerden tasarruf etmemize yardımcı olacaktır. Evaluating Error of the ModelModelimizi oluşturmak için aşağıdaki görselde regülarizasyon yapılmış cost fonksiyon formülünü incelenirse: Doğrusal bir regresyon modelimiz olduğunu ve müşterimizin ürünlerinin satışını tahmin etmek istediğimizi varsayalım. Peki ya modelimiz çalışmazsa ya da biz de onun performansını iyileştirmek istiyorsak? Pekala, farklı yaklaşımlar deneyebiliriz, örneğin: Modele daha fazla eğitim verisi eklenebilir. → (Yüksek Varyans’ı düzeltir) Daha küçük bir feature seti kullanılabilir → ( Yüksek Bias’ı düzeltir) Ek feature örnekleri eklenebilir. → (Yüksek Bias’ı düzeltir) Polinom derecesi yükseltilebilir. → (Yüksek Bias’ı düzeltir.) Regularizasyon katsayısı(ƛ) arttırılabilir. → (Yüksek Varyans’ı düzeltir.) Regularizasyon katsayısı1 azaltılabilir. → (Yüksek Bias’ı düzeltir.) Elbette olasılıklardan biri, farklı parametrelerle rastgele farklı yaklaşımları denemek ve sonucu kontrol etmektir, ancak daha fazla veri elde etmek için büyük çaba gerektiren bazı değişiklikler yaparsak, özellikle zaman kaybı olabilir. Daha fazla veri elde ettikten sonra modelimizin performansının değişmediğini görürsek? Hangi yolu seçmenin daha iyi olduğunu anlamamıza yardımcı olabilecek bazı değerlendirme veya teşhis yöntemlerimiz var. Machine Learning DiagnosticÖnyargı(Bias): Bir işlevin öğrenilmesini kolaylaştırmak için bir model tarafından yapılan varsayımlar.Varyans(Variance): Verilerinizi eğitim verileri üzerinde eğitip ve çok düşük bir hata alırsanız, verileri değiştirdikten sonra aynı modeli değiştirdiğiniz verilerle eğittikten sonra yüksek hata ile karşılaşırsanız, bu varyanstır. Yüksek varyans: Bu sorun, algoritma eğitim verilerine mükemmel bir şekilde uyduğunda ortaya çıkacaktır. Başka bir deyişle, bu, modelin genelleme konusunda kötü olduğu anlamına gelir. Tahmin edilebileceği gibi, bu model görünmeyen veriler üzerinde kötü performans gösterecektir. Bu soruna aşırı uyum( overfitting) da denir. Genelleme hatası, modeliniz için önceden görülmemiş veriler üzerinde ölçülen hatadır. Yüksek sapma: Bu sorun, algoritma eğitim verilerini doğru şekilde uydurmadığında ortaya çıkar. Başka bir deyişle, bu, modelin girdi özellikleri ve tahmin edilen çıktı arasındaki ilgili ilişkileri kaçırdığı anlamına gelir. Tahmin edilebileceği gibi, bu model eğitim verilerinin kendisinde ve görünmeyen verilerde kötü performans gösterecektir. Bu soruna yetersiz uyum(high bias) da denir. Eğitim hatası, modelinizi eğitmek için kullanılan verilerde ölçülen model hatasıdır. UnderfittingBir istatistiksel modelin veya bir makine öğrenme algoritmasının, verilerin temelindeki eğilimi yakalayamadığında yetersiz olduğu söylenir. Yetersiz uyum(underfitting), makine öğrenimi modelimizin doğruluğunu yok eder. Oluşması, modelimizin veya algoritmanın verilere yeterince uymadığı anlamına gelir. Genellikle doğru bir model oluşturmak için daha az veriye sahip olduğumuzda ve ayrıca doğrusal olmayan verilerle doğrusal bir model oluşturmaya çalıştığımızda olur. Bu gibi durumlarda, makine öğrenimi modelinin kuralları bu kadar minimal verilere uygulanamayacak kadar kolay ve esnektir ve bu nedenle model muhtemelen çok sayıda yanlış tahmin yapacaktır. Daha fazla veri kullanılarak ve özellik seçimi ile özellikleri azaltarak yetersiz uyum önlenebilir. Yetersiz uyumu azaltma teknikleri: Model karmaşıklığını artırın Feature Engineering yaparak özelliklerin sayısını artırın Verilerden gürültüyü kaldırın. Daha iyi sonuçlar elde etmek için epoch sayısını artırın veya eğitim süresini artırın. OverfittingÇok fazla veriyle eğittiğimizde istatistiksel bir modelin gereğinden fazla uygun(overfitting) olduğu söylenir. Bir model bu kadar çok veriyle eğitildiğinde, veri setimizdeki gürültü ve hatalı veri girişlerinden öğrenmeye başlar. O zaman model, çok fazla ayrıntı ve gürültü nedeniyle verileri doğru bir şekilde kategorize etmez. Aşırı uyumluluğun nedenleri parametrik olmayan ve doğrusal olmayan yöntemlerdir çünkü bu tür makine öğrenme algoritmaları modeli veri setine dayalı olarak oluşturmada daha fazla özgürlüğe sahiptir ve bu nedenle gerçekten gerçekçi olmayan modeller oluşturabilirler. Aşırı uyumu önlemek için bir çözüm, doğrusal verilerimiz varsa doğrusal bir algoritma kullanmak veya karar ağaçları kullanıyorsak maksimum derinlik gibi parametreleri kullanmaktır. Aşırı uyumu azaltma teknikleri: Eğitim verilerini artırın. Model karmaşıklığını azaltın. Eğitim aşaması sırasında erken durma (eğitim başlar başlamaz eğitim süresi boyunca kaybı gözden geçirin eğer kayıp artmaya başlarsa eğitimi durdurun). Ridge Regülarizasyonu ve Lasso Regülarizasyonu uygulayın. Aşırı uyumluluğun üstesinden gelmek için sinir ağlarını kullanın. Just FitAslında modelin 0 hata ile tahmin yapması durumunda verilere iyi uyduğu söylenir. Bu durum, aşırı uydurma(overfitting) ile yetersiz uydurma(underfitting) arasındaki bir noktada elde edilebilir. Bunu anlamak için, eğitim veri setinden öğrenirken modelimizin performansına zamanın geçişiyle bakmamız gerekecek. Zaman geçtikçe modelimiz öğrenmeye devam edecek ve böylece modelin eğitim ve test verilerindeki hatası azalmaya devam edecektir. Çok uzun süre öğrenecek olursa, model gürültü ve daha az kullanışlı ayrıntıların varlığı nedeniyle fazla takılmaya daha yatkın hale gelecektir. Dolayısıyla modelimizin performansı düşecektir. İyi bir uyum elde etmek için, hatanın artmaya başladığı bir noktada duracağız. Bu noktada, modelin eğitim veri kümeleri ve henüz görülmemiş test veri kümemiz konusunda iyi becerilere sahip olduğu söylenebilir. Başlangıçta verileri iki bölüme ayırmak iyi fikirdir; birincisi modelin eğitimi için kullanılacak ve ikincisi test için kullanılacak. Bu çok kullanışlıdır, özellikle eğitim için modelin doğruluğunun çok yüksek olacağı, test bize modelin o kadar mükemmel olmadığını söyleyecektir. Yani temelde 70 / 30’u böldük: eğitim seti (genellikle% 70) test seti (genellikle% 30) Bu bölünme ile, bir hata değeri ile maliyet fonksiyonumuzu en aza indiren eğitim setine dayalı bir model oluşturabiliriz (bu daha iyi çalışacaktır çünkü model, test setinin verilerinden etkilenmeyecektir). Modelimizi oluşturduktan sonra, tahminler ve gerçek değerler arasındaki tutarsızlıklara dayanarak hatayı hesaplayan modelin tahminini kullanarak hatayı test seti ile değerlendireceğiz. Model Selection ProblemVerilere daha iyi uyması için doğru derece polinom nasıl seçilir (doğrusal, ikinci dereceden, kübik….)?D parametresine (bu, polinomun derecesi olacaktır) dayalı olarak farklı modelleri hesaplayabilir ve her biri için test setindeki değer hatasını ölçebilir, daha iyi performans gösteren modeli seçebiliriz (minimum hata). Bu durumda verilerimizi 3 kısma ayırabiliriz: Eğitim Seti (genellikle% 60) Çapraz Doğrulama Seti(Cross Validation ) - CV (genellikle% 20) Test Seti (genellikle% 20) Modeli eğitim setimiz ile uyumlu hale getiriyoruz. Ardışık olarak, çapraz doğrulama seti adı verilen ikinci bir veri setindeki gözlemlere yönelik tepkileri tahmin etmek için uyumlu model kullanılır.Çapraz Doğrulama seti(Cross Validation Set), modelin hiperparametrelerini ayarlarken eğitim veri setine uyan bir modelin tarafsız bir değerlendirmesini sağlar; bu durumda hiperparametreler, polinom dereceleridir.Hiperparametreler ayarlanınca, Test Seti nihai modelin bir değerlendirmesini sağlamak için kullanılır.Modelimizde değiştirilecek şeyleri seçmemize yardımcı olacak modelimiz için dikkate alınması gereken önemli bir husus, Bias ve Varyans’tır.Farklı polinom derecelerine sahip aynı verilere farklı modeller uydurmanın bir örneğini aşağıdaki görselde görebiliriz. Polinom 1. derecede, sonuç yetersiz uyuyor(underfitting) (Yüksek Bias), polinom 4. derece ile sonuç aşırı uyuyor(overfitting) (Yüksek Varyans) Learning Curves Bu grafikleri birkaç m değeri için (1’den tüm eğitim setine kadar) oluşturduğumuzda, bize modelimizin problemlerini açıkça gösteren Öğrenme Eğrileri(Learning Curves) elde ederiz. Modelimiz yüksek önyargıdan(bias) muzdaripse, JTR ve JVAL, m büyüdükçe çok yakın sonuçlanacak, ancak oldukça büyük bir hata değerine yakınsayacaklar. Bu davranış, yüksek önyargının bir göstergesidir çünkü JTR bile büyük eğitim veri kümeleri için büyüktür. Aslında, aynı zamanda düşük bir varyans durumu ortaya çıkarır. Çünkü tamamen farklı bir setle (validation) değerlendirirken bile hata çok fazla değişmez. Daha fazla veri almanın hatayı azaltmaya yardımcı olmayacağını unutmayın. Modelimiz yüksek varyanstan muzdaripse, JTR ve JVAL m büyüdükçe yaklaşacaktr. Bu, iki çizgi arasındaki boşluk nedeniyle , çünkü çizgilerin nihayetinde birleştiği görünen hata değerinin küçük olduğunu gösterir. Bu durumda, hata çizgileri sonunda daha büyük m değerleri için birleşeceğinden, daha fazla veri almak iyi bir seçenek gibi görünmektedir. Artık modelimizin probleminin (yüksek önyargı veya yüksek varyans) farkındayız, bundan sonra ne yapabiliriz? Sahip olduğunuz veriler için çok karmaşık olduğu için yüksek varyansa (overfits) sahipse: Model karmaşıklığına daha iyi uyması için daha fazla eğitim verisi alın Bazı özellikleri kaldırarak modeli basitleştirin Düzenlilik(Regülarizasyon) faktörünü artırarak modeli yumuşatın Model, sahip olduğunuz veriler için çok basit olduğu için yüksek önyargıya (underfits) sahipse: Daha karmaşık bir model oluşturmak için daha fazla özellik edinin (lojistik regresyon veya K-en yakın komşu gibi doğrusal olmayan modeller kullanılarak uygulanabilir.) Düzenleme(Regülarizasyon) faktörünü azaltarak modeli keskinleştirin Örneğin bir eğitim(trainning) setine tek bir gizli katmana(hidden layer) sahip bir sinir ağı fit ettiğimizi varsayalım. JVAL değerinin JTR değerinden yüksek çıktığını görürsek ne yapmalıyız? Bir gizli katman daha eklememiz problemimizi çözer mi? Hayır, çünkü modelimiz yüksek varyans problemi yaşıyor ve gizli katman sayısı arttırmak çözüm olmayacaktır. Regülarizasyon kat sayısını(ƛ) arttırmak problemi çözmeye yarar. Model Evaluation MetricsSadece makine öğreniminde değil, genel hayatta özellikle iş hayatında da “Ürününüz ne kadar doğru?” veya “Makineniz ne kadar hassas?” gibi sorular duyacaksınız. İnsanlar “Alanındaki en doğru ürün bu!” veya “Bu makine akla gelebilecek en yüksek hassasiyete sahip!”, her iki yanıtla kendilerini rahat hissediyorlar. Değil mi? Aslında, doğru ve kesin terimler çoğu zaman birbirinin yerine kullanılır. Metinde daha sonra kesin tanımlar vereceğiz, ancak kısaca şunu söyleyebiliriz: Accuracy, bazı ölçümlerin belirli bir değere yakınlığı için bir ölçü iken, precision, ölçümlerin birbirine yakınlığıdır. Bu terimler, Makine Öğreniminde de son derece önemlidir. Makine öğrenimi algoritmalarını değerlendirmek veya sonuçlarını daha iyi hale getirmek için onlara ihtiyacımız var. Dört önemli ölçüm vardır. Bu ölçümler, sınıflandırmaların sonuçlarını değerlendirmek için kullanılır. Ölçümler şunlardır: Accuracy Precision Recall F1-Score Bunlara geçmeden önce Type I ve Type II hatalarını bilmek gerekiyor. Type I hatası , Yanlış pozitif(False Positive) ile eşdeğerdir. Type II hatası, Yanlış negatife eşdeğerdir. Type I hatası, kabul edilmesi gereken hipotezin kabul edilmemesini ifade eder. Type II hata, reddedilmesi gereken hipotezin kabul edilmesidir. Bir Biyometri örneği alalım. Birisi parmaklarını biyometrik tarama için taradığında, Type I hatası, yetkili bir eşleşme olsa bile reddedilme olasılığıdır. Type II hatası, yanlış / yetkisiz bir eşleşmeyle bile kabul olasılığıdır. Senaryo / Problem 1: Kansere çare olan bir ilaç için tıbbi denemeler Type I hatası: Durum olmadığında bir tedavi bulunduğunu tahmin etme. Type II hatası: Aslında durum söz konusu olduğunda bir tedavinin bulunamayacağını tahmin etmek. Bu durumda Type I hatası bir sorun değildir. Daha sonra daha fazla denemeyle düzeltilebilir. Type II hatası daha ciddidir, çünkü hiçbir tedavisi yoktur ve bir tedavi milyonlarca hayatı kurtarabilir. Senaryo / Problem İfadesi 2: Bir köprünün yapım modeli doğrudur. Type I hatası: Modelin doğru olmadığında doğru olduğunu tahmin etme. Type II hatası: Bir modelin doğru olduğunda doğru olmadığını tahmin etme. Bu durumda Type I hatası büyük bir risktir. Hatalı olan ve köprünün çökmesine neden olabilecek köprünün inşası anlamına gelebilir. Daha fazla modelden geçip yine de doğru olanı bulabildiğimiz için Type II hatası daha az risklidir. 1. AccuracyDoğruluk(Accuracy), ölçümlerin belirli bir değere yakınlığı için bir ölçüdür. 2.PrecisionKesinlik(Precision) ise ölçümlerin birbirine yakınlığıdır, yani belirli bir değere değil. Başka bir deyişle: Aynı miktarda tekrarlanan ölçümlerden bir dizi veri noktasına sahipsek, ortalamaları ölçülen miktarın gerçek değerine yakınsa setin doğru olduğu söylenir. Öte yandan, değerler birbirine yakınsa kümeyi kesin olarak adlandırıyoruz. İki kavram birbirinden bağımsızdır; bu, veri setinin doğru veya kesin olabileceği veya her ikisinin birden olabileceği veya hiçbirinin olamayacağı anlamına gelir. Bunu aşağıdaki diyagramda gösteriyoruz: Confusion MatrixBir sınıflandırıcının performansını görselleştirmek için bir sürekli tablo veya hata matrisi olarak da adlandırılan bir confusion matrix kullanılır. Matrisin sütunları, tahmin edilen sınıfların örneklerini temsil eder ve satırlar gerçek sınıfın örneklerini temsil eder. (Not: Bunun tam tersi de olabilir.) İkili sınıflandırma durumunda, tabloda 2 satır ve 2 sütun vardır. Konsepti bir örnekle göstermek istiyoruz. Misal:Bu, sınıflandırıcının 42 durumda bir kediyi doğru şekilde tahmin ettiği ve 8 kedi örneğini köpek olarak yanlış tahmin ettiği anlamına gelir. Köpek olarak 32 örneği doğru bir şekilde tahmin etti. 18 vaka yanlışlıkla köpek yerine kedi olarak tahmin edilmiş. Doğruluk(Accuracy), bir sınıflandırıcı tarafından yapılan doğru tahminlerin (hem True Posistives (TP) hem de True Negatives (TN)) bölümünün, False Positives (FP) dahil sınıflandırıcı tarafından yapılan tüm tahminlerin toplamına bölünmesi olarak tanımlanan istatistiksel bir ölçüdür. Bu nedenle, ikili doğruluğu ölçmenin formülü şöyledir: TP = True positive; FP = False positive; TN = True negative; FN = False negative Şimdi kedi-köpek sınıflandırması sonuçlarının doğruluğunu hesaplayacağız. “True” ve “False” yerine burada “cat” ve “dog” görüyoruz. Accuracy şu şekilde hesaplayabiliriz: 12345678TP = 42TN = 32FP = 8FN = 18Accuracy = (TP + TN)/(TP + TN + FP + FN)print(Accuracy)0.74 Kesinlik(Precision), doğru olarak tanımlanan pozitif vakaların tahmin edilen tüm pozitif vakalara, yani pozitif olarak tahmin edilen doğru ve yanlış vakalara oranıdır. Precision, sorguyla ilgili alınan belgelerin oranıdır. Formül: 123456TP = 114FP = 14# FN (0) ve TN (12) bu formülde gerekmiyor!precision = TP / (TP + FP)print(f\"precision: {precision:4.2f}\")precision: 0.89 3. RecallDuyarlılık(recall), doğru olarak tanımlanan pozitif vakaların, “False Negatives” ve “True Positives” toplamı olan tüm True Positive vakalara oranıdır. 123456TP = 114FN = 0# FT (14) ve TN (12) bu formülde gerekmiyor!recall = TP / (TP + FN)print(f\"recall: {recall:4.2f}\")recall: 1.00 1 değeri, spam olmayan mesajların yanlışlıkla spam olarak etiketlenmediği anlamına gelir. İyi bir spam filtresi için bu değerin 1 olması önemlidir. 4. F1 ScoreF1 skoru, harmonik ortalamayı kullanarak precision ve recall birleştiren tek metriktir.Son metriğimiz F1 skoru formülü: 12345678910111213141516TP = 42TN = 32FP = 8FN = 18precision = TP / (TP + FP)accuracy = (TP + TN)/(TP + TN + FP + FN)recall = TP / (TP + FN)f1_score = 2 * precision * recall / (precision + recall)print(f\"accuracy: {accuracy:4.2f}\")print(f\"precision: {precision:4.2f}\")print(f\"recall: {recall:4.2f}\")print(f\"f1_score: {f1_score:4.2f}\")accuracy: 0.74precision: 0.84recall: 0.70f1_score: 0.76 Precision ve recall, son derece önemli iki model değerlendirme ölçütüdür. Precision, sonuçlarınıza uygun olanların yüzdesini ifade ederken, recall, algoritmanız tarafından doğru bir şekilde sınıflandırılan toplam alakalı sonuçların yüzdesini ifade eder. Ne yazık ki, her iki metriği aynı anda maksimize etmek mümkün değildir, çünkü biri diğerinin maliyetine sahiptir. Basit olması için, F-1 skoru adı verilen ve precision ve recall’un harmonik bir ortalaması olan başka bir metrik mevcuttur. Hem precision hem de recall’un önemli olduğu problemler için, bu F-1 puanını en üst düzeye çıkaran bir model seçilebilir. Diğer sorunlar için, bir değiş tokuşa ihtiyaç vardır ve precision’nın mı yoksa recall’un mu maksimize edileceğine karar verilmelidir. ROC CurveBir ROC curve (receiver operating characteristic curve), tüm sınıflandırma eşiklerinde bir sınıflandırma modelinin performansını gösteren bir grafiktir. Bu eğri iki parametreyi çizer: True Positive Rate False Positive Rate True Positive Rate (TPR), recall’ın eşanlamlısıdır ve bu nedenle aşağıdaki gibi tanımlanır: False Positive Rate (FPR) aşağıdaki şekilde tanımlanır: Bir ROC eğrisi, TPR’ye karşı FPR’yi farklı sınıflandırma eşiklerinde çizer. Sınıflandırma eşiğini düşürmek için daha fazla öğeyi pozitif olarak sınıflandırır, böylece hem False Positive’ler hem de True Positive’ler artar. Aşağıdaki şekil tipik bir ROC eğrisini göstermektedir. Bir ROC eğrisindeki noktaları hesaplamak için, bir lojistik regresyon modelini birçok kez farklı sınıflandırma eşikleri ile değerlendirebilirdik, ancak bu verimsiz olacaktır. Neyse ki, bu bilgiyi bize sağlayabilen AUC adında verimli, sıralama tabanlı bir algoritma var. AUCAUC(Area Under the ROC Curve), (0,0) ‘dan (1,1)’ e kadar tüm ROC eğrisinin altındaki iki boyutlu alanın tamamını ölçer (integral hesabı düşünün). AUC, tüm olası sınıflandırma eşiklerinde toplu bir performans ölçüsü sağlar. AUC’yi yorumlamanın bir yolu, modelin rastgele bir pozitif örneği rastgele bir negatif örnekten daha yüksek sıralama olasılığıdır. Örneğin, lojistik regresyon tahminlerinin artan sırasına göre soldan sağa düzenlenen aşağıdaki örnekler verildiğinde: AUC, rastgele bir pozitif (yeşil) örneğin rastgele bir negatif (kırmızı) örneğin sağına yerleştirilme olasılığını temsil eder.AUC, 0 ile 1 arasındadır. Tahminleri% 100 yanlış olan bir modelin AUC değeri 0,0; Tahminleri% 100 doğru olan birinin AUC’si 1,0’dır. AUC, aşağıdaki iki nedenden dolayı arzu edilir: AUC, ölçekle değişmez. Kesin değerlerinden ziyade tahminlerin ne kadar iyi sıralandığını ölçer. AUC, sınıflandırma eşiği ile değişmez. Hangi sınıflandırma eşiğinin seçildiğine bakılmaksızın modelin tahminlerinin kalitesini ölçer. Bununla birlikte, bu iki neden de bazı kullanım durumlarında AUC’nin yararlılığını sınırlayabilecek uyarılarla birlikte gelir: Ölçek değişmezliği her zaman arzu edilen bir şey değildir. Örneğin, bazen gerçekten iyi kalibre edilmiş olasılık çıktılarına ihtiyacımız olur ve AUC bize bundan bahsetmez. Sınıflandırma eşiği değişmezliği her zaman arzu edilen bir durum değildir. Yanlış negatiflere karşı yanlış pozitiflerin maliyetinde büyük farklılıklar olduğu durumlarda, bir tür sınıflandırma hatasını en aza indirmek kritik olabilir. Örneğin, e-posta spam tespiti yaparken, muhtemelen false positive’leri en aza indirmeye öncelik vermek istersiniz (bu, false negative’lerde önemli bir artışla sonuçlansa bile). AUC, bu tür optimizasyon için kullanışlı bir ölçüm değildir.","link":"/Algorithm/"},{"title":"Support Vector Machines (SVMs)","text":"Vladimir Vapnik Sovyet Birliği’nden Amerika’ya 1991’ de göç ediyor. Kimse çalışmaları hakkında birşey bilmiyordu. Aslında Ph.D yaparken Moskova’da SVM’leri 1960’lı yılların başında yazmıştı.Ama o zamanlar bilgisayar olmadığı için test edecek imkanı bulamamıştı.Sonraki 25 yıl Sovyet Birliği’nde Onkoloji Enstitüsünde çalıştı bir yandan da başvurular yapıyordu. Bell Labs’ta birileri onu keşfetti ve Amerika’ya davet etti. Sonrasında Amerika’ya taşınan Vapnik 3 makalesini NIPS (Neural Information Processing System) Journal’a gönderdi ve hepsi reddedildi.Hala buna üzgün ama bu onu motive etti. 1992-1993 yıllarında Bell Labs hand-written recognation ile ilgileniyordu. Vapnik neural networkün yetersiz olduğu SVM’lerin bu konuda daha iyi olduğuna dair çalışma arkadaşlarıyla iddiaya girdi. Çalışma arkadaşları bu konuda SVM kernelde n=2 olarak denediler ve sonuç lineer olmayan verileri sınıflandırmada harikaydı. Peki ik defa mı birileri kernel kullandı? Aslında Vapnik tezinde yazmıştı ama bunun önemli olduğunu düşünmemişti. Vapnik kernel fikrini yeniden canlandırdı ve geliştirmeye başladı. Vapnik’in kernelleri anlaması ve bunların önemini takdir etmesi arasında 30 yıl geçti ve işler böyle yürür. Harika fikirlerin ardından hiçbir şeyin olmadığı uzun dönemler gelir. Ardından orjinal fikrin biraz değişimiyle büyük bir güce sahip gibi göründüğü bir aydınlanma anı gelir. 90’ların başına kadar kimsenin adını bile duymadığı Vapnik, bugün makine öğrenmesiyle uğraşan herkesin tanıdığı bir üne kavuştu. Gelin Vapnik’in dünyaya kazandırdığı SVM ve Kernel kavramına yakından bakalım. Support Vector Machines(SVMs)SVM’ler, makine öğrenimi algoritmalarında sınıflandırma için en popüler algoritmadır. SVM’lerin matematiksel arkaplanı, iki sınıf arasındaki geometrik ayrım için temel bloğu oluşturmada mükemmeldir. Destek Vektör Makineleri(SVM), sınıflandırma ve regresyon analizi için verilerin analizini sağlayan bir tür denetimli makine öğrenme algoritmasıdır. Regresyon için kullanılabilirlerse de, SVM çoğunlukla sınıflandırma için kullanılır. N boyutlu uzayda çizim yapıyoruz. Her özelliğin değeri aynı zamanda belirli koordinatın değeridir. Ardından, iki sınıf arasında farklılaşan ideal hiper düzlemi buluyoruz. Bu destek vektörleri, bireysel gözlemlerin koordinat temsilleridir. İki sınıfı ayırmak için bir sınır yöntemidir. Destek vektör makinelerinin çalışmasının arkasındaki temel ilke basittir. Veri kümesini sınıflara ayıran bir hiper düzlem oluşturun. Örnek bir problemle başlayalım. Verilen bir veri kümesi için kırmızı üçgenleri mavi dairelerden sınıflandırmanız gerektiğini varsayalım. Amacınız, verileri iki sınıfa ayıran, kırmızı üçgenler ve mavi daireler arasında bir ayrım oluşturan bir çizgi oluşturmaktır. İki sınıfı birbirinden ayıran net bir çizgi varsayılabilirken, bu işi yapabilecek birçok satır olabilir. Bu nedenle, bu görevi yerine getirebilecek üzerinde anlaşabileceğiniz tek bir satır yoktur. İki sınıf arasında ayrım yapabilen bazı satırları aşağıdaki gibi görselleştirelim: SVM’ye göre, her iki sınıfa da en yakın olan noktaları bulmalıyız. Bu noktalar, destek vektörleri olarak bilinir. Bir sonraki adımda, ayıran düzlemimiz ile destek vektörleri arasındaki yakınlığı buluyoruz. Noktalar ve bölme çizgisi arasındaki mesafe, margin olarak bilinir. Bir SVM algoritmasının amacı, bu marjı maksimize etmektir.Margin maksimuma ulaştığında, hiper düzlem en uygun olanı olur. Pekala bu marjini adım adım hesaplamaya başlayalım. Görselde olduğu gibi (+) ve (-) leri ayırmamız gerekiyor böylece Decision Boundary çizmemizi sağlayacak eğrimizi bulabiliriz. Gutter denilen aslında görselde caddeye benzeyen şekle dik olan veya şeklin medyanına doğru giden uzunluğunu bilmediğimiz w vektörümüz olduğunu varsayalım. w vektörümüzden ayrılan ve caddenin hangi tarafında olduğunu bilmediğimiz u vektörümüz olduğunu düşünelim. Şimdi asıl ilgilendiğimiz şey bilinmeyenin sokağın sağ tarafında mı yoksa sol tarafında mı olduğu. Bu u vektörünü sokağa dik olan w vektörüne yansıtmak istiyoruz. Çünkü o zaman bu yöndeki mesafeye veya bu yönde bununla orantılı bir sayıya sahip olacağız. Ve ne kadar uzağa gidersek, sokağın sağ tarafına o kadar yaklaşırız. Vektörleri çarpıp b sabit sayısı ile topladıktan sonra değer 1’dan büyük ise seçtiğimiz (+) veya (-)sınıfında olduğunu belirleriz.Eğer eşitlik görseldeki gibi 0 ‘a eşit olursa xi noktamız gutter veya caddeye benzettiğimiz noktadadır. Lagrange Multipliersİki vektörün farkını alırsak ve w vektörüyle çarpıp w vektör büyüklüğüne bölersek cadde dediğimiz alanın uzunluğunu bulabiliriz.Bulduğumuz sonucu maksimum yapmak istiyoruz. Matematiksel optimizasyonda Lagrange Çarpanları(Lagrange Multipliers) yöntemini kullanacağız. Her iki tarafı 2 ile çarpıp w vektörüne göre diferansiyel alınca w vektörü eşitliğini elde ederiz. Bulduğumuz w vektör eşitliğini bir üstte yer alan Lagrange eşitliğinde yerine yazarız. Ardından yine her iki tarafı 2 ile çarpıp b’ ye göre diferansiyel alırız. Burda elde ettiğimiz sonuç işimize yarayacaktır. Bu sonucları lagrange denklemimizde yerine yazalım. İşte bulmak istediğimiz sonucu elde ettik.Peki yıldızlarla işaretlediğimiz yere bakalım.Tek yapmamız gereken bu iç çarpımları hesaplamaktı. Peki neden bu kadar zahmete girdik? Çünkü bu ifadenin bağımlılığını bulmak istedim. Bu maksimizasyonun bu vektörlere göre neye bağlı olduğunu bulmak istiyorum, x örnek vektörü ve keşfettiğim şey, optimizasyonun yalnızca örnek çiftlerinin iç çarpımına bağlı olduğudur. İki boyutlu ve 3 boyutlu olarak en uygun hiper düzlemi grafiklerde daha iyi görebiliriz: SVM modeli, iyi tanımlanmış bir karar sınırı oluşturarak iki sınıf arasındaki mesafeyi genişletmeye çalışır. Yukarıdaki durumda, hiper düzlemimiz verileri böldü. Verilerimiz 2 boyutlu iken, hiper düzlem 1 boyutluydu. Daha yüksek boyutlar için, örneğin n-boyutlu bir Öklid Uzayı için, alanı iki bağlantısız bileşene bölen n-1 boyutlu bir alt kümemiz var. Peki lineer olmayan durumlarda ne yapacağız?Aslında gerçek hayatta verisetleri genellikle tam ayrışmayan verilerden oluşuyor. Bu durumda SVM’lerin doğrusal olarak ayrılmaz verileri sınıflandırmak için kullandığı Soft Margin Formulation ve Kernel Trick kavramlarına bakalım. Aşağıdaki görselde olduğu gibi tam olarak ayrılmayan verileri grafikte inceleyelim. Şekilden, verileri mükemmel bir şekilde ayırabilecek belirli bir doğrusal karar sınırı olmadığı açıktır, yani veriler doğrusal olarak ayrılmazdır. Daha yüksek boyutlu temsillerde de benzer bir duruma sahip olabiliriz. Bu, genellikle verilerden elde ettiğimiz özelliklerin, iki sınıfı açıkça ayırabilmemiz için yeterli bilgi içermediği gerçeğine bağlanabilir. Çoğu gerçek dünya uygulamasında durum budur. Soft Margin FormulationBu fikir basit bir önermeye dayanmaktadır: SVM’nin belirli sayıda hata yapmasına izin verin ve marjı olabildiğince geniş tutun, böylece diğer noktalar hala doğru şekilde sınıflandırılabilir. Bu, SVM’nin amacını değiştirerek yapılabilir. Bu tür bir formülasyona sahip olmanın nedenini kısaca gözden geçirelim. Daha önce belirtildiği gibi, neredeyse tüm gerçek dünya uygulamaları doğrusal olarak ayrılmaz verilere sahiptir. Verilerin doğrusal olarak ayrılabildiği nadir durumlarda, aşırı uyumu önlemek için verileri mükemmel şekilde ayıran bir karar sınırı seçmek istemeyebiliriz. Örneğin, aşağıdaki diyagramı düşünün: Burada kırmızı karar sınırı, tüm eğitim noktalarını mükemmel bir şekilde ayırır. Ancak, bu kadar az marjla bir karar sınırına sahip olmak gerçekten iyi bir fikir mi? Bu tür bir karar sınırının görünmeyen veriler üzerinde iyi bir genelleme yapacağını düşünüyor musunuz? Cevabımız, tabi ki hayır. Yeşil karar sınırının, görünmeyen veriler üzerinde iyi bir şekilde genelleme yapmasına izin verecek daha geniş bir marjı vardır. Bu anlamda, Soft Margin Formulation, aşırı uyum sorununu önlemeye de yardımcı olacaktır. Burada C, marjı maksimize etmek ile hataları en aza indirmek arasındaki değiş tokuşa karar veren bir hiperparametredir. C küçük olduğunda, sınıflandırma hatalarına daha az önem verilir ve marjı maksimize etmeye daha çok odaklanırken, C büyük olduğunda, marjı küçük tutmak pahasına yanlış sınıflandırmadan kaçınmaya odaklanır. Ancak bu noktada, tüm hataların eşit olmadığını da belirtmeliyiz. Karar sınırından çok uzakta yanlış tarafında bulunan veri noktaları, daha yakın olanlara göre daha fazla ceza almalıdır. Aşağıdaki diyagramın yardımıyla bunun nasıl birleştirilebileceğini görelim. Buradaki fikir şudur: Her xi veri noktası için, bir gevşek değişken ξi sunuyoruz. Görselde olduğu gibi A,B ve C bölgelerinde ξ farklı değerler alır. C çok büyük olursa fonksiyon bütün ξ parametrelerini çok küçültmeye çalışacaktır. Daha dar bir marjin elde ederiz. Bu da , düşük bias ve yüksek varyansı meydana getirir (Overfitting). C çok küçük olursa daha gevşek, geniş bir marjin elde edilir ve ξ değeri büyük olur. Bu da yüksek bias ve düşük varyansı meyadan getirir (Underfitting). Kernels TrickŞimdi, doğrusal ayrılmazlık problemini çözmek için “Kernel Trick” i kullanmanın ikinci çözümünü inceleyelim. Ama önce Kernel fonksiyonlarının ne olduğunu öğrenmeliyiz. Kernel FunctionsKernel fonksiyonları, iki vektörü (herhangi bir boyuttan) girdi olarak alan ve girdi vektörlerinin ne kadar benzer olduğunu gösteren bir puan veren genelleştirilmiş işlevlerdir. Basit bir Kernel işlevi, nokta çarpım işlevidir: iç çarpım küçükse, vektörlerin farklı olduğu sonucuna varırız ve iç çarpım büyükse, vektörlerin daha benzer olduğu sonucuna varırız. The “Trick”Doğrusal olarak ayrılabilir durum için amaç fonksiyonuna bakalım: Fonksiyonda w ve b değerlerini yerine yazınca aşağıdaki fonksiyonu elde ederiz. Bir Kernel fonksiyonundan başka bir şey olmayan girdi vektör çiftlerinin (xi. xj) iç çarpımına bağlıdır. Şimdi burada iyi bir şey var: Nokta ürün gibi basit bir kernel işleviyle sınırlı kalmamıza gerek yok. Hesaplama maliyetlerini fazla artırmadan, daha yüksek boyutlarda benzerliği ölçme kabiliyetine sahip nokta ürün yerine herhangi bir süslü Kernel işlevini kullanabiliriz. Bu aslında Kernel Trick olarak bilinir. Burada x ve y giriş vektörleridir, ϕ bir dönüşüm fonksiyonudur ve &lt;,&gt; nokta çarpım işlemini belirtir. Nokta çarpım fonksiyonu durumunda, ϕ sadece giriş vektörünü kendisine eşler. 2d uzayda veri noktalarını mükemmel şekilde ayırabilecek doğrusal bir karar sınırı olmadığını görüyoruz. Dairesel (veya ikinci dereceden) bir karar sınırı işi yapabilir, ancak doğrusal sınıflandırıcılar bu tür karar sınırlarını bulamaz. Şekilde, her bir P noktası 2D uzayda (x, y) formunun özellikleriyle temsil edilmektedir. Arzu edilen karar sınırına baktığımızda, bir P noktası için ϕ dönüşüm fonksiyonunu ϕ (P) = (x ^ 2, y ^ 2, √2xy) olarak tanımlayabiliriz. İki nokta P_1 ve P_2 için bu tür dönüşüm için Kernel işlevinin neye benzediğini görelim. Kernel işlevinin son halini gözlemlersek, bu bir daireden başka bir şey değildir! Bu, benzerlik kavramımızı değiştirdiğimiz anlamına gelir: benzerliği noktaların ne kadar yakın olduğuna göre ölçmek yerine (iç çarpımı kullanarak), benzerliği noktaların bir daire içinde olup olmadığına göre ölçüyoruz. Bu anlamda, böyle bir dönüşümü tanımlamak, 2D uzayda doğrusal olmayan bir karar sınırına sahip olmamızı sağladı (orijinal 3D uzayda hala doğrusaldır). Daha iyi anlamak için aşağıdaki videoyu izleyelim. Kernel fonsiyonunu yeniden yazdığımızda aşağıdaki sonucu elde ederiz. Öyleyse Kernel fonksiyonunun değeri (dolayısıyla, 3D uzaydaki noktalar arasındaki benzerlik), 2D uzaydaki noktalar arasındaki nokta çarpımının sadece karesidir. Oldukça harika, değil mi ? Ama bu nasıl oldu? Bunun nedeni, dönüşüm fonksiyonumuzu akıllıca seçmiş olmamızdır. Ve bunu yapmaya devam ettiğimiz sürece, dönüştürme adımını atlayabilir ve Kernel işlevinin değerini doğrudan 2D uzaydaki noktalar arasındaki benzerlikten hesaplayabiliriz. Bu da aynı zamanda hesaplama maliyetlerini de azaltacaktır. Bu güzel özelliğe sahip ve kutudan çıktığı gibi kullanılabilen birçok popüler Kernel fonksiyonumuz var (mükemmeli aramamıza gerek yok ϕ). SVM Avantajları Garantili Optimallik: Konveks Optimizasyonun doğası gereği, çözüm her zaman local minimum değil global minimum olacaktır. SVM, doğrusal olarak ayrılabilir ve doğrusal olmayan şekilde ayrılabilir veriler için kullanılabilir. Doğrusal olarak ayrılabilir veriler kesin marjin, doğrusal olmayan şekilde ayrılabilir veriler soft marjin oluşturur. SVM’ler, yarı denetimli öğrenme modellerine uyum sağlar. Verilerin etiketlendiği ve etiketlenmediği alanlarda kullanılabilir. Yalnızca Transdüktif SVM olarak bilinen en aza indirme problemi için bir koşul gerektirir. Feature Mapping, eskiden modelin genel eğitim performansının hesaplama karmaşıklığına oldukça yük oluyordu. Bununla birlikte, Kernel Trick’in yardımıyla SVM, basit iç çarpım kullanarak feature mapping gerçekleştirebilir. SVM Dezavantajları SVM, metin yapılarını işleyemez. Bu, sıralı bilgi kaybına ve dolayısıyla daha kötü performansa yol açar. Vanilya SVM, lojistik regresyona benzer olasılıklı güven değerini döndüremez. Tahmin güveni birçok uygulamada önemli olduğundan, bu çok fazla açıklama sağlamaz. Çekirdek seçimi, destek vektör makinesinin belki de en büyük sınırlamasıdır. Bu kadar çok çekirdeğin mevcut olduğu düşünüldüğünde, veriler için doğru olanı seçmek zorlaşıyor.","link":"/SVM/"},{"title":"Naive Bayes Classifier","text":"yüzyılın başlarında İngiliz matematikçi ve Presbiteryen bakanı olan Thomas Bayes, Bayes analizi ifadesini hiçbir zaman kullanmadı. Hayatında sadece iki makale yayınladı, biri teolojik, diğeri Newton’un hesabını filozof George Berkeley’in eleştirilerine karşı savundu. Bayes, yaşamının son dönemlerinde olasılıkla ilgilenmeye başladı. 1761’de öldü ve ölümünden bir yıl sonra arkadaşı Richard Price, Bayes tarafından Bayes Teoremi olarak bilinen şeyi önerdiği bir makalenin halka açık bir okumasını ayarladı. Matematik ve istatistik alanlarının yanında makine öğrenmesinde Bayes Teorisinin kullanımına daha yakından bakalım. Bayes TheoremBayes Teoremi, başka bir B olayı meydana geldiğinde A olayının koşullu olasılığını verir. P(A|B) = B olayı gerçekleştiğinde A olayının gerçekleşme olasılığıP(A) = A olayının gerçekleşme olasılığıP(B|A) = A olayı gerçekleştiğinde B olayının gerçekleşme olasılığıP(B) = B olayının gerçekleşme olasılığı Bayes teoremini kullanarak, B’nin oluştuğu göz önüne alındığında, A’nın olma olasılığını bulabiliriz. Burada B kanıt ve A hipotezdir. Burada yapılan varsayım, tahmin edicilerin / özelliklerin bağımsız olduğudur. Yani belirli bir özelliğin varlığı diğerini etkilemez. Dolayısıyla naif(naive) denir. Yazı/tura örneğiyle Bayes Teoremini inceleyelim. Diyelim ki 2 madeni parayla yazı / tura yapacağız. Burada olasılıklara bakalım.{TT, TY, YT, YY} P(Her 2’sinin tura gelmesi) = 1/4 P(En az 1 yazı gelmesi) = 3/4 P(1.cisinin yazı 2.sinin tura gelmesi) = 1/2 P(1.cisinin tura 2.sinin tura gelmesi) = 1/2 Şimdi 1 ve 2 numaralı olasılıklara baktığımızda örnek uzayda direk ölçebiliyoruz. 3 ve 4 numaralı olasılıklar ise koşullu olasılıktır. P(1.cisinin yazı 2.sinin tura gelmesi) olasılığını hesaplayalım. A 2. sinin tura gelmesi olayı B 1. sinin yazı gelmesi olayı =P(A|B)=[P(B|A) * P(A)] / P(B)=[P(1.sinin yazı gelmesi 2. sinin tura gelmesi)* P(2. sinin tura gelmesi)] / P( 1. cisinin yazı gelmesi) =[(1/2) * (1/2)]*(1/2) = 1/2 = 0.5 Bayes’in teoremi, temel olarak bir olayın meydana gelmesinin koşullu olasılığını, olayla ilgili olabilecek koşulların önceden bilinmesine dayanarak hesaplar. Naive Bayes ClassifierNaive Bayes sınıflandırıcısı, gözetimli öğrenmede (supervised learning) sınıflandırma görevi için kullanılan olasılıklı bir makine öğrenme modelidir. Sınıflandırıcının noktası, Bayes teoremine dayanır. Naïve Bayes sınıflandırıcı, örüntü tanıma problemine ilk bakışta oldukça kısıtlayıcı görülen bir önerme ile kullanılabilen olasılıksal bir yaklaşımdır. Bu önerme, örüntü tanımada kullanılacak her bir tanımlayıcı öznitelik ya da parametrenin istatistik açıdan bağımsız olması gerekliliğidir. Her ne kadar bu önerme Naive Bayes sınıflandırıcının kullanım alanını kısıtlasa da, genelde istatistik bağımsızlık koşulu esnetilerek kullanıldığında da daha karmaşık yapay sinir ağları gibi metotlarla karşılaştırabilir sonuçlar vermektedir. Bir Naive Bayes sınıflandırıcı, her özniteliğin birbirinden koşulsal bağımsız olduğu ve öğrenilmek istenen kavramın tüm bu özniteliklere koşulsal bağlı olduğu bir Bayes ağı olarak da düşünülebilir. Shopping DemoNaive Bayes Sınıflandırıcı kullanarak bir kişinin belirli bir Day, Discount ve Free Delivery kombinasyonunda bir ürün satın alıp almayacağını hesaplamaya çalışalım. Görselde olduğu gibi 30 günlük küçük bir veri setimiz olsun. Day, Discount ve Free Delivery inputlarına göre Frequency Tabloları aşağıdaki görselde inceleyelim.Bayes teoremi için, “Buy” olayı A ve bağımsız değişkenler (Day, Discount ve Free Delivery) B olsun. Weekday, Weekend ve Holiday değişkenlerini içeren “Day” değişkeninin olasılığını hesaplayalım. 8 Weekday 9 Weekend 13 Holiday Yukarıdaki Likelihood tablosuna dayanarak, bazı koşullu olasılıkları hesaplayalım: P(B) = P(Weekday)= 8/30=0.26 P(A) = P(No Buy)= 10/30= 0.33 P(B | A) = P(Weekday | No Buy)= 3/10= 0.3 P(A | B)= P(No Buy | Weekday) = P(Weekday| No Buy) * P(No Buy) / P(Weekday)= (0.3*0.33)/0.26= 0.381 Hafta içi satın alma olasılığı = 8/30 veya 0,26Yani weekend, weekday ve holiday boyunca mağazaya gelen 30 kişiden 8’i hafta içi alışveriş yaptı. Satın almama olasılığı = 3/10 veya 0.3 Haftanın hangi günü olursa olsun, bir satın alma işlemi yapmama ihtimalleri yüzde 30. Son olarak, satın alma gerçekleşmediğinde B’nin (yani hafta içi günler) olasılığına bakarız. Hafta içi bir satın alma olmadan olasılığı = 0,38 veya yüzde 38. (No Buy | Weekday) olasılığı 0,5’ten az olduğundan, müşteri büyük olasılıkla ürünü hafta içi satın alacaktır. Ardından, Naive Bayes Sınıflandırıcısında tablo ve koşullu olasılıkların nasıl çalıştığını görelim. Üç bağımsız değişkenin frekans tablolarına sahibiz ve üç değişken için de tablolar oluşturabiliriz. Aşağıdaki üç değişken için olasılık tablolarına bakın: Likelihood tabloları, bir müşterinin bir ürünü indirimin olduğu günün belirli bir kombinasyonunda satın alıp almayacağını ve ücretsiz teslimat olup olmadığını hesaplamak için kullanılabilir. B’nin eşit olduğu aşağıdaki faktörlerin bir kombinasyonunu düşünün: Day = HolidayDiscount = YesFree Delivery = Yes Yukarıdaki koşullara göre satın almama olasılıklarını bulalım. A = No Purchase Bayes Teoremini uygulayalım: = [(5/10) * (4/10) * (5/10) * (10/30)] / [(16/30) * (20/30) * (13/30)]= 0.22 Benzer şekilde, yukarıdaki koşullar altında bir ürün satın alma olasılıklarını bulalım. A = Buy Bayes Teoremini uygulayarak, gösterildiği gibi P (A | B) elde ederiz: = [(13/20) * (14/20) * (8/20) * (20/30)] / [(16/30) * (13/30) * (20/30)]= 0.79 Satış yapma olasılığı = 0.79Satış yapmama olasılığı = 0.22 Son olarak, bu gün şartlı satın alma olasılığımız var. Ardından, olayların olasılığını elde etmek için bu olasılıkları normalleştirin: Olasılıkların Toplamı = 0.79 + 0.22 = 1.01 Satış yapma olasılığı = 0.79 / 1.01 = 0.782Satış yapmama olasılığı = 0.22 /1.01 = 0.218 Sonuç: % 78.2, % 21.8’den fazla olduğundan, ortalama bir müşterinin tatilde indirimli ve ücretsiz teslimatla alışveriş yapacağı sonucuna varabiliriz. Understanding Naive Bayes and Machine LearningNaive Bayes sınıflandırıcısı, sınıflandırma görevi için kullanılan olasılıklı bir makine öğrenme modelidir. Sınıflandırıcının noktası, Bayes teoremine dayanır. Types of Naive Bayes Classifier:Multinomial Naive Bayes:Bu çoğunlukla belge sınıflandırma problemi için kullanılır, yani bir belgenin spor, politika, teknoloji vb. kategorisine ait olup olmadığı. Sınıflandırıcının kullandığı özellikler / öngörücüler belgede bulunan kelimelerin sıklığıdır. Haberleri sınıflandırmak için kullanılabilir. Bernoulli Naive Bayes:Bu, multinomial saf naive bayese benzer, ancak tahmin ediciler boole değişkenleridir. Sınıf değişkenini tahmin etmek için kullandığımız parametreler, örneğin metinde bir kelime olduğunda veya olmasa da, sadece evet veya hayır değerlerini alır. Gaussian Naive Bayes:Gauss Naive Bayes, her biri bir Gauss (normal) dağılıma uygun olarak sürekli değerli özellikleri ve modelleri destekler. Verilerin boyutlar arasında eş varyans (bağımsız boyutlar) olmaksızın bir Gauss dağılımı ile tanımlandığı bir model varsayalım. Bu model, her bir etiketin içindeki noktaların ortalamasını ve standart sapmasını basitçe bularak uygun hale getirilebilir, böyle bir dağılımı tanımlamak için gereken tek şeydir.Yukarıdaki çizim, bir Gaussian Naive Bayes (GNB) sınıflandırıcısının nasıl çalıştığını gösterir. Her veri noktasında, o nokta ile her sınıf ortalaması arasındaki z-skor mesafesi hesaplanır, yani sınıf ortalamasından uzaklığın o sınıfın standart sapmasına bölünmesidir. Böylece, Gauss Naive Bayes’in biraz farklı bir yaklaşıma sahip olduğunu ve verimli bir şekilde kullanılabileceğini görüyoruz. Advantages of Naive Bayes Bağımsız tahmin ediciler varsayımı doğru olduğunda, Naive Bayes sınıflandırıcı diğer modellere kıyasla daha iyi performans gösterir. Naive Bayes, test verilerini tahmin etmek için az miktarda eğitim verisi gerektirir. Yani eğitim süresi daha azdır. Naive Bayes’in uygulanması da kolaydır. Hem sürekli hem de ayrık verileri işler. Tahmin edicilerin ve veri noktalarının sayısı ile oldukça ölçeklenebilir. Hızlıdır ve gerçek zamanlı tahminler yapmak için kullanılabilir. Alakasız özelliklere duyarlı değildir. Disadvantages of Naive Bayes Naive Bayes’in temeli, bağımsız tahmin edicilerin varsayımıdır. Naive Bayes, dolaylı olarak tüm özniteliklerin karşılıklı olarak bağımsız olduğunu varsayar. Gerçek hayatta, tamamen bağımsız bir dizi tahmin ediciye sahip olmamız neredeyse imkansızdır. Kategorik değişkenin test veri setinde eğitim veri setinde gözlenmeyen bir kategori varsa, model 0 (sıfır) olasılık atayacaktır ve bir tahmin yapamayacaktır. Bu genellikle Sıfır Frekans olarak bilinir. Naive Bayes kötü bir tahminci olarak da bilinir, bu nedenle tahmin_proba’nın olasılık çıktıları çok ciddiye alınmamalıdır. Where is Naive Bayes Used?Naive Bayes Classifier birçok alanda kullanılabilir. Bunlarda bazıları : Recommendation System Face/Object Recognition Hava Tahmini Haberlerin sınıflandırılması Spam Filtresi /Sentiment Analysis/ Text Sınıflandırma Medikal Teşhis","link":"/NaiveBayes/"},{"title":"Decision Tree Algorithm","text":"What is a Decision Tree?Karar Ağacı, sınıflandırma problemlerinde yaygın olarak kullanılan önceden tanımlanmış bir hedef değişkene sahip ve denetlenen(supervised) öğrenme algoritması olarak tanımlanabilir. Karar Ağaçları yapısı gereği sınıflandırma problemlerine mükemmel uyar. Karar ağaçları hem sürekli girdi-çıktı değişkenlerinde hem de kategorik çıktı değişkenlerinde kullanılabilir. Bu yöntemde örnek, giriş değişkenlerindeki en önemli ayırıcı veya farklılaştırıcı tarafından iki veya daha fazla homojen kümeye bölünür. Örnek olarak 3 farklı değişkeni olan 30 tane çocuğun olduğu bir gruba bakalım. Gender (M,F) Town (A ,B) Weight(50-60 kg) 15 tanesi boş zamanlarında Lord of The Rings(LOTR) izliyor. Şimdi şart, boş zamanlarında kimin LOTR izlediğini tahmin edecek bir model yaratmak istemem. Bu problem için çocukları farklılaştırmak ve LOTR izleyen çocuklar gibi kategorilere eklemek gerekir. Bu, üçü arasında oldukça önemli bir girdi değişkenine dayanmalıdır.Böyle bir durumda, bir karar ağacı, üç değişkeni de kullanarak çocukları farklılaştırdığı ve sınıflandırdığı için çok yardımcı olabilir ve birbirlerine heterojen olacak en homojen çocuk gruplarını oluşturur. Karar ağaçları, yukarıda bahsedildiği gibi, en önemli değişkeni ve onun değerini bulur ve tanımlar. Yani en iyi homojen veri kümesini bulur. Bununla birlikte buradan çıkan soru, bunu nasıl yaptığı yani değişkeni ve bölünmeyi nasıl tanımladığıdır. Karar ağacı, bu eylemi gerçekleştirmek için çeşitli algoritmalar kullanır. Types of Decision TreesKarar ağacının sınıflandırılması, mevcut olan hedef değişken türüne bağlı olabilir. İki tipte olabileceği bulunmuştur: 1. Categorical Variable Decision Tree:Kategorik hedef değişkeni olan Karar ağaçlarıdır. Az önce bahsettiğimiz örneğe dönersek, içindeki hedef değişken” Çocuklar LOTR izliyor mu?” cevap EVET veya HAYIR. 2. Continuous Variable Decision Tree:Karar ağacında devam eden bir hedef değişkeni vardır. Örneğin bir kişinin vergi departmanına ödeme yapacağını varsayalım(Evet/Hayır). Burada bireyin geliriniin önemli bir değişken olduğu görülmektedir. Ancak vergi şirketi, kişinin ayrıntılarına sahip olabilir veya olmayabilir. Şimdi, değişkenin öneminin zaten farkında olduğumuz için, ürün, meslek vb. değişkenler kullanılarak geliri tahmin etmek için bir karar ağacı oluşturulabilir. Böyle bir durumda, sürekli bir değişken için tahminler gerçekleşiyor. Karar Ağacı genellikle ağaç metaforlarıyla dolu bir jargonu vardır. En önemli deyimlere bir göz atalım:Root Node:Toplam örnek veya popülasyon anlamına gelir. Bu daha sonra iki veya daha fazla homojen kümeye bölünür.Splitting: Düğümleri(nodes) iki veya daha fazla alt düğümlere(sub nodes) ayırmak için kullanılan işlemdir.Decision Node: Alt düğümlerin daha fazla alt düğümlere bölünmesi splitting olarak bilinir. Ancak, bu süreçte oluşturulan düğüm bir karar düğümü olarak bilinir.Leaf/Terminal Node: Yaprak veya terminal olarak bilinen bölünemeyen düğümlerdir.Pruning:Ağaç ve bitkiler metaforlarına devam edersek, bir karar düğümünün alt düğümlerinin kaldırıldığı süreç, budama olarak bilinir. Dolayısıyla bölünmeyi önleyen bir süreçtir.Branch / Sub-Tree:Tam bir ağacın alt bölümü, alt ağaç veya dal olarak bilinir.Parent and Child Node:Düğümlerin bölümünde, bölünen düğümler parent node olarak adlandırılırken, child node bu bölünme nedeniyle oluşur. Karar ağaçlarında, bir kayıt için bir sınıf etiketi tahmin etmek için ağacın kökünden(root) başlarız. Kök niteliğinin değerlerini kaydın niteliğiyle karşılaştırırız. Karşılaştırma temelinde, bu değere karşılık gelen dalı izler ve bir sonraki düğüme atlarız. Tahmin edilen sınıf değerine sahip bir yaprak düğüme(leaf node) ulaşana kadar kaydımızın nitelik değerlerini ağacın diğer dahili düğümleriyle karşılaştırmaya devam ediyoruz.Şimdi karar ağacı modelini nasıl oluşturabileceğimizi anlayalım. Karar ağacını kullanırken yaptığımız varsayımlardan bazıları aşağıdadır: Başlangıçta tüm eğitim seti kök(root) olarak kabul edilir. Özellik değerlerinin kategorik olması tercih edilir. Değerler süreklilik arz ediyorsa modeli oluşturmadan önce ayrıklaştırılır. Kayıtlar, nitelik değerlerine göre yinelemeli olarak dağıtılır. Ağacın kök veya iç düğümü olarak niteliklerin yerleştirilmesi, bazı istatistiksel yaklaşımlar kullanılarak yapılır. Karar ağacı uygulamasındaki birincil zorluk, hangi nitelikleri kök düğüm ve her düzeyde kök düğüm(root) olarak ele almamız gerektiğini belirlemektir. Buna nitelik seçimi(attributes selection) denir. Her seviyede kök düğüm olarak düşünülebilecek niteliği belirlemek için farklı nitelik seçim ölçülerimiz vardır. Nitelik seçiminde kullanılan popüler ölçümler: Information Gain Gini Index Attributes SelectionVeri kümesi “n” nitelikten oluşuyorsa, hangi niteliğin kökte veya ağacın farklı düzeylerinde dahili düğümler olarak yerleştirileceğine karar vermek karmaşık bir adımdır. Kök olacak herhangi bir düğümü rastgele seçmek sorunu çözemez. Rastgele bir yaklaşım izlersek, bize düşük doğrulukta kötü sonuçlar verebilir. Bu nitelik seçme problemini çözmek için araştırmacılar Information Gain, Gini Indeksi gibi çözümler geliştirdiler. Bunlar her özellik için değerleri hesaplayacaktır. Değerler sıralanır ve nitelikler sıraya göre ağaca yerleştirilir, yani yüksek değerli nitelik (Information Gain durumunda) köke yerleştirilir. Information Gain’i bir kriter olarak kullanırken, niteliklerin kategorik olduğunu varsayılır. Gini indeksi için niteliklerin sürekli olduğu varsayılır. Information GainInformation Gain bir kriter olarak kullanarak, her bir özelliğin içerdiği bilgileri tahmin etmeye çalışırız. Entropi, rastgele bir değişkenin belirsizliğinin ölçüsüdür, rastgele bir örnek koleksiyonunun safsızlığını karakterize eder. Entropi ne kadar yüksekse bilgi içeriği o kadar fazladır. Veri biliminde entropi, bir sütunun ne kadar “karışık” olduğunu ölçmenin bir yolu olarak kullanılır. Özellikle, düzensizliği ölçmek için entropi kullanılır. Yalnızca iki sınıflı binary classification problemi için, pozitif ve negatif sınıf vardır. Tüm örnekler pozitifse veya tümü negatifse, o zaman entropi 0, yani düşük olacaktır. Kayıtların yarısı pozitif sınıfta ve yarısı negatif sınıfta ise, o zaman entropi 1 yani yüksektir. Çıkarılacak sonuç sınıflandırdığımız dalların entropisinin düşük olması yani homojen olmasını isteriz. Entropi formülü:Bir örnekle entropi hesaplayalım. Diyelim ki aşağıdaki görselde olduğu gibi bir veri setimiz olsun. Eğer x= 1.5 için verileri ayırırsak nele oluyor bakalım. Bu ayırma işlemi veriyi iki dala veya kümeye ayıracak. Bu dallarda Sol dalda, 4 mor Sağ dalda, 1 mor, 5 yeşil Bu ayırma optimal mi, en iyi mi? Gelin bu ayırmayı en iyi olacak şekilde ölçelim.C tane sınıf için entropi formülü:Ayırmadan önce 5 mor ve 5 yeşil verimiz vardı.Ayırma öncesi entropi Ebefore: Ayırma işleminden sonra entropilerimiz Eleft ve Eright: Ayırma entropimiz Esplit: Her özelliğin entropi ölçüsünü hesaplayarak information gain hesaplanabilir. Information Gain, niteliğe göre sıralama nedeniyle entropide beklenen azalmayı hesaplar. Information Gain hesaplayalım. Burda ne kadar entropiden kurtulduğumuzu buluruz. Parent entropimiz Ebefore, child entropimiz Esplit.IG (Parent,Child) = E(Parent)- E(Child) Gini Indexİtalyan istatistikçi ve sosyolojist olan Corrado Gini, toplumda gelir eşitsizliğini ölçmek için geliştirdiği gini indeksine bakalım.Gini İndeksi, rastgele seçilen bir öğenin ne sıklıkla yanlış bir şekilde tanımlanacağını ölçmek için kullanılan bir metriktir. Daha düşük gini indeksli bir niteliğin tercih edilmesi gerektiği anlamına gelir. Şimdi görseldeki gibi veri setimiz olsun. Gini indeksini ölçelim. x= 2 için verisetini ayıralım. Bu mükemmel bir ayrım! Veri kümemizi mükemmel şekilde iki kola ayırır: Sol dalda, 5 mor Sağ dalda, 5 yeşil Ya biz x= 1.5 değerinde ayırırsak? Sol dalda, 4 mor Sağ dalda, 1 mor, 5 yeşil Hangi ayırmanın daha iyi olduğunu nasıl anlarız?İşte bu noktada Gini Impurity bize yolu gösteriyor. Veri kümemizde rastgele bir veri noktası seçin Veri kümesindeki sınıf dağılımına göre rastgele sınıflandırın. Veri noktasını yanlış sınıflandırmamızın olasılığı nedir? Bu sorunun cevabı Gini Impurity. Veri kümemizin tamamının Gini Impurity’sini hesaplayalım. Rasgele bir veri noktası seçersek, bu ya mor (%50) veya yeşil (%50)dir. Şimdi, veri noktamızı sınıf dağılımına göre rastgele sınıflandırıyoruz. Her bir rengin 5’ine sahip olduğumuz için %50 oranında mor, %50 oranında yeşil olarak sınıflandırıyoruz. Veri noktamızı yanlış sınıflandırmamızın olasılığı nedir? Yukarıda sadece 2 olayı yanlış sınıflandırdık. Toplam olasılığımız 25%+25% =50%Gini Impurity = 0.5 C tane sınıf için Gini Impurity formülü: C=2 (mor,yeşil) P(1)=p(2)=0.5 G = p(1)∗(1−p(1))+p(2)∗(1−p(2))G = 0.5∗(1−0.5)+0.5∗(1−0.5)G = 0.5Tabloda hesapladığımız sonuç çıktı.​ Yaptığımız mükemmel bölüme geri dönelim. Bölünmeden sonra iki dalın Gini Impurity değerleri nelerdir?Sol dalda sadece mor veriler var.Gini Impurity değeri:Gleft = 1∗(1−1) + 0∗(1−0) = 0​Sağ dalda sadece yeşil veriler var.​Gini Impurity değeri:Gright = 0∗(1−0) + 1∗(1−1) = 0​Gini Gain = 0.5 - 0 = 0.5 (for x=2)Her iki dalda da 0 safsızlık var. Mükemmel ayrım, 0.5 safsızlık içeren bir veri kümesini 0 safsızlık içeren 2 dala dönüştürdü. 0 değerindeki bir Gini Impurity, mümkün olan en düşük ve en iyi safsızlıktır. Sadece her şey aynı sınıf olduğunda elde edilebilir. Şimdi x=1.5 için ayırdığımız ver kümesine bakalım.Sol dalda sadece mor veriler var.Gini Impurity değeri:Gleft = 1∗(1−1) + 0∗(1−0) = 0 Sağ dalda 1 mor ve 5 yeşil veri var.​Gini Impurity değeri:Gright = 1/6∗(1−1/6) + 5/6∗(1−5/6)Gright = 0.278 Her dalın safsızlığını kaç veriye sahip olduğuna göre ağırlıklandırarak ayrımın kalitesini belirleyeceğiz. Sol dalda 4 veriye ve Sağ dalda 6 veriye sahip olduğundan, şunu elde ederiz:G = (0.4∗0) + (0.6∗0.278) = 0.167 Bu ayırımla çıkardığımız safsızlık miktari yani kazanç(gain): Gini Gain = 0.5- 0.67 = 0.33 (for x= 1.5) 0.5 &gt; 0.33’ten büyük olduğu için x=2 noktası en iyi ayırım noktasıdır.Büyük Gini Gain= En İyi Ayırım Bir karar ağacı eğitilirken, dalların ağırlıklı safsızlıklarının orijinal safsızlıktan çıkarılmasıyla hesaplanan Gini Gain maksimize ederek en iyi ayrım seçilir. Entropy vs Gini ImpurityHer iki yöntemin de dahili çalışması çok benzerdir ve her ikisi de her yeni bölünmeden sonra feature/split hesaplamak için kullanılır. Ancak her iki yöntemi de karşılaştırırsak, o zaman Gini Impurity bilgi işlem gücü açısından entropiden daha verimlidir. Entropi grafiğinde de görebileceğiniz gibi, önce 1’e kadar artar ve sonra azalmaya başlar, ancak Gini Impurity durumunda sadece 0,5’e kadar gider ve sonra azalmaya başlar, dolayısıyla daha az hesaplama gücü gerektirir. Entropi aralığı 0 ila 1 arasındadır ve Gini Impurity aralığı 0 ila 0,5 arasındadır. Bu nedenle, Gini Impurity’nin en iyi özellikleri seçmek için entropiye kıyasla daha iyi olduğu sonucuna varabiliriz. Pruning TreeStopping CriteriaBüyüme aşaması, bir durdurma kriteri tetiklenene kadar devam eder. Aşağıdaki koşullar ortak durdurma kurallarıdır: Eğitim setindeki tüm örnekler tek bir y değerine aittir. Maksimum ağaç derinliğine ulaşıldı. Terminal düğümündeki vaka sayısı, üst düğümler için minimum vaka sayısından azdır. Düğüm bölünmüşse, bir veya daha fazla alt düğümdeki vaka sayısı, alt düğümler için minimum vaka sayısından daha az olacaktır. En iyi bölme kriteri, belirli bir eşikten büyük değildir. PruningSıkı durdurma kriterlerinin kullanılması, küçük ve yetersiz donatılmış karar ağaçları oluşturma eğilimindedir. Öte yandan, gevşek durdurma kriterlerinin kullanılması, eğitim setine aşırı uygun(overfit) büyük karar ağaçları oluşturma eğilimindedir. Bu ikilemi çözmek için, gevşek bir durdurma kriterine dayalı ve karar ağacının eğitim setini aşırı öğrenmesine(overfit) izin veren bir budama metodolojisi geliştirildi. Daha sonra aşırı uyumlu ağaç, genelleme doğruluğuna katkıda bulunmayan alt dalları kaldırarak daha küçük bir ağaç haline getirilir. Çeşitli çalışmalarda, budama yöntemlerinin, özellikle gürültülü alanlarda, bir karar ağacının genelleme performansını iyileştirebileceği gösterilmiştir.Budamanın bir diğer önemli motivasyonu da “basitlik için accuracy değiş-tokuşu” dur. Amaç yeterince doğru, kompakt bir konsept tanımı oluşturmak olduğunda, budama(pruning) oldukça faydalıdır. Bu süreç içinde ilk karar ağacı tamamen doğru olarak görüldüğünden, budanmış bir karar ağacının doğruluğu ilk ağaca ne kadar yakın olduğunu gösterir.Karar ağaçlarını budamak için çeşitli teknikler vardır. Çoğu, düğümlerin yukarıdan aşağıya veya aşağıdan yukarıya geçişini gerçekleştirir. Bu işlem belirli bir kriteri iyileştirirse bir düğüm budanır. Aşağıda en popüler teknikleri inceleyelim. 1.Cost Complexity PruningCost Complexity Pruning (aynı zamanda en zayıf halka budama veya hata karmaşıklığı budama olarak da bilinir) iki aşamada ilerler. İlk aşamada, T0’ın budama öncesi orijinal ağaç ve Tk’nin kök ağaç olduğu eğitim verileri üzerine T0, T1, …, Tk ağaçları dizisi oluşturulur. İkinci aşamada bu ağaçlardan biri genelleme hatası tahminine göre budanmış ağaç olarak seçilir. Ti + 1 ağacı, önceki Ti ağacındaki bir veya daha fazla alt ağacın uygun yapraklarla değiştirilmesiyle elde edilir. Budanmış alt ağaçlar, budanmış yaprak başına görünen hata oranındaki en düşük artışı elde edenlerdir:Burada ε(T, S), örnek S üzerinden T ağacının hata oranını gösterir ve |leaves (T )| T’deki yaprak sayısını gösterir .pruned (T,t), T’deki t düğümü uygun yaprakla değiştirilerek elde edilen ağacı gösterir. İkinci aşamada, budanmış her ağacın genelleme hatası T0, T1,…, Tk tahmin edilmektedir. Daha sonra en iyi budanmış ağaç seçilir. Verilen veri kümesi yeterince büyükse, onu bir eğitim setine ve bir budama setine(pruning set) ayırmak önerilir. Ağaçlar eğitim seti kullanılarak inşa edilir ve budama seti üzerinde değerlendirilir.Öte yandan, verilen veri kümesi yeterince büyük değilse, hesaplama karmaşıklığı etkilerine rağmen çapraz doğrulama(cross-validation) metodolojisinin kullanması öneririlir. 2.Reduced Error PruningAzaltılmış hata budama olarak bilinen karar ağaçlarını budamak için basit bir prosedür. Alttan üste iç düğümler üzerinde geçiş yaparken, en sık sınıfla değiştirmenin ağacın doğruluğunu azaltıp azaltmadığını belirlemek için her iç düğümü kontrol eder.Accuracy azalmazsa düğüm kesilir. Prosedür, daha fazla budama accuracy azaltana kadar devam eder.Accuracy tahmin etmek için bir budama seti kullanılması önerilir. Bu prosedürün, belirli bir budama setine göre en küçük accuracy alt ağaç ile sona erdiği gösterilebilir. 3.Minimum Error Pruning (MEP)Minimum hata budama, iç düğümlerin aşağıdan yukarıya geçişini içerir. Bu teknik, her düğümde, budama ile ve budama olmadan l-olasılık hata oranı tahminini karşılaştırır.L-olasılık hata oranı tahmini, frekansları kullanarak basit olasılık tahmininin düzeltilmesidir. St, yaprak t’ye ulaşan örnekleri gösteriyorsa, bu yapraktaki beklenen hata oranı: Burada papr (y = ci), y’nin ci değerini aldığı a-priori olasılığıdır ve l, a-priori olasılığına verilen ağırlığı gösterir. Bir iç düğümün hata oranı, dallarının hata oranının ağırlıklı ortalamasıdır. Ağırlık, her dal boyunca örneklerin oranına göre belirlenir. Hesaplama yapraklara kadar yinelemeli olarak yapılır. Bir iç düğüm budanırsa, o zaman bir yaprak olur ve hata oranı son denklem kullanılarak doğrudan hesaplanır. Sonuç olarak,belirli bir iç düğümün budamasından önce ve sonra hata oranını karşılaştırabiliriz. Bu düğümün budaması hata oranını arttırmazsa, budama kabul edilmelidir. 4.Pessimistic PruningPessimistic Pruning, bir budama seti veya çapraz doğrulama(cross-validation) ihtiyacını önler ve bunun yerine pessimistic istatistiksel korelasyon testini kullanır.Temel fikir, eğitim seti kullanılarak tahmin edilen hata oranının yeterince güvenilir olmamasıdır. Bunun yerine, binom dağılımı için süreklilik düzeltmesi olarak bilinen daha gerçekçi bir önlem kullanılmalıdır: Ancak, bu düzeltme hala iyimser bir hata oranı üretir. Sonuç olarak, hata oranı bir referans ağacından bir standart hata içinde ise, bir iç düğüm t budama:Son koşul, oranlar için istatistiksel güven aralığına dayanmaktadır. Genellikle son koşul, kökü t iç düğüm olan bir alt ağaca karşılık gelir. S, t düğümüne atıfta bulunan eğitim kümesini gösterir. 5.Error-Based Pruning (EBP)Error-Based Pruning, kötümser budamanın bir evrimidir. İyi bilinen C4.5 algoritmasında uygulanmaktadır.Pessimistic Pruning’de olduğu gibi, hata oranı, oranlar için istatistiksel güven aralığının üst sınırı kullanılarak tahmin edilir.ε(T, S), S eğitim setindeki T ağacının yanlış sınıflandırma oranını gösterir.Z, standart normal kümülatif dağılımın tersidir.α, istenen anlamlılık seviyesidir.Alt ağaç(sub-tree) (T,t), t düğüm tarafından köklendirilen alt ağacı gösterir.maxchild (T, t), t’nin en sık görülen alt düğümünü gösterir.St, t düğümüne ulaşan S’deki tüm örnekleri gösterir.Prosedür, aşağıdan yukarıya tüm düğümleri geçer ve aşağıdaki değerleri karşılaştırır:(1) εUB(subtree(T,t), St)(2) εUB(pruned(subtree(T,t), t), St)(3) εUB(subtree(T, maxchild(T,t)), Smaxchild(T,t)) En düşük değere göre, prosedür ağacı olduğu gibi bırakır,t düğümünü budar veya t düğümünü maxchild(T,t) tarafından köklendirilen alt ağaçla değiştirir. 6.Minimum Description Length (MDL) PruningMinimum Description Length (MDL), bir düğümün genelleştirilmiş doğruluğunu değerlendirmek için kullanılabilir. Bu yöntem, ağacı kodlamak için gereken bit sayısını kullanarak karar ağacının boyutunu ölçer. MDL yöntemi, daha az bit ile kodlanabilen karar ağaçlarını tercih eder, bir yaprak t’deki bir bölünmenin maliyetinin şu şekilde tahmin edilebileceğini gösterir:St, t düğümüne ulaşan örnekleri gösterir. Bir iç düğümün bölme maliyeti, çocuklarının maliyet toplamasına göre hesaplanır. Comparison of Pruning MethodsÇeşitli çalışmalar farklı budama tekniklerinin performansını karşılaştırır. Sonuçlar, Cost-Complexity Pruning ve Reduced Error Pruning aşırı budama eğilimindedir, yani daha küçük ama daha az doğru karar ağaçları oluşturur. Error-Based Pruning, Pessimistic Error Pruning ve Minimum Error Pruning düşük budamaya eğilimlidir. Karşılaştırmaların çoğu, no free lunch teoreminin budama için de geçerli olduğu sonucuna varmıştır, yani diğer budama yöntemlerinden daha iyi performans gösteren bir budama yöntemi yoktur. Type of Decision Tree Algorithm● Classification and Regression Tree (CART)● Iterative Dichotomiser 3 (ID3)● C4.5 and C5.0 (different versions of a robust approach)● Chi-squared Automatic Interaction Detection (CHAID)● Decision Stump● M5● Conditional Decision Trees En dikkate değer karar ağacı algoritması türleri şunlardır: Iterative Dichotomiser 3 (ID3)Bu algoritma, hangi özelliğin kullanılacağına karar vermek için Information Gain kullanır ve verilerin mevcut alt kümesini sınıflandırır. Ağacın her seviyesi için, geri kalan veriler için Information Gain özyinelemeli olarak hesaplanır. C4.5Bu algoritma, ID3 algoritmasının halefidir. Bu algoritma, sınıflandırma niteliğine karar vermek için Information Gain veya Gain ratio kullanır. Hem sürekli hem de eksik nitelik değerlerini işleyebildiği için ID3 algoritmasının doğrudan bir iyileştirmesidir. Classification and Regression Tree (CART)Bağımlı değişkene bağlı olarak bir regresyon ağacı ve bir sınıflandırma ağacı üretebilen dinamik bir öğrenme algoritmasıdır. Advantages of Decision Trees Karar ağaçları kendinden açıklamalıdır ve sıkıştırıldıklarında takip etmeleri de kolaydır. Yani karar ağacında makul sayıda yaprak varsa profesyonel olmayan kullanıcılar tarafından kavranabilir. Dahası, karar ağaçları bir dizi kurala dönüştürülebildiğinden, bu tür bir temsil anlaşılır olarak kabul edilir. Karar ağaçları, hem nominal hem de sayısal girdi niteliklerini işleyebilir. Karar ağacı gösterimi, herhangi bir ayrık değer sınıflandırıcısını temsil edecek kadar zengindir. Karar ağaçları, hatalı olabilecek veri kümelerini işleyebilir. Karar ağaçları, eksik değerlere sahip olabilecek veri setlerini ele alabilir. Karar ağaçları, parametrik olmayan bir yöntem olarak kabul edilir, yani kararlar, alan dağılımı ve sınıflandırıcı yapısı hakkında herhangi bir varsayım içermez. Sınıflandırma maliyeti yüksek olduğunda, karar ağaçları sadece kökten yaprağa tek bir yol boyunca yer alan özelliklerin değerlerini talep etmeleri bakımından çekici olabilir. Disadvantages of Decision Trees Algoritmaların çoğu (ID3 ve C4.5 gibi), hedef özelliğin yalnızca ayrık değerlere sahip olmasını gerektirir. Karar ağaçları “böl ve yönet” yöntemini kullandıkça, alaka düzeyi yüksek birkaç özellik varsa iyi performans gösterir, ancak birçok karmaşık etkileşim mevcuttur. Bunun sebeplerinden biri diğer sınıflandırıcıların bir sınıflandırıcıyı kısaca tanımlayabilmesidir.Bunu bir karar ağacı kullanarak temsil etmek çok zor olurdu. Bu fenomenin basit bir örneği, karar ağaçlarının çoğaltma sorunudur. Çoğu karar ağacı, bir kavramı temsil etmek için örnek alanını birbirini dışlayan bölgelere böldüğünden, bazı durumlarda ağaç, sınıflandırıcıyı temsil etmek için aynı alt ağacın birkaç kopyasını içermelidir. Çoğaltma problemi, alt ağaçların tekrarlanmasını ayırıcı kavramlara zorlar. Örneğin, kavram aşağıdaki ikili fonksiyonu takip ederse: y = (A1 ∩ A2) ∪ (A3 ∩ A4) bu fonksiyonu temsil eden minimum tek değişkenli karar ağacı aşağıdaki şekilde gösterilmektedir. Ağacın aynı alt ağacın iki kopyasını içerdiğine dikkat edin. Karar ağaçlarının açgözlü özelliği, belirtilmesi gereken başka bir dezavantaja yol açar. Eğitim setine, ilgili niteliklere ve gürültüye aşırı duyarlılık, karar ağaçlarını özellikle istikrarsız hale getirir: köke yakın bir bölünmede küçük bir değişiklik, aşağıdaki tüm alt ağacı değiştirecektir. Eğitim setindeki küçük farklılıklar nedeniyle, algoritma en iyisi olmayan bir özelliği seçebilir. Parçalanma sorunu, verilerin daha küçük parçalara bölünmesine neden olur. Bu genellikle, yol boyunca birçok özellik test edilirse gerçekleşir. Veriler her bölünmede yaklaşık olarak eşit olarak bölünürse, tek değişkenli bir karar ağacı O (logn) özelliklerinden fazlasını test edemez. Bu, birçok ilgili özelliğe sahip görevler için karar ağaçlarını dezavantajlı konuma getirir. Çoğaltmanın her zaman parçalanmayı ifade ettiğini, ancak parçalanmanın herhangi bir çoğaltma olmadan gerçekleşebileceğini unutmayın. Başka bir sorun, eksik değerlerle başa çıkmak için gereken çabayla ilgilidir. Eksik değerleri ele alma becerisi bir avantaj olarak kabul edilirken, bunu başarmak için gereken aşırı çaba bir dezavantaj olarak kabul edilir. Test edilen bir özellik eksikse alınacak doğru dal bilinmemektedir ve algoritmanın eksik değerleri işlemek için özel mekanizmalar kullanması gerekir. C4.5, eksik değerler üzerindeki test oluşumlarını azaltmak için, information gaini bilinmeyen vakaların oranıyla cezalandırır ve ardından bu örnekleri alt ağaçlara böler. CART, çok daha karmaşık bir vekil özellikler(feature) şeması kullanır. Karar ağacı indüksiyon algoritmalarının çoğunun miyop doğası indükleyicilerin yalnızca bir seviye ileriye bakması gerçeğiyle yansıtılır. Özellikle, bölme kriteri, olası öznitelikleri hemen soyundan gelenlere göre sıralar. Bu tür bir strateji, tek başına yüksek puan alan testleri tercih eder ve özellik kombinasyonlarını gözden kaçırabilir. Daha derin önden bakış stratejilerinin kullanılması, hesaplama açısından pahalı kabul edilir ve yararlı olduğu kanıtlanmamıştır.","link":"/DecisionTree/"},{"title":"Real Time Iot Project","text":"Akıllı şehirler, akıllı evler, akıllı tarım ve daha birçok alana duyduğumuz Nesnelerin İnterneti(Internet Of Things(IOT)) hayatlarımıza girdi. Dünyada akıllı tarım uygulamalarını takip etmemiz ve bunları ülkemizdeki her çiftinin kullanabileceği ücretsiz uygulamalarla tarımı daha verimli hale getirmemiz gerekiyor. Fazladan 1 damla su bile israf etmememiz gereken günlerdeyiz. Akıllı tarım yöntemi ile çiftçiler, tarlalarını tablet ya da telefondan kolay bir şekilde kontrol edebilecek ve sulamaya kadar birçok işlemi uzaktan halledebilecektir.Peki bunun için neler yapabiliriz? Elimizi taşın altına koyabiliriz diyerek bu projeye başladım. Bu projede ortam sıcaklığını ve nemini anlık ölçüp mosquitto, kafka, spark, postgressql ve grafana kullanarak bu verileri kullanılabilir hale getirmeye çalıştım. Hadi başlayalım!!! Data Pipeline Malzemeler:-DHT11 (ısı ve nem ölçer)-ESP8266-Dişi-dişi jumper kablo-Usb kablo DHT11 projede kullandığım ısı ve nem ölçer sensör. Herhangi bir elektronik mağazasından temin edebilirsiniz. 15 TL ye satın aldım.ESP8266 modülü internete bağlanıp veri yükleme ve veri çekmeye, projelerinizi internet üzerinden kontrol edebilmenize imkan tanıyan ufak boyutlara sahip, Espressif System tarafından SoC (System on Chip) olarak geliştirilen çipi üzerinde barındıran modüldür. Daha ayrıntılı bilgi için bu kaynağı inceleyebilirsiniz. https://medium.com/@zaferaltun/esp8266-wifi-modul-nedir-nasil-kullanilir-neler-yapabiliriz-9216886ef604Jumper Kablo DHT11 ve ESP8266 arasında iletişim için gerekli kablo dişi-dişi olanını kullandım.Fiyatı 7-10 TL arasında değişiyor.USB kablo ESP8266 ile bilgisayar arasında iletişim kurmak için kullandım.Malzemeler tamamlandı şimdi projemizin akış diyagramında hangi teknolojileri kullandığımıza bakalım. MosquittoMosquitto (open source) açık kaynak MQTT Broker yazılımıdır. Diğer haberleşme yapılarına göre basit oluşu ve minimum kaynak tüketmesi sebebiyle“machine-to-machine” (M2M) makineden makineye veri iletiminde ve (IOT) “Internet of Things” İnternete bağlı nesnelerin mesajlaşmasında tercih edilmektedir. Mosquitto kurulumu için bu kaynakları kullanabilirsiniz. https://medium.com/@iotmqtt/mqtt-mosquitto-kurulumu-e9ac57e42e59 https://mosquitto.org/download/ Apache KafkaLinkedln tarafından geliştirilen bu framework yapısı şuan Apache bünyesinde yer almaktadır. Büyük verileri anlık olarak kaydeden, depolayan ve analiz eden bu açık kaynak kodlu framework büyük verilerin hızlı biçimde analiz edilmesi ve depolanması için kullanılmaktadır. Apache Kafkanın ürünleri arasında Apache ZooKeeper yer almaktadır. Apache yazılım vakfı tarafından geliştirilen bir yazılım projesi olan Apache Zookeeper, büyük dağıtık sistemler için kullanılan dağıtık bir yapılandırma hizmetidir. Üst düzey bir Apache projesi olan ZooKeeper, adlandırma katkı ve senkronizasyon hizmeti yapmak adına kullanılan bir hiyerarşik anahtar değer deposudur. Genellikle dağıtık sistemler için kullanılmaktadır. Kurulumu için bu kaynağı kullanabilirsiniz.https://medium.com/teknopar-akademi/kafka-installation-3ac651169d0bhttps://svn.apache.org/repos/asf/kafka/site/082/quickstart.html Apache SparkApache Spark, büyük veri kümelerindeki görevleri hızlı bir şekilde gerçekleştirebilen, aynı zamanda veri işleme görevlerini birden çok bilgisayara tek başına dağıtabilen veya diğer dağıtılmış bilgi işlem araçlarıyla birlikte dağıtabilen bir veri işleme motorudur. Bu iki nitelik, Büyük Veri depoları arasında hızla ilerlemek için gerekli olan bilgi işlem gücünün düzenlenmesini sağlayan büyük veri ve makine öğrenimi dünyalarının anahtarıdır. Kaynakları inceleyebilirsiniz. https://medium.com/@sinemhasircioglu/apache-spark-kurulumu-windows-4d411a5c9b43 https://teknoloji.org/apache-spark-nedir-nasil-calisir/ https://medium.com/5bayt/apache-spark-nedir-ne-i%C5%9F-yapar-5797c28eb95 Postgres SQLPostgreSQL, güçlü özellikler ve avantajlara sahip, açık kaynaklı ve tamamen ücretsiz nesne ilişkisel veri tabanı sistemidir. SQL dilinin güvenlik, depolanabilirlik ve ölçeklendirilebilme özelliklerinden faydalanan PostgreSQL, birçok alanda veri tabanı yöneticisi olarak da kullanılmaktadır. https://kerteriz.net/postgresql-veritabani-windows-kurulumu/ Apache GrafanaGrafana, çok platformlu bir açık kaynak analitiği ve etkileşimli görselleştirme web uygulamasıdır. Desteklenen veri kaynaklarına bağlandığında web için çizelgeler, grafikler ve uyarılar sağlar. Kurulumu yaptıktan sonra kullandığınız tarayıcıdan localhost:3000 ile erişebilirsiniz.https://grafana.com/docs/grafana/latest/installation/ Kullandığım teknolojiler açık kaynak kodlu ve ücretsizdir. Windows üzerine kurulumları kullandım şimdilik ama Vmware, Docker, Oracle VirtualBox üzerine kurup programları kullanabilirsiniz. Programları kurduk ve ortamımızı hazırladık.O zaman May the force be with you young padawan! Mosquitto servisini çalıştıralım.1.Powershell’i yönetici olarak çalıştıralım. Dosya yolunu mosquittoya götürelim.Enter’a basalım. cd '..\\..\\Program Files\\mosquitto\\' 2.Ardından aşağıdaki kodu yazıp Enter’a basalım. sc start mosquitto Mosquittoyu çalıştırdık Powershell’i kapatabiliriz. Zookeeper Server’ı çalıştıralım.Kafka dosya dizinine gidip kırmızı okla işaretlediğim yere cmd yazıp Enter’a basalım. Bize komut istemci açacaktır burada aşağıdaki kodu yazıp Enter’a basınca ZooKeeper Server çalışacaktır. Bu istemcileri kapatmıyoruz açık kalması gerekiyor.Windows üzerine kurduğum için: bin\\windows\\zookeeper-server-start.bat .\\config\\zookeeper.properties Linux’a kurduysanız: bin/zookeeper-server-start.sh ./config/zookeeper.properties Çıktımız aşağıdaki görseldeki gibi olmalıdır. Kafka Server’ı çalıştıralım.Yine Kafka dosya dizinine gidip kırmızı okla işaretlediğim yere cmd yazıp Enter’a basalım. Bize yeni bir komut istemci açacaktır burada aşağıdaki kodu yazıp Enter’a basınca Kafka Server çalışacaktır. Bu istemcileri kapatmıyoruz açık kalması gerekiyor.Windows üzerine kurulum için: bin\\windows\\kafka-server-start.bat .\\config\\server.properties Linux’a kurduysanız: bin/kafka-server-start.sh config/server.properties Çıktımız aşağıdaki görseldeki gibi olmalıdır. DHT11’den Mosquitto’yaPython kodlarını indirdiğimiz dosya dizinine gidip kırmızı okla işaretlediğim yere cmd yazıp Enter’a basalım. Bize yeni bir komut istemci açacaktır burada aşağıdaki kodu yazıp Enter’a basınca DHT11 ile Mosquitto konuşmaya başlayacak ve aşağıdaki görselde olduğu mesaj gönderdiğini göreceğiz. Bu istemcileri kapatmıyoruz açık kalması gerekiyor. python iot.py Kafka Producer Topic oluşturalım.Yine Kafka dosya dizinine gidip kırmızı okla işaretlediğim yere cmd yazıp Enter’a basalım. Bize yeni bir komut istemci açacaktır burada aşağıdaki kodu yazıp Enter’a basınca Kafka producer grogu isimli topiğini oluşturmuş olacağız. Bu istemcileri kapatmıyoruz açık kalması gerekiyor. bin\\windows\\kafka-console-producer.bat --broker-list localhost:9092 --topic grogu Çıktımız aşağıdaki görseldeki gibi olmalıdır. Kafka Consumer Topic oluşturalım.Yine Kafka dosya dizinine gidip kırmızı okla işaretlediğim yere cmd yazıp Enter’a basalım. Bize yeni bir komut istemci açacaktır burada aşağıdaki kodu yazıp Enter’a basınca Kafka consumer topiğini oluşturmuş olacağız. Bu istemcileri kapatmıyoruz açık kalması gerekiyor. bin\\windows\\kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic grogu Çıktımız aşağıdaki görseldeki gibi olmalıdır. Mosquitto ‘dan Kafka’yaMosquitto’dan Kafka’ya iletişimi sağlayacak dosya olan python kodlarını indirdiğimiz dosya dizinine gidip kırmızı okla işaretlediğim yere cmd yazıp Enter’a basalım. Bize yeni bir komut istemci açacaktır burada aşağıdaki kodu yazıp Enter’a basınca Mosquitto Kafka ile konuşmaya başlayacak ve aşağıdaki görselde olduğu mesaj gönderdiğini göreceğiz. Bu istemcileri kapatmıyoruz açık kalması gerekiyor. python mqttToKafka.py Çıktımız aşağıdaki görseldeki gibi olmalıdır. İndirdiğimiz PostgresSQL pgadmin4 açıp “iot_database” adında bir database oluşturalım. Ardından “iot_data” adlı bir tablo oluşturalım create table iot_data( starttime timestamp without time zone, endtime timestamp without time zone, device_name varchar(10), avg_temperature integer, avg_humiditiy integer ); Database ve tablomuzu oluşturduğumuza göre bir sonraki aşamaya geçebiliriz. Kafka’dan Spark’a SubmitKafka’ya gelen mesajları Spark’a submit edelim. İletişimi sağlayacak dosya olan python kodlarını indirdiğimiz dosya dizinine gidip kırmızı okla işaretlediğim yere cmd yazıp Enter’a basalım. Bize yeni bir komut istemci açacaktır burada aşağıdaki kodu yazıp Enter’a basınca Kafka ile Spark konuşmaya başlayacak ve aşağıdaki görselde olduğu mesaj gönderdiğini göreceğiz. Bu istemcileri kapatmıyoruz açık kalması gerekiyor. spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.0 spark_postgres.py Çıktımız aşağıdaki görseldeki gibi olmalıdır. Tekrar PostgresSQL pgAdmine gelipiot_database içine girip aşağıdaki komutu çalıştıralım. select * from iot_data; Verileri eklendiğini göreceksiniz. PostgresSQL’den Grafana’yaProjenin son aşaması olan verileri görselleştirme kısmına geldik. Bunun için Apache Grafana kullandım.Örnek dashboard yapmak için birçok kaynak mevcut bunlardan istediğiniz şekilde verileri görselleştirebilirsiniz. Dashboard oluşturunca buraya ekleyeceğim.https://www.youtube.com/watch?v=oPumWaoNw5s&amp;t=1397shttps://www.youtube.com/watch?v=4qpI4T6_bUw&amp;t=254s İlerleyen zamanda anlık verileri işlenebilir hale getirdiğim bu projenin üzerinde realtime anomaly detection yapmayı planlıyorum.","link":"/RealTime-IOT-Project/"}],"tags":[{"name":"Model","slug":"Model","link":"/tags/Model/"},{"name":"Representation","slug":"Representation","link":"/tags/Representation/"},{"name":"CostFunction","slug":"CostFunction","link":"/tags/CostFunction/"},{"name":"Regression","slug":"Regression","link":"/tags/Regression/"},{"name":"Linear Regression","slug":"Linear-Regression","link":"/tags/Linear-Regression/"},{"name":"Polynomial Regression","slug":"Polynomial-Regression","link":"/tags/Polynomial-Regression/"},{"name":"NLP","slug":"NLP","link":"/tags/NLP/"},{"name":"GPT-3","slug":"GPT-3","link":"/tags/GPT-3/"},{"name":"OpenAI","slug":"OpenAI","link":"/tags/OpenAI/"},{"name":"Feature Scaling","slug":"Feature-Scaling","link":"/tags/Feature-Scaling/"},{"name":"Min-Max Scaler","slug":"Min-Max-Scaler","link":"/tags/Min-Max-Scaler/"},{"name":"Standard Scaler","slug":"Standard-Scaler","link":"/tags/Standard-Scaler/"},{"name":"Max Abs Scaler","slug":"Max-Abs-Scaler","link":"/tags/Max-Abs-Scaler/"},{"name":"Robust Scaler","slug":"Robust-Scaler","link":"/tags/Robust-Scaler/"},{"name":"Quantile Transformer Scaler","slug":"Quantile-Transformer-Scaler","link":"/tags/Quantile-Transformer-Scaler/"},{"name":"Power Transformer Scaler","slug":"Power-Transformer-Scaler","link":"/tags/Power-Transformer-Scaler/"},{"name":"Unit Vector Scaler","slug":"Unit-Vector-Scaler","link":"/tags/Unit-Vector-Scaler/"},{"name":"Classification","slug":"Classification","link":"/tags/Classification/"},{"name":"Logistic Regression","slug":"Logistic-Regression","link":"/tags/Logistic-Regression/"},{"name":"Decision Boundary","slug":"Decision-Boundary","link":"/tags/Decision-Boundary/"},{"name":"Binary Classification","slug":"Binary-Classification","link":"/tags/Binary-Classification/"},{"name":"Multiclass Classification","slug":"Multiclass-Classification","link":"/tags/Multiclass-Classification/"},{"name":"Artificial Neural Networks (ANNs)","slug":"Artificial-Neural-Networks-ANNs","link":"/tags/Artificial-Neural-Networks-ANNs/"},{"name":"Input Layer","slug":"Input-Layer","link":"/tags/Input-Layer/"},{"name":"Hidden Layer","slug":"Hidden-Layer","link":"/tags/Hidden-Layer/"},{"name":"Output Layer","slug":"Output-Layer","link":"/tags/Output-Layer/"},{"name":"Back Propagation Algorithm","slug":"Back-Propagation-Algorithm","link":"/tags/Back-Propagation-Algorithm/"},{"name":"FeedForward Neural Networks","slug":"FeedForward-Neural-Networks","link":"/tags/FeedForward-Neural-Networks/"},{"name":"FeedBack Neural Network","slug":"FeedBack-Neural-Network","link":"/tags/FeedBack-Neural-Network/"},{"name":"Bayes Networks","slug":"Bayes-Networks","link":"/tags/Bayes-Networks/"},{"name":"Directed Acyclic Graphs (DAGs)","slug":"Directed-Acyclic-Graphs-DAGs","link":"/tags/Directed-Acyclic-Graphs-DAGs/"},{"name":"Bias","slug":"Bias","link":"/tags/Bias/"},{"name":"Variance","slug":"Variance","link":"/tags/Variance/"},{"name":"Underfitting","slug":"Underfitting","link":"/tags/Underfitting/"},{"name":"Overfitting","slug":"Overfitting","link":"/tags/Overfitting/"},{"name":"Model Selection","slug":"Model-Selection","link":"/tags/Model-Selection/"},{"name":"Cross Validation","slug":"Cross-Validation","link":"/tags/Cross-Validation/"},{"name":"Learning Curve","slug":"Learning-Curve","link":"/tags/Learning-Curve/"},{"name":"Error Analysis","slug":"Error-Analysis","link":"/tags/Error-Analysis/"},{"name":"Model Evaluation Metrics","slug":"Model-Evaluation-Metrics","link":"/tags/Model-Evaluation-Metrics/"},{"name":"Accuracy","slug":"Accuracy","link":"/tags/Accuracy/"},{"name":"Precision","slug":"Precision","link":"/tags/Precision/"},{"name":"Recall","slug":"Recall","link":"/tags/Recall/"},{"name":"F1 Score","slug":"F1-Score","link":"/tags/F1-Score/"},{"name":"ROC","slug":"ROC","link":"/tags/ROC/"},{"name":"AUC","slug":"AUC","link":"/tags/AUC/"},{"name":"Support Vector Machine","slug":"Support-Vector-Machine","link":"/tags/Support-Vector-Machine/"},{"name":"Lagrange Multipliers","slug":"Lagrange-Multipliers","link":"/tags/Lagrange-Multipliers/"},{"name":"Soft Margin Formulation","slug":"Soft-Margin-Formulation","link":"/tags/Soft-Margin-Formulation/"},{"name":"Kernels Tricks","slug":"Kernels-Tricks","link":"/tags/Kernels-Tricks/"},{"name":"Bayes Theorem","slug":"Bayes-Theorem","link":"/tags/Bayes-Theorem/"},{"name":"Naive Bayes","slug":"Naive-Bayes","link":"/tags/Naive-Bayes/"},{"name":"Multinomial Naive Bayes","slug":"Multinomial-Naive-Bayes","link":"/tags/Multinomial-Naive-Bayes/"},{"name":"Bernoulli Naive Bayes","slug":"Bernoulli-Naive-Bayes","link":"/tags/Bernoulli-Naive-Bayes/"},{"name":"Gaussian Naive Bayes","slug":"Gaussian-Naive-Bayes","link":"/tags/Gaussian-Naive-Bayes/"},{"name":"Probability","slug":"Probability","link":"/tags/Probability/"},{"name":"Decision Tree","slug":"Decision-Tree","link":"/tags/Decision-Tree/"},{"name":"Information Gain","slug":"Information-Gain","link":"/tags/Information-Gain/"},{"name":"Gini Index","slug":"Gini-Index","link":"/tags/Gini-Index/"},{"name":"Entropy","slug":"Entropy","link":"/tags/Entropy/"},{"name":"Gini Impurity","slug":"Gini-Impurity","link":"/tags/Gini-Impurity/"},{"name":"Pruning Tree","slug":"Pruning-Tree","link":"/tags/Pruning-Tree/"},{"name":"Cost Complexity Pruning","slug":"Cost-Complexity-Pruning","link":"/tags/Cost-Complexity-Pruning/"},{"name":"Reduced Error Pruning","slug":"Reduced-Error-Pruning","link":"/tags/Reduced-Error-Pruning/"},{"name":"Minimum Error Pruning (MEP)","slug":"Minimum-Error-Pruning-MEP","link":"/tags/Minimum-Error-Pruning-MEP/"},{"name":"Pessimistic Pruning","slug":"Pessimistic-Pruning","link":"/tags/Pessimistic-Pruning/"},{"name":"Error-Based Pruning (EBP)","slug":"Error-Based-Pruning-EBP","link":"/tags/Error-Based-Pruning-EBP/"},{"name":"Minimum Description Length (MDL) Pruning","slug":"Minimum-Description-Length-MDL-Pruning","link":"/tags/Minimum-Description-Length-MDL-Pruning/"},{"name":"Iterative Dichotomiser 3 (ID3)","slug":"Iterative-Dichotomiser-3-ID3","link":"/tags/Iterative-Dichotomiser-3-ID3/"},{"name":"C4.5","slug":"C4-5","link":"/tags/C4-5/"},{"name":"Classification and Regression Tree (CART)","slug":"Classification-and-Regression-Tree-CART","link":"/tags/Classification-and-Regression-Tree-CART/"},{"name":"Iot","slug":"Iot","link":"/tags/Iot/"},{"name":"Kafka","slug":"Kafka","link":"/tags/Kafka/"},{"name":"Zookeeper","slug":"Zookeeper","link":"/tags/Zookeeper/"},{"name":"Mosquitto","slug":"Mosquitto","link":"/tags/Mosquitto/"},{"name":"Grafana","slug":"Grafana","link":"/tags/Grafana/"},{"name":"Smart Agriculture","slug":"Smart-Agriculture","link":"/tags/Smart-Agriculture/"},{"name":"Smart House","slug":"Smart-House","link":"/tags/Smart-House/"},{"name":"Smart City","slug":"Smart-City","link":"/tags/Smart-City/"},{"name":"Big Data Engineer","slug":"Big-Data-Engineer","link":"/tags/Big-Data-Engineer/"},{"name":"Real Time Analysis","slug":"Real-Time-Analysis","link":"/tags/Real-Time-Analysis/"},{"name":"Spark Streamming","slug":"Spark-Streamming","link":"/tags/Spark-Streamming/"},{"name":"Postgres Sql","slug":"Postgres-Sql","link":"/tags/Postgres-Sql/"}],"categories":[{"name":"Machine Learning","slug":"Machine-Learning","link":"/categories/Machine-Learning/"},{"name":"Deep Learning","slug":"Deep-Learning","link":"/categories/Deep-Learning/"}]}